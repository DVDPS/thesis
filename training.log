2025-02-27 09:47:03,939 - INFO - === 2048 Enhanced Training ===
2025-02-27 09:47:03,940 - INFO - Training for 5000 epochs with batch size 96
2025-02-27 09:47:03,940 - INFO - Learning rate: 0.0008
2025-02-27 09:47:03,941 - INFO - Device: cuda
2025-02-27 09:47:03,941 - INFO - Starting training with simplified approach
2025-02-27 09:47:03,942 - INFO - Training for 5000 epochs with batch size 96
2025-02-27 09:47:06,314 - INFO - New best model saved with reward 2396.9
2025-02-27 09:47:16,259 - INFO - New best model saved with reward 2401.2
2025-02-27 09:47:23,036 - INFO - Epoch 10/5000 | Reward: 2580.4 | Running reward: 2345.2 | Max tile: 128 | Exploration: 0.75
2025-02-27 09:47:41,922 - INFO - Epoch 20/5000 | Reward: 3046.3 | Running reward: 2306.0 | Max tile: 256 | Exploration: 0.75
2025-02-27 09:47:59,961 - INFO - Epoch 30/5000 | Reward: 2591.5 | Running reward: 2194.0 | Max tile: 128 | Exploration: 0.75
2025-02-27 09:48:20,062 - INFO - Epoch 40/5000 | Reward: 1971.6 | Running reward: 2247.5 | Max tile: 128 | Exploration: 0.75
2025-02-27 09:48:40,604 - INFO - Epoch 50/5000 | Reward: 2820.3 | Running reward: 2257.6 | Max tile: 256 | Exploration: 0.75
2025-02-27 09:49:03,154 - INFO - Epoch 60/5000 | Reward: 1804.5 | Running reward: 2259.3 | Max tile: 64 | Exploration: 0.74
2025-02-27 09:49:23,128 - INFO - Epoch 70/5000 | Reward: 1782.4 | Running reward: 2160.8 | Max tile: 64 | Exploration: 0.74
2025-02-27 09:49:41,301 - INFO - Epoch 80/5000 | Reward: 1958.6 | Running reward: 2086.4 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:50:00,754 - INFO - Epoch 90/5000 | Reward: 2221.0 | Running reward: 2097.2 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:50:21,883 - INFO - Epoch 100/5000 | Reward: 1855.5 | Running reward: 2177.8 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:50:41,931 - INFO - Epoch 110/5000 | Reward: 2471.5 | Running reward: 2182.0 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:51:02,890 - INFO - Epoch 120/5000 | Reward: 1704.4 | Running reward: 2191.5 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:51:23,651 - INFO - Epoch 130/5000 | Reward: 2210.2 | Running reward: 2159.8 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:51:45,016 - INFO - Epoch 140/5000 | Reward: 1589.1 | Running reward: 2182.6 | Max tile: 64 | Exploration: 0.74
2025-02-27 09:52:05,436 - INFO - Epoch 150/5000 | Reward: 2201.1 | Running reward: 2186.4 | Max tile: 128 | Exploration: 0.74
2025-02-27 09:52:27,862 - INFO - Epoch 160/5000 | Reward: 2779.2 | Running reward: 2227.8 | Max tile: 256 | Exploration: 0.74
2025-02-27 09:52:46,057 - INFO - Epoch 170/5000 | Reward: 1944.7 | Running reward: 2109.9 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:53:08,149 - INFO - Epoch 180/5000 | Reward: 2337.8 | Running reward: 2138.3 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:53:27,365 - INFO - Epoch 190/5000 | Reward: 2097.9 | Running reward: 2127.4 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:53:47,454 - INFO - Epoch 200/5000 | Reward: 2749.2 | Running reward: 2153.3 | Max tile: 256 | Exploration: 0.73
2025-02-27 09:54:08,636 - INFO - Epoch 210/5000 | Reward: 2814.6 | Running reward: 2216.9 | Max tile: 256 | Exploration: 0.73
2025-02-27 09:54:28,063 - INFO - Epoch 220/5000 | Reward: 2251.7 | Running reward: 2182.3 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:54:47,519 - INFO - Epoch 230/5000 | Reward: 2413.8 | Running reward: 2162.7 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:55:09,016 - INFO - Epoch 240/5000 | Reward: 2338.9 | Running reward: 2229.6 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:55:29,757 - INFO - Epoch 250/5000 | Reward: 2651.1 | Running reward: 2253.2 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:55:49,812 - INFO - Epoch 260/5000 | Reward: 2162.5 | Running reward: 2220.9 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:56:10,462 - INFO - Epoch 270/5000 | Reward: 2096.4 | Running reward: 2160.6 | Max tile: 128 | Exploration: 0.73
2025-02-27 09:56:32,883 - INFO - Epoch 280/5000 | Reward: 2330.5 | Running reward: 2240.0 | Max tile: 128 | Exploration: 0.72
2025-02-27 10:02:01,339 - INFO - === 2048 Enhanced Training/Evaluation ===
2025-02-27 10:02:01,339 - INFO - Training for 3000 epochs with batch size 96
2025-02-27 10:02:01,340 - INFO - Learning rate: 0.0008
2025-02-27 10:02:01,340 - INFO - Device: cuda
2025-02-27 10:02:01,341 - INFO - Starting training with simplified approach
2025-02-27 10:02:01,341 - INFO - Training for 3000 epochs with batch size 96
2025-02-27 10:02:03,747 - INFO - New best model saved with reward 2396.9
2025-02-27 10:02:13,265 - INFO - New best model saved with reward 2401.2
2025-02-27 10:02:20,603 - INFO - Epoch 10/3000 | Reward: 2604.5 | Running reward: 2372.5 | Max tile: 128 | Exploration: 0.75
2025-02-27 10:02:37,470 - INFO - Epoch 20/3000 | Reward: 2383.4 | Running reward: 2254.6 | Max tile: 128 | Exploration: 0.75
2025-02-27 10:02:55,339 - INFO - Epoch 30/3000 | Reward: 1653.2 | Running reward: 2223.6 | Max tile: 128 | Exploration: 0.75
2025-02-27 10:03:10,458 - INFO - Epoch 40/3000 | Reward: 1638.0 | Running reward: 2097.5 | Max tile: 128 | Exploration: 0.74
2025-02-27 10:03:27,895 - INFO - Epoch 50/3000 | Reward: 2338.1 | Running reward: 2107.3 | Max tile: 128 | Exploration: 0.74
2025-02-27 10:03:47,331 - INFO - Epoch 60/3000 | Reward: 2717.2 | Running reward: 2235.3 | Max tile: 256 | Exploration: 0.74
2025-02-27 10:04:06,665 - INFO - Epoch 70/3000 | Reward: 2221.6 | Running reward: 2281.7 | Max tile: 128 | Exploration: 0.74
2025-02-27 10:04:24,702 - INFO - Epoch 80/3000 | Reward: 2458.8 | Running reward: 2254.7 | Max tile: 256 | Exploration: 0.74
2025-02-27 10:04:42,880 - INFO - Epoch 90/3000 | Reward: 2383.4 | Running reward: 2252.2 | Max tile: 128 | Exploration: 0.74
2025-02-27 10:05:01,589 - INFO - Epoch 100/3000 | Reward: 2007.5 | Running reward: 2282.1 | Max tile: 128 | Exploration: 0.74
2025-02-27 10:05:19,844 - INFO - Epoch 110/3000 | Reward: 2461.6 | Running reward: 2270.3 | Max tile: 128 | Exploration: 0.73
2025-02-27 10:05:37,329 - INFO - Epoch 120/3000 | Reward: 1682.6 | Running reward: 2215.7 | Max tile: 64 | Exploration: 0.73
2025-02-27 10:05:54,605 - INFO - Epoch 130/3000 | Reward: 2378.4 | Running reward: 2191.6 | Max tile: 128 | Exploration: 0.73
2025-02-27 10:06:12,617 - INFO - Epoch 140/3000 | Reward: 1635.3 | Running reward: 2192.3 | Max tile: 128 | Exploration: 0.73
2025-02-27 10:06:33,176 - INFO - Epoch 150/3000 | Reward: 2582.4 | Running reward: 2310.7 | Max tile: 256 | Exploration: 0.73
2025-02-27 10:06:52,807 - INFO - Epoch 160/3000 | Reward: 2376.1 | Running reward: 2345.5 | Max tile: 256 | Exploration: 0.73
2025-02-27 10:07:10,245 - INFO - Epoch 170/3000 | Reward: 1795.2 | Running reward: 2260.4 | Max tile: 128 | Exploration: 0.72
2025-02-27 10:07:28,682 - INFO - Epoch 180/3000 | Reward: 1981.1 | Running reward: 2258.9 | Max tile: 128 | Exploration: 0.72
2025-02-27 10:07:48,840 - INFO - Epoch 190/3000 | Reward: 2709.3 | Running reward: 2290.4 | Max tile: 128 | Exploration: 0.72
2025-02-27 10:08:07,453 - INFO - Epoch 200/3000 | Reward: 1923.4 | Running reward: 2207.5 | Max tile: 128 | Exploration: 0.72
2025-02-27 10:08:26,250 - INFO - Epoch 210/3000 | Reward: 2607.4 | Running reward: 2223.5 | Max tile: 128 | Exploration: 0.72
2025-02-27 10:08:42,909 - INFO - Epoch 220/3000 | Reward: 1730.5 | Running reward: 2139.1 | Max tile: 64 | Exploration: 0.72
2025-02-27 10:09:01,118 - INFO - Epoch 230/3000 | Reward: 2958.5 | Running reward: 2193.9 | Max tile: 256 | Exploration: 0.72
2025-02-27 10:09:19,426 - INFO - Epoch 240/3000 | Reward: 1769.2 | Running reward: 2187.5 | Max tile: 128 | Exploration: 0.71
2025-02-27 10:09:37,035 - INFO - Epoch 250/3000 | Reward: 2242.5 | Running reward: 2163.8 | Max tile: 128 | Exploration: 0.71
2025-02-27 10:09:55,177 - INFO - Epoch 260/3000 | Reward: 2081.7 | Running reward: 2175.0 | Max tile: 128 | Exploration: 0.71
2025-02-27 10:10:11,839 - INFO - Epoch 270/3000 | Reward: 2627.2 | Running reward: 2101.1 | Max tile: 128 | Exploration: 0.71
2025-02-27 10:10:29,702 - INFO - Epoch 280/3000 | Reward: 2660.6 | Running reward: 2114.3 | Max tile: 256 | Exploration: 0.71
2025-02-27 10:10:48,359 - INFO - Epoch 290/3000 | Reward: 1840.1 | Running reward: 2175.4 | Max tile: 128 | Exploration: 0.71
2025-02-27 10:11:06,298 - INFO - Epoch 300/3000 | Reward: 1810.9 | Running reward: 2150.8 | Max tile: 128 | Exploration: 0.71
2025-02-27 10:11:22,523 - INFO - Epoch 310/3000 | Reward: 1617.9 | Running reward: 2076.7 | Max tile: 128 | Exploration: 0.70
2025-02-27 10:11:41,317 - INFO - Epoch 320/3000 | Reward: 2635.0 | Running reward: 2185.9 | Max tile: 128 | Exploration: 0.70
2025-02-27 10:11:58,309 - INFO - Epoch 330/3000 | Reward: 2011.9 | Running reward: 2147.4 | Max tile: 128 | Exploration: 0.70
2025-02-27 10:12:15,442 - INFO - Epoch 340/3000 | Reward: 2058.4 | Running reward: 2130.5 | Max tile: 128 | Exploration: 0.70
2025-02-27 10:12:33,966 - INFO - Epoch 350/3000 | Reward: 2714.7 | Running reward: 2171.3 | Max tile: 256 | Exploration: 0.70
2025-02-27 10:12:51,477 - INFO - Epoch 360/3000 | Reward: 2319.7 | Running reward: 2174.0 | Max tile: 128 | Exploration: 0.70
2025-02-27 10:13:08,845 - INFO - Epoch 370/3000 | Reward: 1773.1 | Running reward: 2135.2 | Max tile: 64 | Exploration: 0.69
2025-02-27 10:13:27,860 - INFO - Epoch 380/3000 | Reward: 1984.0 | Running reward: 2174.1 | Max tile: 256 | Exploration: 0.69
2025-02-27 10:13:46,312 - INFO - Epoch 390/3000 | Reward: 2116.2 | Running reward: 2191.7 | Max tile: 128 | Exploration: 0.69
2025-02-27 10:14:01,871 - INFO - Epoch 400/3000 | Reward: 2525.1 | Running reward: 2081.5 | Max tile: 128 | Exploration: 0.69
2025-02-27 10:14:20,927 - INFO - Epoch 410/3000 | Reward: 1777.2 | Running reward: 2187.7 | Max tile: 128 | Exploration: 0.69
2025-02-27 10:14:40,392 - INFO - Epoch 420/3000 | Reward: 2379.1 | Running reward: 2269.4 | Max tile: 128 | Exploration: 0.69
2025-02-27 10:14:57,438 - INFO - Epoch 430/3000 | Reward: 2758.0 | Running reward: 2205.3 | Max tile: 256 | Exploration: 0.69
2025-02-27 10:15:16,385 - INFO - Epoch 440/3000 | Reward: 1825.2 | Running reward: 2240.4 | Max tile: 128 | Exploration: 0.68
2025-02-27 10:15:34,523 - INFO - Epoch 450/3000 | Reward: 1500.8 | Running reward: 2227.2 | Max tile: 64 | Exploration: 0.68
2025-02-27 10:15:51,209 - INFO - Epoch 460/3000 | Reward: 1933.1 | Running reward: 2164.5 | Max tile: 128 | Exploration: 0.68
2025-02-27 10:16:07,498 - INFO - Epoch 470/3000 | Reward: 1234.7 | Running reward: 2077.9 | Max tile: 64 | Exploration: 0.68
2025-02-27 10:16:26,181 - INFO - Epoch 480/3000 | Reward: 2544.4 | Running reward: 2159.5 | Max tile: 128 | Exploration: 0.68
2025-02-27 10:16:43,431 - INFO - Epoch 490/3000 | Reward: 1765.2 | Running reward: 2138.8 | Max tile: 128 | Exploration: 0.68
2025-02-27 10:17:00,650 - INFO - Epoch 500/3000 | Reward: 1555.8 | Running reward: 2095.3 | Max tile: 64 | Exploration: 0.68
2025-02-27 10:17:18,418 - INFO - Epoch 510/3000 | Reward: 2282.4 | Running reward: 2147.0 | Max tile: 128 | Exploration: 0.67
2025-02-27 10:17:37,890 - INFO - Epoch 520/3000 | Reward: 2111.9 | Running reward: 2235.5 | Max tile: 128 | Exploration: 0.67
2025-02-27 10:17:57,149 - INFO - Epoch 530/3000 | Reward: 2806.4 | Running reward: 2284.2 | Max tile: 256 | Exploration: 0.67
2025-02-27 10:18:14,609 - INFO - Epoch 540/3000 | Reward: 2632.4 | Running reward: 2230.1 | Max tile: 256 | Exploration: 0.67
2025-02-27 10:18:32,471 - INFO - Epoch 550/3000 | Reward: 1973.6 | Running reward: 2190.6 | Max tile: 128 | Exploration: 0.67
2025-02-27 10:18:50,410 - INFO - Epoch 560/3000 | Reward: 1644.2 | Running reward: 2192.1 | Max tile: 64 | Exploration: 0.67
2025-02-27 10:19:09,434 - INFO - Epoch 570/3000 | Reward: 2862.9 | Running reward: 2189.5 | Max tile: 256 | Exploration: 0.66
2025-02-27 10:19:29,764 - INFO - Epoch 580/3000 | Reward: 1974.4 | Running reward: 2192.6 | Max tile: 128 | Exploration: 0.66
2025-02-27 10:19:52,008 - INFO - Epoch 590/3000 | Reward: 2480.5 | Running reward: 2260.9 | Max tile: 128 | Exploration: 0.66
2025-02-27 10:20:12,235 - INFO - Epoch 600/3000 | Reward: 2944.0 | Running reward: 2266.4 | Max tile: 256 | Exploration: 0.66
2025-02-27 10:20:32,112 - INFO - Epoch 610/3000 | Reward: 1461.9 | Running reward: 2230.5 | Max tile: 128 | Exploration: 0.66
2025-02-27 10:20:51,632 - INFO - Epoch 620/3000 | Reward: 1943.0 | Running reward: 2202.8 | Max tile: 128 | Exploration: 0.66
2025-02-27 10:21:09,118 - INFO - Epoch 630/3000 | Reward: 1851.2 | Running reward: 2116.6 | Max tile: 128 | Exploration: 0.66
2025-02-27 10:21:28,891 - INFO - Epoch 640/3000 | Reward: 2268.4 | Running reward: 2159.0 | Max tile: 128 | Exploration: 0.65
2025-02-27 10:21:51,330 - INFO - Epoch 650/3000 | Reward: 3068.7 | Running reward: 2307.6 | Max tile: 256 | Exploration: 0.65
2025-02-27 10:22:13,039 - INFO - Epoch 660/3000 | Reward: 3165.6 | Running reward: 2365.0 | Max tile: 256 | Exploration: 0.65
2025-02-27 10:22:33,852 - INFO - Epoch 670/3000 | Reward: 2312.3 | Running reward: 2341.6 | Max tile: 128 | Exploration: 0.65
2025-02-27 10:22:54,146 - INFO - Epoch 680/3000 | Reward: 2658.2 | Running reward: 2316.8 | Max tile: 256 | Exploration: 0.65
2025-02-27 10:23:13,476 - INFO - Epoch 690/3000 | Reward: 2363.4 | Running reward: 2223.6 | Max tile: 128 | Exploration: 0.65
2025-02-27 10:23:33,131 - INFO - Epoch 700/3000 | Reward: 1712.0 | Running reward: 2215.6 | Max tile: 128 | Exploration: 0.65
2025-02-27 10:23:54,939 - INFO - Epoch 710/3000 | Reward: 2232.5 | Running reward: 2322.0 | Max tile: 128 | Exploration: 0.64
2025-02-27 10:24:16,844 - INFO - Epoch 720/3000 | Reward: 1947.3 | Running reward: 2339.4 | Max tile: 128 | Exploration: 0.64
2025-02-27 10:24:37,583 - INFO - Epoch 730/3000 | Reward: 2407.8 | Running reward: 2285.1 | Max tile: 128 | Exploration: 0.64
2025-02-27 10:24:58,710 - INFO - Epoch 740/3000 | Reward: 2118.3 | Running reward: 2313.1 | Max tile: 128 | Exploration: 0.64
2025-02-27 10:25:19,557 - INFO - Epoch 750/3000 | Reward: 2479.6 | Running reward: 2313.3 | Max tile: 128 | Exploration: 0.64
2025-02-27 10:25:40,189 - INFO - Epoch 760/3000 | Reward: 2795.1 | Running reward: 2335.8 | Max tile: 128 | Exploration: 0.64
2025-02-27 10:26:00,353 - INFO - Epoch 770/3000 | Reward: 1844.0 | Running reward: 2278.6 | Max tile: 64 | Exploration: 0.63
2025-02-27 10:26:21,003 - INFO - Epoch 780/3000 | Reward: 1970.8 | Running reward: 2285.5 | Max tile: 128 | Exploration: 0.63
2025-02-27 10:26:43,997 - INFO - Epoch 790/3000 | Reward: 2135.9 | Running reward: 2336.8 | Max tile: 128 | Exploration: 0.63
2025-02-27 10:27:04,516 - INFO - Epoch 800/3000 | Reward: 2242.5 | Running reward: 2250.0 | Max tile: 128 | Exploration: 0.63
2025-02-27 10:27:27,511 - INFO - Epoch 810/3000 | Reward: 3114.5 | Running reward: 2380.3 | Max tile: 256 | Exploration: 0.63
2025-02-27 10:27:46,403 - INFO - Epoch 820/3000 | Reward: 2711.8 | Running reward: 2320.8 | Max tile: 128 | Exploration: 0.63
2025-02-27 10:28:06,862 - INFO - Epoch 830/3000 | Reward: 2619.6 | Running reward: 2314.3 | Max tile: 256 | Exploration: 0.63
2025-02-27 10:28:27,466 - INFO - Epoch 840/3000 | Reward: 2127.3 | Running reward: 2289.5 | Max tile: 128 | Exploration: 0.62
2025-02-27 10:28:46,744 - INFO - Epoch 850/3000 | Reward: 2655.6 | Running reward: 2236.3 | Max tile: 256 | Exploration: 0.62
2025-02-27 10:29:08,327 - INFO - Epoch 860/3000 | Reward: 1893.5 | Running reward: 2268.4 | Max tile: 128 | Exploration: 0.62
2025-02-27 10:29:27,145 - INFO - Epoch 870/3000 | Reward: 2129.2 | Running reward: 2183.7 | Max tile: 128 | Exploration: 0.62
2025-02-27 10:29:47,112 - INFO - Epoch 880/3000 | Reward: 2485.0 | Running reward: 2193.8 | Max tile: 128 | Exploration: 0.62
2025-02-27 10:30:04,823 - INFO - Epoch 890/3000 | Reward: 2162.1 | Running reward: 2135.9 | Max tile: 128 | Exploration: 0.62
2025-02-27 10:30:25,794 - INFO - Epoch 900/3000 | Reward: 2516.3 | Running reward: 2207.6 | Max tile: 256 | Exploration: 0.62
2025-02-27 10:30:46,860 - INFO - Epoch 910/3000 | Reward: 1546.9 | Running reward: 2223.9 | Max tile: 64 | Exploration: 0.61
2025-02-27 10:31:07,187 - INFO - Epoch 920/3000 | Reward: 1627.3 | Running reward: 2194.2 | Max tile: 64 | Exploration: 0.61
2025-02-27 10:31:26,555 - INFO - Epoch 930/3000 | Reward: 2791.3 | Running reward: 2170.8 | Max tile: 128 | Exploration: 0.61
2025-02-27 10:31:46,666 - INFO - Epoch 940/3000 | Reward: 2492.2 | Running reward: 2197.7 | Max tile: 256 | Exploration: 0.61
2025-02-27 10:32:06,652 - INFO - Epoch 950/3000 | Reward: 2597.1 | Running reward: 2199.2 | Max tile: 128 | Exploration: 0.61
2025-02-27 10:32:27,795 - INFO - Epoch 960/3000 | Reward: 2649.2 | Running reward: 2258.2 | Max tile: 128 | Exploration: 0.61
2025-02-27 10:32:47,300 - INFO - Epoch 970/3000 | Reward: 2241.0 | Running reward: 2214.0 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:33:09,423 - INFO - Epoch 980/3000 | Reward: 2411.8 | Running reward: 2291.3 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:33:30,502 - INFO - Epoch 990/3000 | Reward: 2285.0 | Running reward: 2288.6 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:33:51,105 - INFO - Epoch 1000/3000 | Reward: 1976.8 | Running reward: 2268.9 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:34:13,862 - INFO - Epoch 1010/3000 | Reward: 1887.9 | Running reward: 2331.2 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:34:36,150 - INFO - Epoch 1020/3000 | Reward: 2299.9 | Running reward: 2345.0 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:34:57,955 - INFO - Epoch 1030/3000 | Reward: 2229.2 | Running reward: 2346.9 | Max tile: 128 | Exploration: 0.60
2025-02-27 10:35:18,557 - INFO - Epoch 1040/3000 | Reward: 2397.7 | Running reward: 2309.0 | Max tile: 128 | Exploration: 0.59
2025-02-27 10:35:39,360 - INFO - Epoch 1050/3000 | Reward: 2628.8 | Running reward: 2286.5 | Max tile: 256 | Exploration: 0.59
2025-02-27 10:35:57,770 - INFO - Epoch 1060/3000 | Reward: 1822.1 | Running reward: 2167.0 | Max tile: 128 | Exploration: 0.59
2025-02-27 10:36:17,846 - INFO - Epoch 1070/3000 | Reward: 1742.9 | Running reward: 2141.8 | Max tile: 128 | Exploration: 0.59
2025-02-27 10:36:40,168 - INFO - Epoch 1080/3000 | Reward: 2224.6 | Running reward: 2176.5 | Max tile: 128 | Exploration: 0.59
2025-02-27 10:37:02,177 - INFO - Epoch 1090/3000 | Reward: 1526.5 | Running reward: 2219.9 | Max tile: 64 | Exploration: 0.59
2025-02-27 10:37:22,298 - INFO - Epoch 1100/3000 | Reward: 1938.0 | Running reward: 2191.5 | Max tile: 128 | Exploration: 0.59
2025-02-27 10:37:44,210 - INFO - Epoch 1110/3000 | Reward: 2155.6 | Running reward: 2250.4 | Max tile: 128 | Exploration: 0.58
2025-02-27 10:38:06,154 - INFO - Epoch 1120/3000 | Reward: 2174.4 | Running reward: 2271.1 | Max tile: 128 | Exploration: 0.58
2025-02-27 10:38:27,453 - INFO - Epoch 1130/3000 | Reward: 3241.9 | Running reward: 2293.4 | Max tile: 256 | Exploration: 0.58
2025-02-27 10:38:46,545 - INFO - Epoch 1140/3000 | Reward: 2417.7 | Running reward: 2182.3 | Max tile: 128 | Exploration: 0.58
2025-02-27 10:39:05,766 - INFO - Epoch 1150/3000 | Reward: 2400.9 | Running reward: 2148.7 | Max tile: 128 | Exploration: 0.58
2025-02-27 10:39:28,063 - INFO - Epoch 1160/3000 | Reward: 1830.3 | Running reward: 2225.3 | Max tile: 64 | Exploration: 0.58
2025-02-27 10:39:48,557 - INFO - Epoch 1170/3000 | Reward: 3323.9 | Running reward: 2216.3 | Max tile: 256 | Exploration: 0.57
2025-02-27 10:40:09,404 - INFO - Epoch 1180/3000 | Reward: 2472.8 | Running reward: 2261.7 | Max tile: 128 | Exploration: 0.57
2025-02-27 10:40:28,282 - INFO - Epoch 1190/3000 | Reward: 2057.6 | Running reward: 2186.6 | Max tile: 128 | Exploration: 0.57
2025-02-27 10:40:48,775 - INFO - Epoch 1200/3000 | Reward: 2189.0 | Running reward: 2224.3 | Max tile: 128 | Exploration: 0.57
2025-02-27 10:41:06,705 - INFO - Epoch 1210/3000 | Reward: 1711.2 | Running reward: 2088.4 | Max tile: 128 | Exploration: 0.57
2025-02-27 10:41:26,777 - INFO - Epoch 1220/3000 | Reward: 1851.8 | Running reward: 2113.9 | Max tile: 128 | Exploration: 0.57
2025-02-27 10:41:48,260 - INFO - Epoch 1230/3000 | Reward: 2098.7 | Running reward: 2214.0 | Max tile: 64 | Exploration: 0.57
2025-02-27 10:42:08,121 - INFO - Epoch 1240/3000 | Reward: 1864.6 | Running reward: 2181.1 | Max tile: 128 | Exploration: 0.56
2025-02-27 10:42:28,157 - INFO - Epoch 1250/3000 | Reward: 2312.0 | Running reward: 2200.0 | Max tile: 128 | Exploration: 0.56
2025-02-27 10:42:50,899 - INFO - Epoch 1260/3000 | Reward: 2504.1 | Running reward: 2281.9 | Max tile: 128 | Exploration: 0.56
2025-02-27 10:43:11,189 - INFO - Epoch 1270/3000 | Reward: 2145.1 | Running reward: 2217.0 | Max tile: 128 | Exploration: 0.56
2025-02-27 10:43:30,389 - INFO - Epoch 1280/3000 | Reward: 1912.9 | Running reward: 2170.2 | Max tile: 64 | Exploration: 0.56
2025-02-27 10:43:51,791 - INFO - Epoch 1290/3000 | Reward: 2401.9 | Running reward: 2232.8 | Max tile: 128 | Exploration: 0.56
2025-02-27 10:44:12,829 - INFO - Epoch 1300/3000 | Reward: 2420.0 | Running reward: 2279.1 | Max tile: 128 | Exploration: 0.56
2025-02-27 10:44:32,671 - INFO - Epoch 1310/3000 | Reward: 2115.1 | Running reward: 2228.6 | Max tile: 128 | Exploration: 0.55
2025-02-27 10:44:54,723 - INFO - Epoch 1320/3000 | Reward: 2101.1 | Running reward: 2277.8 | Max tile: 128 | Exploration: 0.55
2025-02-27 10:45:14,774 - INFO - Epoch 1330/3000 | Reward: 2848.8 | Running reward: 2265.4 | Max tile: 128 | Exploration: 0.55
2025-02-27 10:45:33,236 - INFO - Epoch 1340/3000 | Reward: 2355.5 | Running reward: 2196.7 | Max tile: 128 | Exploration: 0.55
2025-02-27 10:45:52,273 - INFO - Epoch 1350/3000 | Reward: 2069.5 | Running reward: 2182.1 | Max tile: 128 | Exploration: 0.55
2025-02-27 10:46:13,831 - INFO - Epoch 1360/3000 | Reward: 2374.5 | Running reward: 2260.0 | Max tile: 128 | Exploration: 0.55
2025-02-27 10:46:34,700 - INFO - Epoch 1370/3000 | Reward: 1324.6 | Running reward: 2221.0 | Max tile: 64 | Exploration: 0.54
2025-02-27 10:46:52,990 - INFO - Epoch 1380/3000 | Reward: 1680.9 | Running reward: 2120.6 | Max tile: 64 | Exploration: 0.54
2025-02-27 10:47:13,365 - INFO - Epoch 1390/3000 | Reward: 1741.1 | Running reward: 2140.7 | Max tile: 128 | Exploration: 0.54
2025-02-27 10:47:34,579 - INFO - Epoch 1400/3000 | Reward: 2293.1 | Running reward: 2202.5 | Max tile: 128 | Exploration: 0.54
2025-02-27 10:47:54,910 - INFO - Epoch 1410/3000 | Reward: 2106.3 | Running reward: 2240.7 | Max tile: 128 | Exploration: 0.54
2025-02-27 10:48:15,138 - INFO - Epoch 1420/3000 | Reward: 1876.8 | Running reward: 2254.6 | Max tile: 128 | Exploration: 0.54
2025-02-27 10:48:35,694 - INFO - Epoch 1430/3000 | Reward: 3514.5 | Running reward: 2263.3 | Max tile: 256 | Exploration: 0.54
2025-02-27 10:48:56,448 - INFO - Epoch 1440/3000 | Reward: 1876.5 | Running reward: 2255.6 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:49:18,394 - INFO - Epoch 1450/3000 | Reward: 2230.0 | Running reward: 2332.4 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:49:38,138 - INFO - Epoch 1460/3000 | Reward: 2297.2 | Running reward: 2258.9 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:49:59,875 - INFO - Epoch 1470/3000 | Reward: 1947.5 | Running reward: 2343.0 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:50:16,730 - INFO - Epoch 1480/3000 | Reward: 1746.4 | Running reward: 2212.2 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:50:34,056 - INFO - Epoch 1490/3000 | Reward: 2118.4 | Running reward: 2172.9 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:50:51,346 - INFO - Epoch 1500/3000 | Reward: 1941.6 | Running reward: 2133.9 | Max tile: 128 | Exploration: 0.53
2025-02-27 10:51:11,162 - INFO - Epoch 1510/3000 | Reward: 2739.1 | Running reward: 2275.5 | Max tile: 128 | Exploration: 0.52
2025-02-27 10:51:29,658 - INFO - Epoch 1520/3000 | Reward: 1471.9 | Running reward: 2268.6 | Max tile: 64 | Exploration: 0.52
2025-02-27 10:51:46,967 - INFO - Epoch 1530/3000 | Reward: 1908.2 | Running reward: 2172.5 | Max tile: 128 | Exploration: 0.52
2025-02-27 10:52:03,146 - INFO - Epoch 1540/3000 | Reward: 1738.2 | Running reward: 2054.6 | Max tile: 64 | Exploration: 0.52
2025-02-27 10:52:23,218 - INFO - Epoch 1550/3000 | Reward: 2515.8 | Running reward: 2213.8 | Max tile: 128 | Exploration: 0.52
2025-02-27 10:52:40,929 - INFO - Epoch 1560/3000 | Reward: 1790.2 | Running reward: 2184.4 | Max tile: 64 | Exploration: 0.52
2025-02-27 10:53:00,928 - INFO - Epoch 1570/3000 | Reward: 2569.3 | Running reward: 2298.0 | Max tile: 256 | Exploration: 0.51
2025-02-27 10:53:18,954 - INFO - Epoch 1580/3000 | Reward: 2430.6 | Running reward: 2283.3 | Max tile: 128 | Exploration: 0.51
2025-02-27 10:53:37,018 - INFO - Epoch 1590/3000 | Reward: 1669.3 | Running reward: 2261.7 | Max tile: 64 | Exploration: 0.51
2025-02-27 10:53:54,747 - INFO - Epoch 1600/3000 | Reward: 2578.5 | Running reward: 2218.3 | Max tile: 256 | Exploration: 0.51
2025-02-27 10:54:12,388 - INFO - Epoch 1610/3000 | Reward: 2881.2 | Running reward: 2175.7 | Max tile: 256 | Exploration: 0.51
2025-02-27 10:54:30,376 - INFO - Epoch 1620/3000 | Reward: 2116.6 | Running reward: 2177.2 | Max tile: 256 | Exploration: 0.51
2025-02-27 10:54:48,780 - INFO - Epoch 1630/3000 | Reward: 3870.5 | Running reward: 2205.6 | Max tile: 256 | Exploration: 0.51
2025-02-27 10:55:06,215 - INFO - Epoch 1640/3000 | Reward: 1707.2 | Running reward: 2158.5 | Max tile: 128 | Exploration: 0.50
2025-02-27 10:55:23,748 - INFO - Epoch 1650/3000 | Reward: 2185.0 | Running reward: 2142.9 | Max tile: 128 | Exploration: 0.50
2025-02-27 10:55:42,958 - INFO - Epoch 1660/3000 | Reward: 2133.5 | Running reward: 2228.5 | Max tile: 128 | Exploration: 0.50
2025-02-27 10:55:59,611 - INFO - Epoch 1670/3000 | Reward: 1707.6 | Running reward: 2130.7 | Max tile: 64 | Exploration: 0.50
2025-02-27 10:56:16,158 - INFO - Epoch 1680/3000 | Reward: 1644.0 | Running reward: 2068.7 | Max tile: 64 | Exploration: 0.50
2025-02-27 10:56:34,005 - INFO - Epoch 1690/3000 | Reward: 2328.5 | Running reward: 2099.7 | Max tile: 128 | Exploration: 0.50
2025-02-27 10:56:52,260 - INFO - Epoch 1700/3000 | Reward: 2773.8 | Running reward: 2163.7 | Max tile: 256 | Exploration: 0.50
2025-02-27 10:57:08,801 - INFO - Epoch 1710/3000 | Reward: 1877.2 | Running reward: 2100.1 | Max tile: 128 | Exploration: 0.49
2025-02-27 10:57:25,436 - INFO - Epoch 1720/3000 | Reward: 1520.3 | Running reward: 2038.9 | Max tile: 64 | Exploration: 0.49
2025-02-27 10:57:41,945 - INFO - Epoch 1730/3000 | Reward: 1948.6 | Running reward: 1997.9 | Max tile: 128 | Exploration: 0.49
2025-02-27 10:58:00,686 - INFO - Epoch 1740/3000 | Reward: 2367.4 | Running reward: 2105.8 | Max tile: 128 | Exploration: 0.49
2025-02-27 10:58:17,295 - INFO - Epoch 1750/3000 | Reward: 2709.4 | Running reward: 2121.3 | Max tile: 128 | Exploration: 0.49
2025-02-27 10:58:35,685 - INFO - Epoch 1760/3000 | Reward: 2428.9 | Running reward: 2182.2 | Max tile: 256 | Exploration: 0.49
2025-02-27 10:58:54,079 - INFO - Epoch 1770/3000 | Reward: 2119.3 | Running reward: 2211.8 | Max tile: 128 | Exploration: 0.48
2025-02-27 10:59:10,770 - INFO - Epoch 1780/3000 | Reward: 1908.6 | Running reward: 2154.2 | Max tile: 128 | Exploration: 0.48
2025-02-27 10:59:28,325 - INFO - Epoch 1790/3000 | Reward: 1962.2 | Running reward: 2110.7 | Max tile: 128 | Exploration: 0.48
2025-02-27 10:59:44,437 - INFO - Epoch 1800/3000 | Reward: 2899.2 | Running reward: 2042.2 | Max tile: 256 | Exploration: 0.48
2025-02-27 11:00:03,217 - INFO - Epoch 1810/3000 | Reward: 3388.7 | Running reward: 2147.7 | Max tile: 256 | Exploration: 0.48
2025-02-27 11:00:21,433 - INFO - Epoch 1820/3000 | Reward: 2233.9 | Running reward: 2189.6 | Max tile: 128 | Exploration: 0.48
2025-02-27 11:00:39,976 - INFO - Epoch 1830/3000 | Reward: 1736.7 | Running reward: 2247.8 | Max tile: 128 | Exploration: 0.48
2025-02-27 11:01:00,190 - INFO - Epoch 1840/3000 | Reward: 3404.7 | Running reward: 2356.1 | Max tile: 256 | Exploration: 0.47
2025-02-27 11:01:17,629 - INFO - Epoch 1850/3000 | Reward: 2056.2 | Running reward: 2277.5 | Max tile: 128 | Exploration: 0.47
2025-02-27 11:01:34,885 - INFO - Epoch 1860/3000 | Reward: 1994.9 | Running reward: 2171.2 | Max tile: 128 | Exploration: 0.47
2025-02-27 11:01:49,430 - INFO - Epoch 1870/3000 | Reward: 1518.4 | Running reward: 1983.9 | Max tile: 128 | Exploration: 0.47
2025-02-27 11:02:08,056 - INFO - Epoch 1880/3000 | Reward: 3157.9 | Running reward: 2115.7 | Max tile: 256 | Exploration: 0.47
2025-02-27 11:02:24,573 - INFO - Epoch 1890/3000 | Reward: 1648.7 | Running reward: 2054.4 | Max tile: 64 | Exploration: 0.47
2025-02-27 11:02:42,501 - INFO - Epoch 1900/3000 | Reward: 2475.7 | Running reward: 2121.4 | Max tile: 128 | Exploration: 0.47
2025-02-27 11:03:00,770 - INFO - Epoch 1910/3000 | Reward: 2220.7 | Running reward: 2157.9 | Max tile: 128 | Exploration: 0.46
2025-02-27 11:03:17,637 - INFO - Epoch 1920/3000 | Reward: 1599.6 | Running reward: 2110.5 | Max tile: 128 | Exploration: 0.46
2025-02-27 11:03:35,495 - INFO - Epoch 1930/3000 | Reward: 2055.2 | Running reward: 2145.9 | Max tile: 128 | Exploration: 0.46
2025-02-27 11:03:51,502 - INFO - Epoch 1940/3000 | Reward: 1403.7 | Running reward: 2022.9 | Max tile: 64 | Exploration: 0.46
2025-02-27 11:04:07,048 - INFO - Epoch 1950/3000 | Reward: 1536.6 | Running reward: 1944.0 | Max tile: 64 | Exploration: 0.46
2025-02-27 11:04:25,754 - INFO - Epoch 1960/3000 | Reward: 2408.3 | Running reward: 2089.4 | Max tile: 256 | Exploration: 0.46
2025-02-27 11:04:44,867 - INFO - Epoch 1970/3000 | Reward: 2693.2 | Running reward: 2221.4 | Max tile: 128 | Exploration: 0.45
2025-02-27 11:05:05,429 - INFO - Epoch 1980/3000 | Reward: 2298.1 | Running reward: 2370.6 | Max tile: 128 | Exploration: 0.45
2025-02-27 11:05:12,146 - INFO - New best model saved with reward 2419.3
2025-02-27 11:05:25,067 - INFO - Epoch 1990/3000 | Reward: 1984.9 | Running reward: 2348.2 | Max tile: 128 | Exploration: 0.45
2025-02-27 11:05:40,535 - INFO - Epoch 2000/3000 | Reward: 1725.1 | Running reward: 2152.9 | Max tile: 128 | Exploration: 0.45
2025-02-27 11:05:56,320 - INFO - Epoch 2010/3000 | Reward: 1861.2 | Running reward: 2033.9 | Max tile: 128 | Exploration: 0.45
2025-02-27 11:06:10,599 - INFO - Epoch 2020/3000 | Reward: 1816.5 | Running reward: 1878.9 | Max tile: 128 | Exploration: 0.45
2025-02-27 11:06:28,661 - INFO - Epoch 2030/3000 | Reward: 2544.1 | Running reward: 1981.2 | Max tile: 256 | Exploration: 0.45
2025-02-27 11:06:46,490 - INFO - Epoch 2040/3000 | Reward: 1762.2 | Running reward: 2066.5 | Max tile: 64 | Exploration: 0.44
2025-02-27 11:07:08,838 - INFO - Epoch 2050/3000 | Reward: 2380.2 | Running reward: 2239.4 | Max tile: 128 | Exploration: 0.44
2025-02-27 11:07:29,228 - INFO - Epoch 2060/3000 | Reward: 2018.6 | Running reward: 2237.2 | Max tile: 128 | Exploration: 0.44
2025-02-27 11:07:48,553 - INFO - Epoch 2070/3000 | Reward: 2636.0 | Running reward: 2201.5 | Max tile: 256 | Exploration: 0.44
2025-02-27 11:08:07,519 - INFO - Epoch 2080/3000 | Reward: 1733.4 | Running reward: 2124.7 | Max tile: 64 | Exploration: 0.44
2025-02-27 11:08:27,887 - INFO - Epoch 2090/3000 | Reward: 2480.8 | Running reward: 2129.7 | Max tile: 128 | Exploration: 0.44
2025-02-27 11:08:46,765 - INFO - Epoch 2100/3000 | Reward: 2039.7 | Running reward: 2079.7 | Max tile: 128 | Exploration: 0.44
2025-02-27 11:09:06,020 - INFO - Epoch 2110/3000 | Reward: 2633.5 | Running reward: 2114.1 | Max tile: 128 | Exploration: 0.43
2025-02-27 11:09:27,522 - INFO - Epoch 2120/3000 | Reward: 1787.4 | Running reward: 2205.0 | Max tile: 64 | Exploration: 0.43
2025-02-27 11:09:48,956 - INFO - Epoch 2130/3000 | Reward: 2015.4 | Running reward: 2231.4 | Max tile: 128 | Exploration: 0.43
2025-02-27 11:10:11,090 - INFO - Epoch 2140/3000 | Reward: 4123.0 | Running reward: 2342.2 | Max tile: 256 | Exploration: 0.43
2025-02-27 11:10:29,776 - INFO - Epoch 2150/3000 | Reward: 1949.9 | Running reward: 2206.1 | Max tile: 256 | Exploration: 0.43
2025-02-27 11:10:46,826 - INFO - Epoch 2160/3000 | Reward: 1534.0 | Running reward: 2030.4 | Max tile: 64 | Exploration: 0.43
2025-02-27 11:11:04,214 - INFO - Epoch 2170/3000 | Reward: 1495.9 | Running reward: 1964.3 | Max tile: 64 | Exploration: 0.42
2025-02-27 11:11:23,662 - INFO - Epoch 2180/3000 | Reward: 2288.1 | Running reward: 2036.3 | Max tile: 128 | Exploration: 0.42
2025-02-27 11:11:48,458 - INFO - Epoch 2190/3000 | Reward: 3248.3 | Running reward: 2334.3 | Max tile: 256 | Exploration: 0.42
2025-02-27 11:12:10,935 - INFO - Epoch 2200/3000 | Reward: 2651.9 | Running reward: 2388.2 | Max tile: 128 | Exploration: 0.42
2025-02-27 11:12:13,788 - INFO - New best model saved with reward 2429.9
2025-02-27 11:12:16,453 - INFO - New best model saved with reward 2450.9
2025-02-27 11:12:23,496 - INFO - New best model saved with reward 2459.9
2025-02-27 11:12:26,054 - INFO - New best model saved with reward 2467.5
2025-02-27 11:12:28,546 - INFO - New best model saved with reward 2476.8
2025-02-27 11:12:33,463 - INFO - New best model saved with reward 2481.0
2025-02-27 11:12:35,385 - INFO - Epoch 2210/3000 | Reward: 2020.6 | Running reward: 2458.0 | Max tile: 128 | Exploration: 0.42
2025-02-27 11:12:53,375 - INFO - Epoch 2220/3000 | Reward: 2272.1 | Running reward: 2236.3 | Max tile: 128 | Exploration: 0.42
2025-02-27 11:13:11,379 - INFO - Epoch 2230/3000 | Reward: 1786.1 | Running reward: 2107.7 | Max tile: 128 | Exploration: 0.42
2025-02-27 11:13:27,889 - INFO - Epoch 2240/3000 | Reward: 1130.9 | Running reward: 1944.1 | Max tile: 64 | Exploration: 0.41
2025-02-27 11:13:47,828 - INFO - Epoch 2250/3000 | Reward: 2618.5 | Running reward: 2050.7 | Max tile: 256 | Exploration: 0.41
2025-02-27 11:14:09,269 - INFO - Epoch 2260/3000 | Reward: 2809.6 | Running reward: 2207.5 | Max tile: 128 | Exploration: 0.41
2025-02-27 11:14:29,308 - INFO - Epoch 2270/3000 | Reward: 2392.6 | Running reward: 2210.0 | Max tile: 256 | Exploration: 0.41
2025-02-27 11:14:52,539 - INFO - Epoch 2280/3000 | Reward: 2177.9 | Running reward: 2338.2 | Max tile: 128 | Exploration: 0.41
2025-02-27 11:15:13,205 - INFO - Epoch 2290/3000 | Reward: 2279.3 | Running reward: 2280.1 | Max tile: 128 | Exploration: 0.41
2025-02-27 11:15:31,100 - INFO - Epoch 2300/3000 | Reward: 1851.0 | Running reward: 2118.2 | Max tile: 128 | Exploration: 0.41
2025-02-27 11:15:48,821 - INFO - Epoch 2310/3000 | Reward: 1424.8 | Running reward: 2035.7 | Max tile: 64 | Exploration: 0.40
2025-02-27 11:16:05,585 - INFO - Epoch 2320/3000 | Reward: 1841.3 | Running reward: 1922.4 | Max tile: 128 | Exploration: 0.40
2025-02-27 11:16:25,696 - INFO - Epoch 2330/3000 | Reward: 2535.5 | Running reward: 2062.8 | Max tile: 128 | Exploration: 0.40
2025-02-27 11:16:48,949 - INFO - Epoch 2340/3000 | Reward: 2343.5 | Running reward: 2264.0 | Max tile: 128 | Exploration: 0.40
2025-02-27 11:17:12,342 - INFO - Epoch 2350/3000 | Reward: 2536.4 | Running reward: 2414.9 | Max tile: 256 | Exploration: 0.40
2025-02-27 11:17:31,384 - INFO - Epoch 2360/3000 | Reward: 1945.2 | Running reward: 2286.0 | Max tile: 128 | Exploration: 0.40
2025-02-27 11:17:48,126 - INFO - Epoch 2370/3000 | Reward: 2055.3 | Running reward: 2071.3 | Max tile: 128 | Exploration: 0.39
2025-02-27 11:18:05,769 - INFO - Epoch 2380/3000 | Reward: 1794.3 | Running reward: 1967.3 | Max tile: 128 | Exploration: 0.39
2025-02-27 11:18:24,767 - INFO - Epoch 2390/3000 | Reward: 1121.3 | Running reward: 1956.4 | Max tile: 64 | Exploration: 0.39
2025-02-27 11:18:41,599 - INFO - Epoch 2400/3000 | Reward: 2361.7 | Running reward: 1899.2 | Max tile: 128 | Exploration: 0.39
2025-02-27 11:19:02,689 - INFO - Epoch 2410/3000 | Reward: 3086.5 | Running reward: 2109.7 | Max tile: 256 | Exploration: 0.39
2025-02-27 11:19:23,327 - INFO - Epoch 2420/3000 | Reward: 1978.8 | Running reward: 2215.5 | Max tile: 128 | Exploration: 0.39
2025-02-27 11:19:45,415 - INFO - Epoch 2430/3000 | Reward: 2619.0 | Running reward: 2285.0 | Max tile: 128 | Exploration: 0.39
2025-02-27 11:20:07,440 - INFO - Epoch 2440/3000 | Reward: 1860.9 | Running reward: 2322.9 | Max tile: 128 | Exploration: 0.38
2025-02-27 11:20:26,663 - INFO - Epoch 2450/3000 | Reward: 1656.9 | Running reward: 2222.1 | Max tile: 64 | Exploration: 0.38
2025-02-27 11:20:44,572 - INFO - Epoch 2460/3000 | Reward: 1392.6 | Running reward: 2091.0 | Max tile: 64 | Exploration: 0.38
2025-02-27 11:21:01,151 - INFO - Epoch 2470/3000 | Reward: 1567.1 | Running reward: 1951.4 | Max tile: 128 | Exploration: 0.38
2025-02-27 11:21:20,234 - INFO - Epoch 2480/3000 | Reward: 2760.6 | Running reward: 2019.6 | Max tile: 256 | Exploration: 0.38
2025-02-27 11:21:41,547 - INFO - Epoch 2490/3000 | Reward: 2745.9 | Running reward: 2129.3 | Max tile: 128 | Exploration: 0.38
2025-02-27 11:22:03,820 - INFO - Epoch 2500/3000 | Reward: 2759.6 | Running reward: 2267.2 | Max tile: 128 | Exploration: 0.38
2025-02-27 11:22:25,710 - INFO - Epoch 2510/3000 | Reward: 2523.3 | Running reward: 2317.0 | Max tile: 128 | Exploration: 0.37
2025-02-27 11:22:47,094 - INFO - Epoch 2520/3000 | Reward: 1723.3 | Running reward: 2324.3 | Max tile: 128 | Exploration: 0.37
2025-02-27 11:23:04,670 - INFO - Epoch 2530/3000 | Reward: 2126.8 | Running reward: 2112.1 | Max tile: 128 | Exploration: 0.37
2025-02-27 11:23:21,636 - INFO - Epoch 2540/3000 | Reward: 1476.6 | Running reward: 1943.8 | Max tile: 64 | Exploration: 0.37
2025-02-27 11:23:39,816 - INFO - Epoch 2550/3000 | Reward: 1631.0 | Running reward: 1924.3 | Max tile: 64 | Exploration: 0.37
2025-02-27 11:24:01,754 - INFO - Epoch 2560/3000 | Reward: 2016.0 | Running reward: 2151.6 | Max tile: 128 | Exploration: 0.37
2025-02-27 11:24:23,439 - INFO - Epoch 2570/3000 | Reward: 2388.9 | Running reward: 2283.9 | Max tile: 128 | Exploration: 0.36
2025-02-27 11:24:45,599 - INFO - Epoch 2580/3000 | Reward: 1949.3 | Running reward: 2328.7 | Max tile: 128 | Exploration: 0.36
2025-02-27 11:25:07,115 - INFO - Epoch 2590/3000 | Reward: 1264.0 | Running reward: 2277.1 | Max tile: 64 | Exploration: 0.36
2025-02-27 11:25:24,907 - INFO - Epoch 2600/3000 | Reward: 1477.8 | Running reward: 2117.6 | Max tile: 64 | Exploration: 0.36
2025-02-27 11:25:41,948 - INFO - Epoch 2610/3000 | Reward: 1850.5 | Running reward: 1985.0 | Max tile: 128 | Exploration: 0.36
2025-02-27 11:25:59,110 - INFO - Epoch 2620/3000 | Reward: 1348.7 | Running reward: 1908.8 | Max tile: 64 | Exploration: 0.36
2025-02-27 11:26:18,270 - INFO - Epoch 2630/3000 | Reward: 1937.5 | Running reward: 1994.0 | Max tile: 64 | Exploration: 0.36
2025-02-27 11:26:37,960 - INFO - Epoch 2640/3000 | Reward: 3058.0 | Running reward: 2086.4 | Max tile: 128 | Exploration: 0.35
2025-02-27 11:26:59,826 - INFO - Epoch 2650/3000 | Reward: 2151.2 | Running reward: 2221.7 | Max tile: 128 | Exploration: 0.35
2025-02-27 11:27:21,714 - INFO - Epoch 2660/3000 | Reward: 1660.2 | Running reward: 2275.0 | Max tile: 128 | Exploration: 0.35
2025-02-27 11:27:41,312 - INFO - Epoch 2670/3000 | Reward: 1445.3 | Running reward: 2168.5 | Max tile: 128 | Exploration: 0.35
2025-02-27 11:27:59,855 - INFO - Epoch 2680/3000 | Reward: 1660.6 | Running reward: 2057.2 | Max tile: 64 | Exploration: 0.35
2025-02-27 11:28:19,808 - INFO - Epoch 2690/3000 | Reward: 1887.6 | Running reward: 2060.6 | Max tile: 128 | Exploration: 0.35
2025-02-27 11:28:41,132 - INFO - Epoch 2700/3000 | Reward: 2371.6 | Running reward: 2164.4 | Max tile: 128 | Exploration: 0.35
2025-02-27 11:29:05,267 - INFO - Epoch 2710/3000 | Reward: 3301.2 | Running reward: 2361.8 | Max tile: 256 | Exploration: 0.34
2025-02-27 11:29:27,842 - INFO - Epoch 2720/3000 | Reward: 2421.5 | Running reward: 2429.5 | Max tile: 128 | Exploration: 0.34
2025-02-27 11:29:47,975 - INFO - Epoch 2730/3000 | Reward: 2242.5 | Running reward: 2316.8 | Max tile: 128 | Exploration: 0.34
2025-02-27 11:30:06,843 - INFO - Epoch 2740/3000 | Reward: 1819.0 | Running reward: 2149.8 | Max tile: 128 | Exploration: 0.34
2025-02-27 11:30:22,935 - INFO - Epoch 2750/3000 | Reward: 1942.9 | Running reward: 1943.3 | Max tile: 128 | Exploration: 0.34
2025-02-27 11:30:37,951 - INFO - Epoch 2760/3000 | Reward: 1263.3 | Running reward: 1790.5 | Max tile: 64 | Exploration: 0.34
2025-02-27 11:31:00,496 - INFO - Epoch 2770/3000 | Reward: 2091.4 | Running reward: 2058.2 | Max tile: 128 | Exploration: 0.33
2025-02-27 11:31:22,563 - INFO - Epoch 2780/3000 | Reward: 3052.0 | Running reward: 2213.2 | Max tile: 256 | Exploration: 0.33
2025-02-27 11:31:44,043 - INFO - Epoch 2790/3000 | Reward: 2342.1 | Running reward: 2281.2 | Max tile: 128 | Exploration: 0.33
2025-02-27 11:32:06,795 - INFO - Epoch 2800/3000 | Reward: 3024.2 | Running reward: 2343.1 | Max tile: 256 | Exploration: 0.33
2025-02-27 11:32:25,348 - INFO - Epoch 2810/3000 | Reward: 2003.1 | Running reward: 2202.0 | Max tile: 128 | Exploration: 0.33
2025-02-27 11:32:43,888 - INFO - Epoch 2820/3000 | Reward: 1946.3 | Running reward: 2080.6 | Max tile: 128 | Exploration: 0.33
2025-02-27 11:33:01,645 - INFO - Epoch 2830/3000 | Reward: 1649.6 | Running reward: 1990.9 | Max tile: 128 | Exploration: 0.33
2025-02-27 11:33:21,364 - INFO - Epoch 2840/3000 | Reward: 2450.5 | Running reward: 2106.2 | Max tile: 256 | Exploration: 0.32
2025-02-27 11:33:42,852 - INFO - Epoch 2850/3000 | Reward: 2485.5 | Running reward: 2206.5 | Max tile: 128 | Exploration: 0.32
2025-02-27 11:34:04,885 - INFO - Epoch 2860/3000 | Reward: 2342.3 | Running reward: 2301.8 | Max tile: 128 | Exploration: 0.32
2025-02-27 11:34:25,158 - INFO - Epoch 2870/3000 | Reward: 1108.9 | Running reward: 2247.5 | Max tile: 64 | Exploration: 0.32
2025-02-27 11:34:45,555 - INFO - Epoch 2880/3000 | Reward: 2231.1 | Running reward: 2183.3 | Max tile: 256 | Exploration: 0.32
2025-02-27 11:35:02,467 - INFO - Epoch 2890/3000 | Reward: 1659.6 | Running reward: 2005.1 | Max tile: 64 | Exploration: 0.32
2025-02-27 11:35:19,358 - INFO - Epoch 2900/3000 | Reward: 1752.3 | Running reward: 1896.8 | Max tile: 128 | Exploration: 0.32
2025-02-27 11:35:39,539 - INFO - Epoch 2910/3000 | Reward: 2487.2 | Running reward: 2035.7 | Max tile: 128 | Exploration: 0.31
2025-02-27 11:36:02,924 - INFO - Epoch 2920/3000 | Reward: 2362.5 | Running reward: 2285.2 | Max tile: 128 | Exploration: 0.31
2025-02-27 11:36:26,115 - INFO - Epoch 2930/3000 | Reward: 2321.3 | Running reward: 2397.6 | Max tile: 128 | Exploration: 0.31
2025-02-27 11:36:47,657 - INFO - Epoch 2940/3000 | Reward: 1852.3 | Running reward: 2379.9 | Max tile: 64 | Exploration: 0.31
2025-02-27 11:37:07,808 - INFO - Epoch 2950/3000 | Reward: 1835.1 | Running reward: 2284.0 | Max tile: 128 | Exploration: 0.31
2025-02-27 11:37:25,500 - INFO - Epoch 2960/3000 | Reward: 1873.9 | Running reward: 2085.0 | Max tile: 128 | Exploration: 0.31
2025-02-27 11:37:42,393 - INFO - Epoch 2970/3000 | Reward: 1884.7 | Running reward: 1944.3 | Max tile: 128 | Exploration: 0.30
2025-02-27 11:38:01,302 - INFO - Epoch 2980/3000 | Reward: 2223.2 | Running reward: 1982.5 | Max tile: 128 | Exploration: 0.30
2025-02-27 11:38:23,741 - INFO - Epoch 2990/3000 | Reward: 2048.8 | Running reward: 2212.9 | Max tile: 128 | Exploration: 0.30
2025-02-27 11:38:48,189 - INFO - Epoch 3000/3000 | Reward: 3292.5 | Running reward: 2436.2 | Max tile: 256 | Exploration: 0.30
2025-02-27 11:38:48,190 - INFO - Training complete!
2025-02-27 11:38:48,190 - INFO - Best reward achieved: 2481.0
2025-02-27 11:38:48,190 - INFO - Highest tile achieved: 512
2025-02-27 11:38:48,196 - INFO - Running final evaluation
2025-02-27 11:38:48,530 - INFO - Game 1: Score = 444, Max Tile = 32
2025-02-27 11:38:49,076 - INFO - Game 2: Score = 1068, Max Tile = 128
2025-02-27 11:38:50,094 - INFO - Game 3: Score = 2320, Max Tile = 128
2025-02-27 11:38:51,631 - INFO - Game 4: Score = 3652, Max Tile = 256
2025-02-27 11:38:52,568 - INFO - Game 5: Score = 2116, Max Tile = 128
2025-02-27 11:38:52,988 - INFO - Game 6: Score = 692, Max Tile = 64
2025-02-27 11:38:53,615 - INFO - Game 7: Score = 1292, Max Tile = 128
2025-02-27 11:38:54,819 - INFO - Game 8: Score = 3032, Max Tile = 256
2025-02-27 11:38:56,286 - INFO - Game 9: Score = 3676, Max Tile = 256
2025-02-27 11:38:57,110 - INFO - Game 10: Score = 2032, Max Tile = 256
2025-02-27 11:38:57,685 - INFO - Game 11: Score = 1136, Max Tile = 128
2025-02-27 11:38:58,405 - INFO - Game 12: Score = 1220, Max Tile = 64
2025-02-27 11:38:59,162 - INFO - Game 13: Score = 1516, Max Tile = 128
2025-02-27 11:38:59,503 - INFO - Game 14: Score = 512, Max Tile = 64
2025-02-27 11:39:00,352 - INFO - Game 15: Score = 1764, Max Tile = 128
2025-02-27 11:39:00,616 - INFO - Game 16: Score = 296, Max Tile = 32
2025-02-27 11:39:01,449 - INFO - Game 17: Score = 1604, Max Tile = 128
2025-02-27 11:39:02,002 - INFO - Game 18: Score = 800, Max Tile = 64
2025-02-27 11:39:03,165 - INFO - Game 19: Score = 3092, Max Tile = 256
2025-02-27 11:39:03,783 - INFO - Game 20: Score = 1280, Max Tile = 128
2025-02-27 11:39:03,784 - INFO - ========================================
2025-02-27 11:39:03,784 - INFO - Evaluation over 20 games:
2025-02-27 11:39:03,784 - INFO - Average Score: 1677.2
2025-02-27 11:39:03,784 - INFO - Average Max Tile: 137.6
2025-02-27 11:39:03,785 - INFO - Best Max Tile: 256
2025-02-27 11:39:03,785 - INFO - Tile distribution:
2025-02-27 11:39:03,785 - INFO -   32: 2 games (10.0%)
2025-02-27 11:39:03,786 - INFO -   64: 4 games (20.0%)
2025-02-27 11:39:03,786 - INFO -   128: 9 games (45.0%)
2025-02-27 11:39:03,787 - INFO -   256: 5 games (25.0%)
2025-02-27 11:39:03,787 - INFO - Final best tile: 256
2025-02-27 11:45:54,226 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-27 11:45:54,227 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-27 11:45:54,227 - INFO - MCTS Simulations: 20
2025-02-27 11:45:54,228 - INFO - MCTS Temperature: 1.0
2025-02-27 11:45:54,228 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 11:45:54,228 - INFO - Learning rate: 0.0008
2025-02-27 11:45:54,228 - INFO - Device: cuda
2025-02-27 11:45:54,229 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 11:46:35,057 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-27 11:46:35,058 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-27 11:46:35,058 - INFO - MCTS Simulations: 20
2025-02-27 11:46:35,058 - INFO - MCTS Temperature: 1.0
2025-02-27 11:46:35,058 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 11:46:35,059 - INFO - Learning rate: 0.0008
2025-02-27 11:46:35,059 - INFO - Device: cuda
2025-02-27 11:46:35,059 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 11:46:35,161 - INFO - Resuming from epoch 2209
2025-02-27 11:46:35,161 - INFO - Running evaluation
2025-02-27 11:47:06,288 - INFO - Game 1: Score = 3000, Max Tile = 256
2025-02-27 11:47:28,666 - INFO - Game 2: Score = 2224, Max Tile = 256
2025-02-27 11:47:43,634 - INFO - Game 3: Score = 1116, Max Tile = 128
2025-02-27 11:48:02,315 - INFO - Game 4: Score = 1480, Max Tile = 128
2025-02-27 11:48:27,866 - INFO - Game 5: Score = 2520, Max Tile = 256
2025-02-27 11:48:53,974 - INFO - Game 6: Score = 2496, Max Tile = 256
2025-02-27 11:49:12,337 - INFO - Game 7: Score = 1252, Max Tile = 128
2025-02-27 11:49:41,247 - INFO - Game 8: Score = 2624, Max Tile = 256
2025-02-27 11:50:03,373 - INFO - Game 9: Score = 1580, Max Tile = 128
2025-02-27 11:50:26,388 - INFO - Game 10: Score = 1572, Max Tile = 128
2025-02-27 11:50:26,389 - INFO - ========================================
2025-02-27 11:50:26,389 - INFO - Evaluation over 10 games:
2025-02-27 11:50:26,390 - INFO - Average Score: 1986.4
2025-02-27 11:50:26,390 - INFO - Average Max Tile: 192.0
2025-02-27 11:50:26,390 - INFO - Best Max Tile: 256
2025-02-27 11:50:26,390 - INFO - Tile distribution:
2025-02-27 11:50:26,390 - INFO -   128: 5 games (50.0%)
2025-02-27 11:50:26,391 - INFO -   256: 5 games (50.0%)
2025-02-27 11:50:26,391 - INFO - Evaluation complete. Best tile: 256
2025-02-27 12:47:12,956 - INFO - === 2048 Enhanced Training/Evaluation ===
2025-02-27 12:47:12,957 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 12:47:12,957 - INFO - Learning rate: 0.0008
2025-02-27 12:47:12,957 - INFO - Device: cuda
2025-02-27 12:47:12,958 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 12:47:13,051 - INFO - Resuming from epoch 2209
2025-02-27 12:47:13,051 - INFO - Running evaluation
2025-02-27 12:47:13,059 - INFO - Comparing regular agent with MCTS agent (20 simulations)
2025-02-27 12:47:13,059 - INFO - Evaluating regular agent...
2025-02-27 12:47:14,091 - INFO - Game 1/5: Max Tile = 128, Score = 2032, Steps = 179
2025-02-27 12:47:14,805 - INFO - Game 2/5: Max Tile = 128, Score = 1556, Steps = 158
2025-02-27 12:47:15,537 - INFO - Game 3/5: Max Tile = 128, Score = 1696, Steps = 160
2025-02-27 12:47:16,040 - INFO - Game 4/5: Max Tile = 64, Score = 976, Steps = 112
2025-02-27 12:47:17,371 - INFO - Game 5/5: Max Tile = 256, Score = 3872, Steps = 303
2025-02-27 12:47:17,371 - INFO - ========================================
2025-02-27 12:47:17,372 - INFO - Evaluation over 5 games:
2025-02-27 12:47:17,372 - INFO - Average Max Tile: 140.8
2025-02-27 12:47:17,372 - INFO - Average Score: 2026.4
2025-02-27 12:47:17,372 - INFO - Average Steps: 182.4
2025-02-27 12:47:17,373 - INFO - Best Max Tile: 256
2025-02-27 12:47:17,373 - INFO - Tile distribution:
2025-02-27 12:47:17,373 - INFO -   64: 1 games (20.0%)
2025-02-27 12:47:17,374 - INFO -   128: 3 games (60.0%)
2025-02-27 12:47:17,374 - INFO -   256: 1 games (20.0%)
2025-02-27 12:47:17,374 - INFO - 
Evaluating MCTS agent...
2025-02-27 12:47:28,626 - INFO - Game 1/5: Max Tile = 64, Score = 672, Steps = 86
2025-02-27 12:47:56,153 - INFO - Game 2/5: Max Tile = 256, Score = 2888, Steps = 213
2025-02-27 12:48:12,236 - INFO - Game 3/5: Max Tile = 128, Score = 1276, Steps = 125
2025-02-27 12:48:25,073 - INFO - Game 4/5: Max Tile = 128, Score = 984, Steps = 99
2025-02-27 12:48:38,092 - INFO - Game 5/5: Max Tile = 128, Score = 984, Steps = 102
2025-02-27 12:48:38,092 - INFO - ========================================
2025-02-27 12:48:38,093 - INFO - Evaluation over 5 games:
2025-02-27 12:48:38,093 - INFO - Average Max Tile: 140.8
2025-02-27 12:48:38,093 - INFO - Average Score: 1360.8
2025-02-27 12:48:38,094 - INFO - Average Steps: 125.0
2025-02-27 12:48:38,094 - INFO - Best Max Tile: 256
2025-02-27 12:48:38,094 - INFO - Tile distribution:
2025-02-27 12:48:38,094 - INFO -   64: 1 games (20.0%)
2025-02-27 12:48:38,094 - INFO -   128: 3 games (60.0%)
2025-02-27 12:48:38,095 - INFO -   256: 1 games (20.0%)
2025-02-27 12:48:38,095 - INFO - 
==================================================
2025-02-27 12:48:38,095 - INFO - COMPARISON RESULTS:
2025-02-27 12:48:38,095 - INFO - Average Max Tile: Regular = 140.8, MCTS = 140.8
2025-02-27 12:48:38,096 - INFO - Average Score: Regular = 2026.4, MCTS = 1360.8
2025-02-27 12:48:38,096 - INFO - Best Max Tile: Regular = 256, MCTS = 256
2025-02-27 12:48:41,338 - INFO - Testing with 5 simulations...
2025-02-27 12:48:47,291 - INFO - Game 1/3: Max Tile = 256, Score = 2344, Steps = 189
2025-02-27 12:48:50,087 - INFO - Game 2/3: Max Tile = 64, Score = 684, Steps = 86
2025-02-27 12:48:57,300 - INFO - Game 3/3: Max Tile = 256, Score = 2924, Steps = 223
2025-02-27 12:48:57,301 - INFO - ========================================
2025-02-27 12:48:57,301 - INFO - Evaluation over 3 games:
2025-02-27 12:48:57,301 - INFO - Average Max Tile: 192.0
2025-02-27 12:48:57,302 - INFO - Average Score: 1984.0
2025-02-27 12:48:57,302 - INFO - Average Steps: 166.0
2025-02-27 12:48:57,302 - INFO - Best Max Tile: 256
2025-02-27 12:48:57,302 - INFO - Tile distribution:
2025-02-27 12:48:57,303 - INFO -   64: 1 games (33.3%)
2025-02-27 12:48:57,303 - INFO -   256: 2 games (66.7%)
2025-02-27 12:48:57,303 - INFO - Testing with 10 simulations...
2025-02-27 12:49:06,003 - INFO - Game 1/3: Max Tile = 128, Score = 1360, Steps = 138
2025-02-27 12:49:21,058 - INFO - Game 2/3: Max Tile = 256, Score = 2936, Steps = 224
2025-02-27 12:49:27,542 - INFO - Game 3/3: Max Tile = 64, Score = 692, Steps = 88
2025-02-27 12:49:27,543 - INFO - ========================================
2025-02-27 12:49:27,543 - INFO - Evaluation over 3 games:
2025-02-27 12:49:27,543 - INFO - Average Max Tile: 149.3
2025-02-27 12:49:27,544 - INFO - Average Score: 1662.7
2025-02-27 12:49:27,544 - INFO - Average Steps: 150.0
2025-02-27 12:49:27,544 - INFO - Best Max Tile: 256
2025-02-27 12:49:27,544 - INFO - Tile distribution:
2025-02-27 12:49:27,544 - INFO -   64: 1 games (33.3%)
2025-02-27 12:49:27,545 - INFO -   128: 1 games (33.3%)
2025-02-27 12:49:27,545 - INFO -   256: 1 games (33.3%)
2025-02-27 12:49:27,545 - INFO - Testing with 25 simulations...
2025-02-27 12:49:53,814 - INFO - Game 1/3: Max Tile = 128, Score = 1404, Steps = 140
2025-02-27 12:50:08,645 - INFO - Game 2/3: Max Tile = 64, Score = 616, Steps = 80
2025-02-27 12:50:32,986 - INFO - Game 3/3: Max Tile = 128, Score = 1304, Steps = 129
2025-02-27 12:50:32,987 - INFO - ========================================
2025-02-27 12:50:32,987 - INFO - Evaluation over 3 games:
2025-02-27 12:50:32,987 - INFO - Average Max Tile: 106.7
2025-02-27 12:50:32,988 - INFO - Average Score: 1108.0
2025-02-27 12:50:32,988 - INFO - Average Steps: 116.3
2025-02-27 12:50:32,988 - INFO - Best Max Tile: 128
2025-02-27 12:50:32,989 - INFO - Tile distribution:
2025-02-27 12:50:32,989 - INFO -   64: 1 games (33.3%)
2025-02-27 12:50:32,989 - INFO -   128: 2 games (66.7%)
2025-02-27 12:50:32,989 - INFO - Testing with 50 simulations...
2025-02-27 12:51:33,482 - INFO - Game 1/3: Max Tile = 128, Score = 1568, Steps = 143
2025-02-27 12:53:16,202 - INFO - Game 2/3: Max Tile = 256, Score = 3084, Steps = 239
2025-02-27 12:54:12,873 - INFO - Game 3/3: Max Tile = 256, Score = 1800, Steps = 134
2025-02-27 12:54:12,875 - INFO - ========================================
2025-02-27 12:54:12,875 - INFO - Evaluation over 3 games:
2025-02-27 12:54:12,876 - INFO - Average Max Tile: 213.3
2025-02-27 12:54:12,876 - INFO - Average Score: 2150.7
2025-02-27 12:54:12,876 - INFO - Average Steps: 172.0
2025-02-27 12:54:12,877 - INFO - Best Max Tile: 256
2025-02-27 12:54:12,877 - INFO - Tile distribution:
2025-02-27 12:54:12,877 - INFO -   128: 1 games (33.3%)
2025-02-27 12:54:12,878 - INFO -   256: 2 games (66.7%)
2025-02-27 12:56:41,753 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-27 12:56:41,753 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-27 12:56:41,754 - INFO - MCTS Simulations: 100
2025-02-27 12:56:41,754 - INFO - MCTS Temperature: 1.0
2025-02-27 12:56:41,755 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 12:56:41,755 - INFO - Learning rate: 0.0008
2025-02-27 12:56:41,755 - INFO - Device: cuda
2025-02-27 12:56:41,755 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 12:56:41,853 - INFO - Resuming from epoch 2209
2025-02-27 12:56:41,853 - INFO - Running evaluation
2025-02-27 13:00:23,405 - INFO - Game 1: Score = 3072, Max Tile = 256
2025-02-27 13:03:57,744 - INFO - Game 2: Score = 3056, Max Tile = 256
2025-02-27 13:07:43,026 - INFO - Game 3: Score = 3116, Max Tile = 256
2025-02-27 13:11:37,072 - INFO - Game 4: Score = 4156, Max Tile = 512
2025-02-27 13:17:58,774 - INFO - Game 5: Score = 6772, Max Tile = 512
2025-02-27 13:23:30,734 - INFO - Game 6: Score = 5400, Max Tile = 512
2025-02-27 13:26:42,704 - INFO - Game 7: Score = 2708, Max Tile = 256
2025-02-27 13:30:32,695 - INFO - Game 8: Score = 3664, Max Tile = 256
2025-02-27 13:34:56,650 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-27 13:34:56,650 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-27 13:34:56,650 - INFO - MCTS Simulations: 100
2025-02-27 13:34:56,651 - INFO - MCTS Temperature: 1.0
2025-02-27 13:34:56,651 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 13:34:56,651 - INFO - Learning rate: 0.0008
2025-02-27 13:34:56,651 - INFO - Device: cuda
2025-02-27 13:34:56,652 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 13:34:56,749 - INFO - Resuming from epoch 2209
2025-02-27 13:34:56,750 - INFO - Running evaluation
2025-02-27 13:45:08,770 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-27 13:45:08,770 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-27 13:45:08,771 - INFO - MCTS Simulations: 200
2025-02-27 13:45:08,771 - INFO - MCTS Temperature: 1.0
2025-02-27 13:45:08,771 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 13:45:08,772 - INFO - Learning rate: 0.0008
2025-02-27 13:45:08,772 - INFO - Device: cuda
2025-02-27 13:45:08,772 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 13:45:08,868 - INFO - Resuming from epoch 2209
2025-02-27 13:45:08,868 - INFO - Running evaluation
2025-02-27 14:08:57,898 - INFO - Game 1: Score = 7764, Max Tile = 512
2025-02-27 15:00:20,101 - INFO - Game 2: Score = 15824, Max Tile = 1024
2025-02-27 15:04:32,850 - INFO - Game 3: Score = 1276, Max Tile = 128
2025-02-27 15:46:17,603 - INFO - Game 4: Score = 13820, Max Tile = 1024
2025-02-27 16:24:30,997 - INFO - Game 5: Score = 12224, Max Tile = 1024
2025-02-27 16:44:53,509 - INFO - Game 6: Score = 7052, Max Tile = 512
2025-02-27 17:25:35,245 - INFO - Game 7: Score = 12652, Max Tile = 1024
2025-02-27 18:11:58,213 - INFO - === 2048 Enhanced Training/Evaluation ===
2025-02-27 18:11:58,213 - INFO - Training for 2000 epochs with batch size 96
2025-02-27 18:11:58,214 - INFO - Learning rate: 0.0008
2025-02-27 18:11:58,214 - INFO - Device: cuda
2025-02-27 18:11:58,214 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-27 18:11:58,310 - INFO - Resuming from epoch 2209
2025-02-27 18:11:58,310 - INFO - Running evaluation
2025-02-27 18:11:58,319 - INFO - Comparing regular agent with MCTS agent (20 simulations)
2025-02-27 18:11:58,319 - INFO - Evaluating regular agent...
2025-02-27 18:11:58,320 - INFO - Starting game 1/5
2025-02-27 18:11:58,512 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:11:58,536 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:11:58,551 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:11:58,620 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:11:58,727 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:11:59,260 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:11:59,369 - INFO - Game 1/5 completed: Score = 2032, Max Tile = 128, Steps = 179
2025-02-27 18:11:59,370 - INFO - Starting game 2/5
2025-02-27 18:11:59,374 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:11:59,398 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:11:59,456 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:11:59,521 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:11:59,642 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:11:59,698 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:12:00,107 - INFO - Game 2/5 completed: Score = 1556, Max Tile = 128, Steps = 158
2025-02-27 18:12:00,107 - INFO - Starting game 3/5
2025-02-27 18:12:00,113 - INFO - Game 3: New maximum tile achieved: 4
2025-02-27 18:12:00,127 - INFO - Game 3: New maximum tile achieved: 8
2025-02-27 18:12:00,190 - INFO - Game 3: New maximum tile achieved: 16
2025-02-27 18:12:00,209 - INFO - Game 3: New maximum tile achieved: 32
2025-02-27 18:12:00,334 - INFO - Game 3: New maximum tile achieved: 64
2025-02-27 18:12:00,526 - INFO - Game 3: New maximum tile achieved: 128
2025-02-27 18:12:00,855 - INFO - Game 3/5 completed: Score = 1696, Max Tile = 128, Steps = 160
2025-02-27 18:12:00,855 - INFO - Starting game 4/5
2025-02-27 18:12:00,860 - INFO - Game 4: New maximum tile achieved: 2
2025-02-27 18:12:00,865 - INFO - Game 4: New maximum tile achieved: 4
2025-02-27 18:12:00,884 - INFO - Game 4: New maximum tile achieved: 8
2025-02-27 18:12:00,898 - INFO - Game 4: New maximum tile achieved: 16
2025-02-27 18:12:00,952 - INFO - Game 4: New maximum tile achieved: 32
2025-02-27 18:12:01,091 - INFO - Game 4: New maximum tile achieved: 64
2025-02-27 18:12:01,347 - INFO - Game 4/5 completed: Score = 976, Max Tile = 64, Steps = 112
2025-02-27 18:12:01,348 - INFO - Starting game 5/5
2025-02-27 18:12:01,353 - INFO - Game 5: New maximum tile achieved: 2
2025-02-27 18:12:01,357 - INFO - Game 5: New maximum tile achieved: 4
2025-02-27 18:12:01,389 - INFO - Game 5: New maximum tile achieved: 8
2025-02-27 18:12:01,437 - INFO - Game 5: New maximum tile achieved: 16
2025-02-27 18:12:01,563 - INFO - Game 5: New maximum tile achieved: 32
2025-02-27 18:12:01,580 - INFO - Game 5: New maximum tile achieved: 64
2025-02-27 18:12:01,800 - INFO - Game 5: New maximum tile achieved: 128
2025-02-27 18:12:02,108 - INFO - Game 5: New maximum tile achieved: 256
2025-02-27 18:12:02,683 - INFO - Game 5/5 completed: Score = 3872, Max Tile = 256, Steps = 303
2025-02-27 18:12:02,684 - INFO - ========================================
2025-02-27 18:12:02,684 - INFO - Evaluation over 5 games:
2025-02-27 18:12:02,684 - INFO - Average Max Tile: 140.8
2025-02-27 18:12:02,685 - INFO - Average Score: 2026.4
2025-02-27 18:12:02,685 - INFO - Average Steps: 182.4
2025-02-27 18:12:02,686 - INFO - Best Max Tile: 256
2025-02-27 18:12:02,686 - INFO - Tile distribution:
2025-02-27 18:12:02,686 - INFO -   64: 1 games (20.0%)
2025-02-27 18:12:02,686 - INFO -   128: 3 games (60.0%)
2025-02-27 18:12:02,686 - INFO -   256: 1 games (20.0%)
2025-02-27 18:12:02,686 - INFO - Average steps to achieve tile:
2025-02-27 18:12:02,687 - INFO -   16: 13.6 steps
2025-02-27 18:12:02,687 - INFO -   32: 28.4 steps
2025-02-27 18:12:02,687 - INFO -   64: 51.2 steps
2025-02-27 18:12:02,687 - INFO -   128: 104.2 steps
2025-02-27 18:12:02,687 - INFO -   256: 173.0 steps
2025-02-27 18:12:02,688 - INFO - 
Evaluating MCTS agent...
2025-02-27 18:12:02,688 - INFO - Starting game 1/5
2025-02-27 18:12:02,829 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:12:03,078 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:12:04,909 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:12:07,652 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:12:09,552 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:12:15,592 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:12:25,407 - INFO - Game 1/5 completed: Score = 1760, Max Tile = 128, Steps = 155
2025-02-27 18:12:25,407 - INFO - Starting game 2/5
2025-02-27 18:12:25,551 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:12:25,981 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:12:27,729 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:12:28,851 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:12:33,157 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:12:37,298 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:12:37,740 - INFO - Game 2/5 completed: Score = 864, Max Tile = 128, Steps = 84
2025-02-27 18:12:37,741 - INFO - Starting game 3/5
2025-02-27 18:12:37,884 - INFO - Game 3: New maximum tile achieved: 2
2025-02-27 18:12:38,026 - INFO - Game 3: New maximum tile achieved: 4
2025-02-27 18:12:38,723 - INFO - Game 3: New maximum tile achieved: 8
2025-02-27 18:12:39,585 - INFO - Game 3: New maximum tile achieved: 16
2025-02-27 18:12:42,419 - INFO - Game 3: New maximum tile achieved: 32
2025-02-27 18:12:47,015 - INFO - Game 3: New maximum tile achieved: 64
2025-02-27 18:12:51,528 - INFO - Game 3: New maximum tile achieved: 128
2025-02-27 18:12:59,674 - INFO - Game 3: New maximum tile achieved: 256
2025-02-27 18:13:14,427 - INFO - Game 3: New maximum tile achieved: 512
2025-02-27 18:13:18,871 - INFO - Game 3/5 completed: Score = 4092, Max Tile = 512, Steps = 250
2025-02-27 18:13:18,871 - INFO - Starting game 4/5
2025-02-27 18:13:19,017 - INFO - Game 4: New maximum tile achieved: 2
2025-02-27 18:13:19,159 - INFO - Game 4: New maximum tile achieved: 4
2025-02-27 18:13:19,587 - INFO - Game 4: New maximum tile achieved: 8
2025-02-27 18:13:20,435 - INFO - Game 4: New maximum tile achieved: 16
2025-02-27 18:13:23,840 - INFO - Game 4: New maximum tile achieved: 32
2025-02-27 18:13:24,595 - INFO - Game 4: New maximum tile achieved: 64
2025-02-27 18:13:28,718 - INFO - Game 4: New maximum tile achieved: 128
2025-02-27 18:13:40,368 - INFO - Game 4/5 completed: Score = 1584, Max Tile = 128, Steps = 148
2025-02-27 18:13:40,369 - INFO - Starting game 5/5
2025-02-27 18:13:40,515 - INFO - Game 5: New maximum tile achieved: 4
2025-02-27 18:13:40,959 - INFO - Game 5: New maximum tile achieved: 8
2025-02-27 18:13:42,572 - INFO - Game 5: New maximum tile achieved: 16
2025-02-27 18:13:43,807 - INFO - Game 5: New maximum tile achieved: 32
2025-02-27 18:13:48,072 - INFO - Game 5: New maximum tile achieved: 64
2025-02-27 18:13:51,311 - INFO - Game 5: New maximum tile achieved: 128
2025-02-27 18:14:02,604 - INFO - Game 5/5 completed: Score = 1564, Max Tile = 128, Steps = 149
2025-02-27 18:14:02,604 - INFO - ========================================
2025-02-27 18:14:02,605 - INFO - Evaluation over 5 games:
2025-02-27 18:14:02,605 - INFO - Average Max Tile: 204.8
2025-02-27 18:14:02,605 - INFO - Average Score: 1972.8
2025-02-27 18:14:02,606 - INFO - Average Steps: 157.2
2025-02-27 18:14:02,606 - INFO - Best Max Tile: 512
2025-02-27 18:14:02,606 - INFO - Tile distribution:
2025-02-27 18:14:02,606 - INFO -   128: 4 games (80.0%)
2025-02-27 18:14:02,607 - INFO -   512: 1 games (20.0%)
2025-02-27 18:14:02,607 - INFO - Average steps to achieve tile:
2025-02-27 18:14:02,607 - INFO -   16: 13.2 steps
2025-02-27 18:14:02,607 - INFO -   32: 29.0 steps
2025-02-27 18:14:02,608 - INFO -   64: 50.2 steps
2025-02-27 18:14:02,608 - INFO -   128: 80.0 steps
2025-02-27 18:14:02,608 - INFO -   256: 148.0 steps
2025-02-27 18:14:02,608 - INFO -   512: 229.0 steps
2025-02-27 18:14:02,608 - INFO - 
==================================================
2025-02-27 18:14:02,609 - INFO - COMPARISON RESULTS:
2025-02-27 18:14:02,609 - INFO - Average Max Tile: Regular = 140.8, MCTS = 204.8
2025-02-27 18:14:02,609 - INFO - Average Score: Regular = 2026.4, MCTS = 1972.8
2025-02-27 18:14:02,609 - INFO - Best Max Tile: Regular = 256, MCTS = 512
2025-02-27 18:14:03,006 - INFO - Testing with 5 simulations...
2025-02-27 18:14:03,007 - INFO - Starting game 1/2
2025-02-27 18:14:03,049 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:14:03,132 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:14:03,507 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:14:03,661 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:14:05,053 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:14:06,160 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:14:08,383 - INFO - Game 1/2 completed: Score = 1388, Max Tile = 128, Steps = 137
2025-02-27 18:14:08,384 - INFO - Starting game 2/2
2025-02-27 18:14:08,420 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:14:08,547 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:14:08,741 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:14:09,436 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:14:10,501 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:14:12,380 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:14:13,202 - INFO - Game 2/2 completed: Score = 1264, Max Tile = 128, Steps = 126
2025-02-27 18:14:13,203 - INFO - ========================================
2025-02-27 18:14:13,203 - INFO - Evaluation over 2 games:
2025-02-27 18:14:13,203 - INFO - Average Max Tile: 128.0
2025-02-27 18:14:13,204 - INFO - Average Score: 1326.0
2025-02-27 18:14:13,204 - INFO - Average Steps: 131.5
2025-02-27 18:14:13,204 - INFO - Best Max Tile: 128
2025-02-27 18:14:13,204 - INFO - Tile distribution:
2025-02-27 18:14:13,205 - INFO -   128: 2 games (100.0%)
2025-02-27 18:14:13,205 - INFO - Average steps to achieve tile:
2025-02-27 18:14:13,205 - INFO -   16: 10.0 steps
2025-02-27 18:14:13,206 - INFO -   32: 21.5 steps
2025-02-27 18:14:13,206 - INFO -   64: 53.5 steps
2025-02-27 18:14:13,206 - INFO -   128: 91.5 steps
2025-02-27 18:14:13,206 - INFO - Testing with 10 simulations...
2025-02-27 18:14:13,207 - INFO - Starting game 1/2
2025-02-27 18:14:13,281 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:14:13,560 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:14:14,114 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:14:14,731 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:14:16,746 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:14:19,894 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:14:23,285 - INFO - Game 1/2 completed: Score = 1408, Max Tile = 128, Steps = 138
2025-02-27 18:14:23,286 - INFO - Starting game 2/2
2025-02-27 18:14:23,364 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:14:23,714 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:14:24,333 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:14:25,115 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:14:27,116 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:14:29,033 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:14:31,588 - INFO - Game 2/2 completed: Score = 1068, Max Tile = 128, Steps = 112
2025-02-27 18:14:31,589 - INFO - ========================================
2025-02-27 18:14:31,589 - INFO - Evaluation over 2 games:
2025-02-27 18:14:31,589 - INFO - Average Max Tile: 128.0
2025-02-27 18:14:31,590 - INFO - Average Score: 1238.0
2025-02-27 18:14:31,590 - INFO - Average Steps: 125.0
2025-02-27 18:14:31,591 - INFO - Best Max Tile: 128
2025-02-27 18:14:31,591 - INFO - Tile distribution:
2025-02-27 18:14:31,591 - INFO -   128: 2 games (100.0%)
2025-02-27 18:14:31,592 - INFO - Average steps to achieve tile:
2025-02-27 18:14:31,592 - INFO -   16: 13.0 steps
2025-02-27 18:14:31,592 - INFO -   32: 22.5 steps
2025-02-27 18:14:31,592 - INFO -   64: 49.5 steps
2025-02-27 18:14:31,592 - INFO -   128: 83.5 steps
2025-02-27 18:14:31,593 - INFO - Testing with 25 simulations...
2025-02-27 18:14:31,593 - INFO - Starting game 1/2
2025-02-27 18:14:31,783 - INFO - Game 1: New maximum tile achieved: 2
2025-02-27 18:14:31,978 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:14:32,614 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:14:34,115 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:14:36,377 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:14:37,703 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:14:52,879 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:15:01,589 - INFO - Game 1/2 completed: Score = 1668, Max Tile = 128, Steps = 157
2025-02-27 18:15:01,590 - INFO - Starting game 2/2
2025-02-27 18:15:01,768 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:15:02,496 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:15:03,394 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:15:05,362 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:15:09,541 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:15:22,585 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:15:28,823 - INFO - Game 2/2 completed: Score = 1428, Max Tile = 128, Steps = 142
2025-02-27 18:15:28,824 - INFO - ========================================
2025-02-27 18:15:28,824 - INFO - Evaluation over 2 games:
2025-02-27 18:15:28,824 - INFO - Average Max Tile: 128.0
2025-02-27 18:15:28,824 - INFO - Average Score: 1548.0
2025-02-27 18:15:28,824 - INFO - Average Steps: 149.5
2025-02-27 18:15:28,825 - INFO - Best Max Tile: 128
2025-02-27 18:15:28,825 - INFO - Tile distribution:
2025-02-27 18:15:28,825 - INFO -   128: 2 games (100.0%)
2025-02-27 18:15:28,825 - INFO - Average steps to achieve tile:
2025-02-27 18:15:28,825 - INFO -   16: 10.5 steps
2025-02-27 18:15:28,826 - INFO -   32: 22.0 steps
2025-02-27 18:15:28,826 - INFO -   64: 36.5 steps
2025-02-27 18:15:28,826 - INFO -   128: 109.0 steps
2025-02-27 18:15:28,826 - INFO - Testing with 50 simulations...
2025-02-27 18:15:28,827 - INFO - Starting game 1/2
2025-02-27 18:15:29,231 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:15:29,622 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:15:33,210 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:15:38,103 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:15:45,993 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:16:03,133 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:16:24,402 - INFO - Game 1: New maximum tile achieved: 256
2025-02-27 18:17:29,820 - INFO - Game 1: New maximum tile achieved: 512
2025-02-27 18:17:44,468 - INFO - Game 1/2 completed: Score = 4468, Max Tile = 512, Steps = 283
2025-02-27 18:17:44,469 - INFO - Starting game 2/2
2025-02-27 18:17:44,853 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:17:45,986 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:17:50,559 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:17:55,622 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:17:59,205 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:18:20,274 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:18:45,104 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 18:19:31,796 - INFO - Game 2: New maximum tile achieved: 512
2025-02-27 18:21:11,019 - INFO - Game 2/2 completed: Score = 6160, Max Tile = 512, Steps = 389
2025-02-27 18:21:11,019 - INFO - ========================================
2025-02-27 18:21:11,020 - INFO - Evaluation over 2 games:
2025-02-27 18:21:11,020 - INFO - Average Max Tile: 512.0
2025-02-27 18:21:11,021 - INFO - Average Score: 5314.0
2025-02-27 18:21:11,021 - INFO - Average Steps: 336.0
2025-02-27 18:21:11,021 - INFO - Best Max Tile: 512
2025-02-27 18:21:11,021 - INFO - Tile distribution:
2025-02-27 18:21:11,021 - INFO -   512: 2 games (100.0%)
2025-02-27 18:21:11,022 - INFO - Average steps to achieve tile:
2025-02-27 18:21:11,022 - INFO -   16: 12.5 steps
2025-02-27 18:21:11,022 - INFO -   32: 25.0 steps
2025-02-27 18:21:11,022 - INFO -   64: 39.0 steps
2025-02-27 18:21:11,023 - INFO -   128: 85.0 steps
2025-02-27 18:21:11,023 - INFO -   256: 139.5 steps
2025-02-27 18:21:11,023 - INFO -   512: 249.0 steps
2025-02-27 18:21:11,023 - INFO - Testing with 100 simulations...
2025-02-27 18:21:11,024 - INFO - Starting game 1/2
2025-02-27 18:21:11,912 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:21:15,449 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:21:18,156 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:21:28,956 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:21:47,843 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:22:24,391 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:23:21,083 - INFO - Game 1: New maximum tile achieved: 256
2025-02-27 18:26:05,086 - INFO - Game 1: New maximum tile achieved: 512
2025-02-27 18:29:27,223 - INFO - Game 1/2 completed: Score = 6508, Max Tile = 512, Steps = 418
2025-02-27 18:29:27,225 - INFO - Starting game 2/2
2025-02-27 18:29:28,162 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 18:29:29,071 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 18:29:38,002 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 18:29:51,752 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 18:30:10,027 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 18:30:35,115 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 18:31:33,895 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 18:33:50,498 - INFO - Game 2: New maximum tile achieved: 512
2025-02-27 18:39:21,433 - INFO - Game 2: New maximum tile achieved: 1024
2025-02-27 18:50:29,184 - INFO - Game 2/2 completed: Score = 14220, Max Tile = 1024, Steps = 787
2025-02-27 18:50:29,184 - INFO - ========================================
2025-02-27 18:50:29,185 - INFO - Evaluation over 2 games:
2025-02-27 18:50:29,185 - INFO - Average Max Tile: 768.0
2025-02-27 18:50:29,185 - INFO - Average Score: 10364.0
2025-02-27 18:50:29,185 - INFO - Average Steps: 602.5
2025-02-27 18:50:29,186 - INFO - Best Max Tile: 1024
2025-02-27 18:50:29,186 - INFO - Tile distribution:
2025-02-27 18:50:29,186 - INFO -   512: 1 games (50.0%)
2025-02-27 18:50:29,186 - INFO -   1024: 1 games (50.0%)
2025-02-27 18:50:29,186 - INFO - Average steps to achieve tile:
2025-02-27 18:50:29,187 - INFO -   16: 9.0 steps
2025-02-27 18:50:29,187 - INFO -   32: 22.5 steps
2025-02-27 18:50:29,187 - INFO -   64: 42.5 steps
2025-02-27 18:50:29,187 - INFO -   128: 75.5 steps
2025-02-27 18:50:29,187 - INFO -   256: 136.5 steps
2025-02-27 18:50:29,188 - INFO -   512: 267.0 steps
2025-02-27 18:50:29,188 - INFO -   1024: 470.0 steps
2025-02-27 18:50:29,188 - INFO - Testing with 200 simulations...
2025-02-27 18:50:29,189 - INFO - Starting game 1/2
2025-02-27 18:50:31,040 - INFO - Game 1: New maximum tile achieved: 2
2025-02-27 18:50:33,081 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 18:50:40,984 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 18:50:48,904 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 18:51:26,830 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 18:51:50,968 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 18:53:09,953 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 18:55:33,379 - INFO - Game 1: New maximum tile achieved: 256
2025-02-27 19:01:14,920 - INFO - Game 1: New maximum tile achieved: 512
2025-02-27 19:12:41,117 - INFO - Game 1: New maximum tile achieved: 1024
2025-02-27 19:28:03,048 - INFO - Game 1/2 completed: Score = 12268, Max Tile = 1024, Steps = 684
2025-02-27 19:28:03,048 - INFO - Starting game 2/2
2025-02-27 19:28:05,095 - INFO - Game 2: New maximum tile achieved: 2
2025-02-27 19:28:07,190 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 19:28:16,737 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 19:28:22,557 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 19:28:41,835 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 19:29:33,647 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 19:30:41,570 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 19:33:46,472 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 19:38:39,347 - INFO - Game 2: New maximum tile achieved: 512
2025-02-27 19:52:51,242 - INFO - Game 2: New maximum tile achieved: 1024
2025-02-27 20:00:49,344 - INFO - Game 2/2 completed: Score = 11484, Max Tile = 1024, Steps = 633
2025-02-27 20:00:49,345 - INFO - ========================================
2025-02-27 20:00:49,345 - INFO - Evaluation over 2 games:
2025-02-27 20:00:49,345 - INFO - Average Max Tile: 1024.0
2025-02-27 20:00:49,345 - INFO - Average Score: 11876.0
2025-02-27 20:00:49,345 - INFO - Average Steps: 658.5
2025-02-27 20:00:49,346 - INFO - Best Max Tile: 1024
2025-02-27 20:00:49,346 - INFO - Tile distribution:
2025-02-27 20:00:49,346 - INFO -   1024: 2 games (100.0%)
2025-02-27 20:00:49,346 - INFO - Average steps to achieve tile:
2025-02-27 20:00:49,347 - INFO -   16: 9.0 steps
2025-02-27 20:00:49,347 - INFO -   32: 23.5 steps
2025-02-27 20:00:49,347 - INFO -   64: 42.5 steps
2025-02-27 20:00:49,347 - INFO -   128: 78.5 steps
2025-02-27 20:00:49,347 - INFO -   256: 156.5 steps
2025-02-27 20:00:49,348 - INFO -   512: 279.5 steps
2025-02-27 20:00:49,348 - INFO -   1024: 502.0 steps
2025-02-27 20:00:49,357 - INFO - Testing with temperature 0.1...
2025-02-27 20:00:49,357 - INFO - Starting game 1/2
2025-02-27 20:00:49,515 - INFO - Game 1: New maximum tile achieved: 2
2025-02-27 20:00:49,835 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 20:00:50,158 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 20:00:51,484 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 20:00:53,991 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 20:00:59,538 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 20:01:00,685 - INFO - Game 1/2 completed: Score = 536, Max Tile = 64, Steps = 73
2025-02-27 20:01:00,685 - INFO - Starting game 2/2
2025-02-27 20:01:00,835 - INFO - Game 2: New maximum tile achieved: 2
2025-02-27 20:01:00,963 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 20:01:01,669 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 20:01:02,485 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 20:01:03,036 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 20:01:09,410 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 20:01:15,133 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 20:01:23,512 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 20:01:36,818 - INFO - Game 2/2 completed: Score = 2664, Max Tile = 256, Steps = 214
2025-02-27 20:01:36,819 - INFO - ========================================
2025-02-27 20:01:36,819 - INFO - Evaluation over 2 games:
2025-02-27 20:01:36,819 - INFO - Average Max Tile: 160.0
2025-02-27 20:01:36,820 - INFO - Average Score: 1600.0
2025-02-27 20:01:36,820 - INFO - Average Steps: 143.5
2025-02-27 20:01:36,820 - INFO - Best Max Tile: 256
2025-02-27 20:01:36,820 - INFO - Tile distribution:
2025-02-27 20:01:36,820 - INFO -   64: 1 games (50.0%)
2025-02-27 20:01:36,821 - INFO -   256: 1 games (50.0%)
2025-02-27 20:01:36,821 - INFO - Average steps to achieve tile:
2025-02-27 20:01:36,821 - INFO -   16: 12.0 steps
2025-02-27 20:01:36,821 - INFO -   32: 22.0 steps
2025-02-27 20:01:36,821 - INFO -   64: 61.0 steps
2025-02-27 20:01:36,821 - INFO -   128: 96.0 steps
2025-02-27 20:01:36,822 - INFO -   256: 146.0 steps
2025-02-27 20:01:36,822 - INFO - Testing with temperature 0.5...
2025-02-27 20:01:36,822 - INFO - Starting game 1/2
2025-02-27 20:01:37,003 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 20:01:37,667 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 20:01:38,974 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 20:01:39,438 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 20:01:42,709 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 20:01:51,909 - INFO - Game 1/2 completed: Score = 756, Max Tile = 64, Steps = 94
2025-02-27 20:01:51,910 - INFO - Starting game 2/2
2025-02-27 20:01:52,082 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 20:01:52,439 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 20:01:54,158 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 20:01:54,942 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 20:01:58,784 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 20:02:06,626 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 20:02:12,449 - INFO - Game 2/2 completed: Score = 1300, Max Tile = 128, Steps = 127
2025-02-27 20:02:12,449 - INFO - ========================================
2025-02-27 20:02:12,450 - INFO - Evaluation over 2 games:
2025-02-27 20:02:12,450 - INFO - Average Max Tile: 96.0
2025-02-27 20:02:12,451 - INFO - Average Score: 1028.0
2025-02-27 20:02:12,451 - INFO - Average Steps: 110.5
2025-02-27 20:02:12,451 - INFO - Best Max Tile: 128
2025-02-27 20:02:12,451 - INFO - Tile distribution:
2025-02-27 20:02:12,452 - INFO -   64: 1 games (50.0%)
2025-02-27 20:02:12,452 - INFO -   128: 1 games (50.0%)
2025-02-27 20:02:12,452 - INFO - Average steps to achieve tile:
2025-02-27 20:02:12,452 - INFO -   16: 12.5 steps
2025-02-27 20:02:12,452 - INFO -   32: 16.5 steps
2025-02-27 20:02:12,452 - INFO -   64: 39.0 steps
2025-02-27 20:02:12,452 - INFO -   128: 90.0 steps
2025-02-27 20:02:12,453 - INFO - Testing with temperature 1.0...
2025-02-27 20:02:12,453 - INFO - Starting game 1/2
2025-02-27 20:02:12,616 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 20:02:12,776 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 20:02:13,707 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 20:02:16,323 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 20:02:22,200 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 20:02:26,132 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 20:02:37,293 - INFO - Game 1: New maximum tile achieved: 256
2025-02-27 20:02:41,524 - INFO - Game 1/2 completed: Score = 2140, Max Tile = 256, Steps = 175
2025-02-27 20:02:41,524 - INFO - Starting game 2/2
2025-02-27 20:02:41,683 - INFO - Game 2: New maximum tile achieved: 2
2025-02-27 20:02:41,995 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 20:02:42,462 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 20:02:44,164 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 20:02:45,905 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 20:02:50,247 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 20:02:56,956 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 20:03:08,677 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 20:03:12,212 - INFO - Game 2/2 completed: Score = 2356, Max Tile = 256, Steps = 186
2025-02-27 20:03:12,213 - INFO - ========================================
2025-02-27 20:03:12,213 - INFO - Evaluation over 2 games:
2025-02-27 20:03:12,214 - INFO - Average Max Tile: 256.0
2025-02-27 20:03:12,214 - INFO - Average Score: 2248.0
2025-02-27 20:03:12,214 - INFO - Average Steps: 180.5
2025-02-27 20:03:12,214 - INFO - Best Max Tile: 256
2025-02-27 20:03:12,215 - INFO - Tile distribution:
2025-02-27 20:03:12,215 - INFO -   256: 2 games (100.0%)
2025-02-27 20:03:12,215 - INFO - Average steps to achieve tile:
2025-02-27 20:03:12,215 - INFO -   16: 11.5 steps
2025-02-27 20:03:12,215 - INFO -   32: 25.5 steps
2025-02-27 20:03:12,216 - INFO -   64: 57.0 steps
2025-02-27 20:03:12,216 - INFO -   128: 89.5 steps
2025-02-27 20:03:12,216 - INFO -   256: 159.5 steps
2025-02-27 20:03:12,216 - INFO - Testing with temperature 1.5...
2025-02-27 20:03:12,217 - INFO - Starting game 1/2
2025-02-27 20:03:12,368 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 20:03:13,270 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 20:03:14,397 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 20:03:16,621 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 20:03:22,852 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 20:03:28,166 - INFO - Game 1: New maximum tile achieved: 128
2025-02-27 20:03:36,299 - INFO - Game 1: New maximum tile achieved: 256
2025-02-27 20:03:48,469 - INFO - Game 1/2 completed: Score = 2704, Max Tile = 256, Steps = 209
2025-02-27 20:03:48,469 - INFO - Starting game 2/2
2025-02-27 20:03:48,620 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 20:03:49,230 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 20:03:49,700 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 20:03:53,880 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 20:03:59,923 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 20:04:01,265 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 20:04:11,423 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 20:04:19,879 - INFO - Game 2/2 completed: Score = 2304, Max Tile = 256, Steps = 185
2025-02-27 20:04:19,880 - INFO - ========================================
2025-02-27 20:04:19,880 - INFO - Evaluation over 2 games:
2025-02-27 20:04:19,881 - INFO - Average Max Tile: 256.0
2025-02-27 20:04:19,881 - INFO - Average Score: 2504.0
2025-02-27 20:04:19,881 - INFO - Average Steps: 197.0
2025-02-27 20:04:19,881 - INFO - Best Max Tile: 256
2025-02-27 20:04:19,881 - INFO - Tile distribution:
2025-02-27 20:04:19,881 - INFO -   256: 2 games (100.0%)
2025-02-27 20:04:19,882 - INFO - Average steps to achieve tile:
2025-02-27 20:04:19,882 - INFO -   16: 10.0 steps
2025-02-27 20:04:19,882 - INFO -   32: 30.0 steps
2025-02-27 20:04:19,882 - INFO -   64: 67.5 steps
2025-02-27 20:04:19,883 - INFO -   128: 87.5 steps
2025-02-27 20:04:19,883 - INFO -   256: 143.5 steps
2025-02-27 20:04:19,883 - INFO - Testing with temperature 2.0...
2025-02-27 20:04:19,883 - INFO - Starting game 1/2
2025-02-27 20:04:20,050 - INFO - Game 1: New maximum tile achieved: 2
2025-02-27 20:04:20,206 - INFO - Game 1: New maximum tile achieved: 4
2025-02-27 20:04:20,827 - INFO - Game 1: New maximum tile achieved: 8
2025-02-27 20:04:22,144 - INFO - Game 1: New maximum tile achieved: 16
2025-02-27 20:04:24,551 - INFO - Game 1: New maximum tile achieved: 32
2025-02-27 20:04:27,702 - INFO - Game 1: New maximum tile achieved: 64
2025-02-27 20:04:34,857 - INFO - Game 1/2 completed: Score = 728, Max Tile = 64, Steps = 91
2025-02-27 20:04:34,858 - INFO - Starting game 2/2
2025-02-27 20:04:35,010 - INFO - Game 2: New maximum tile achieved: 4
2025-02-27 20:04:35,782 - INFO - Game 2: New maximum tile achieved: 8
2025-02-27 20:04:36,426 - INFO - Game 2: New maximum tile achieved: 16
2025-02-27 20:04:38,295 - INFO - Game 2: New maximum tile achieved: 32
2025-02-27 20:04:46,347 - INFO - Game 2: New maximum tile achieved: 64
2025-02-27 20:04:50,587 - INFO - Game 2: New maximum tile achieved: 128
2025-02-27 20:05:00,238 - INFO - Game 2: New maximum tile achieved: 256
2025-02-27 20:05:11,620 - INFO - Game 2/2 completed: Score = 2788, Max Tile = 256, Steps = 214
2025-02-27 20:05:11,621 - INFO - ========================================
2025-02-27 20:05:11,621 - INFO - Evaluation over 2 games:
2025-02-27 20:05:11,621 - INFO - Average Max Tile: 160.0
2025-02-27 20:05:11,621 - INFO - Average Score: 1758.0
2025-02-27 20:05:11,622 - INFO - Average Steps: 152.5
2025-02-27 20:05:11,622 - INFO - Best Max Tile: 256
2025-02-27 20:05:11,623 - INFO - Tile distribution:
2025-02-27 20:05:11,623 - INFO -   64: 1 games (50.0%)
2025-02-27 20:05:11,623 - INFO -   256: 1 games (50.0%)
2025-02-27 20:05:11,623 - INFO - Average steps to achieve tile:
2025-02-27 20:05:11,623 - INFO -   16: 11.0 steps
2025-02-27 20:05:11,624 - INFO -   32: 24.5 steps
2025-02-27 20:05:11,624 - INFO -   64: 59.0 steps
2025-02-27 20:05:11,624 - INFO -   128: 97.0 steps
2025-02-27 20:05:11,624 - INFO -   256: 155.0 steps
2025-02-27 20:41:12,834 - INFO - === 2048 Enhanced Training/Evaluation ===
2025-02-27 20:41:12,835 - INFO - Training for 3000 epochs with batch size 96
2025-02-27 20:41:12,835 - INFO - Learning rate: 0.0008
2025-02-27 20:41:12,835 - INFO - Device: cuda
2025-02-27 20:41:12,836 - INFO - Starting training with simplified approach
2025-02-27 20:41:12,836 - INFO - Training for 3000 epochs with batch size 96
2025-02-27 20:41:15,523 - INFO - New best model saved with reward 2550.7
2025-02-27 20:41:34,323 - INFO - Epoch 10/3000 | Reward: 1889.3 | Running reward: 2380.7 | Max tile: 128 | Exploration: 0.80
2025-02-27 20:41:55,880 - INFO - Epoch 20/3000 | Reward: 2128.5 | Running reward: 2262.2 | Max tile: 128 | Exploration: 0.80
2025-02-27 20:42:22,507 - INFO - Epoch 30/3000 | Reward: 2896.7 | Running reward: 2375.6 | Max tile: 256 | Exploration: 0.80
2025-02-27 20:42:46,611 - INFO - Epoch 40/3000 | Reward: 2664.1 | Running reward: 2338.3 | Max tile: 256 | Exploration: 0.79
2025-02-27 20:43:07,004 - INFO - Epoch 50/3000 | Reward: 1770.7 | Running reward: 2206.6 | Max tile: 128 | Exploration: 0.79
2025-02-27 20:43:29,145 - INFO - Epoch 60/3000 | Reward: 2335.8 | Running reward: 2216.5 | Max tile: 256 | Exploration: 0.79
2025-02-27 20:43:51,473 - INFO - Epoch 70/3000 | Reward: 2244.1 | Running reward: 2187.5 | Max tile: 128 | Exploration: 0.79
2025-02-27 20:44:12,751 - INFO - Epoch 80/3000 | Reward: 1856.4 | Running reward: 2132.5 | Max tile: 128 | Exploration: 0.79
2025-02-27 20:44:33,177 - INFO - Epoch 90/3000 | Reward: 2646.5 | Running reward: 2103.6 | Max tile: 256 | Exploration: 0.79
2025-02-27 20:44:55,672 - INFO - Epoch 100/3000 | Reward: 2418.1 | Running reward: 2131.4 | Max tile: 128 | Exploration: 0.79
2025-02-27 20:45:18,775 - INFO - Epoch 110/3000 | Reward: 2608.5 | Running reward: 2207.1 | Max tile: 128 | Exploration: 0.79
2025-02-27 20:45:41,183 - INFO - Epoch 120/3000 | Reward: 1959.7 | Running reward: 2217.3 | Max tile: 128 | Exploration: 0.78
2025-02-27 20:46:02,025 - INFO - Epoch 130/3000 | Reward: 1763.4 | Running reward: 2206.8 | Max tile: 128 | Exploration: 0.78
2025-02-27 20:46:22,835 - INFO - Epoch 140/3000 | Reward: 2169.0 | Running reward: 2149.5 | Max tile: 128 | Exploration: 0.78
2025-02-27 20:46:44,143 - INFO - Epoch 150/3000 | Reward: 2688.4 | Running reward: 2151.5 | Max tile: 256 | Exploration: 0.78
2025-02-27 20:47:06,032 - INFO - Epoch 160/3000 | Reward: 2552.6 | Running reward: 2171.8 | Max tile: 128 | Exploration: 0.78
2025-02-27 20:47:29,120 - INFO - Epoch 170/3000 | Reward: 2001.9 | Running reward: 2188.4 | Max tile: 128 | Exploration: 0.78
2025-02-27 20:47:50,635 - INFO - Epoch 180/3000 | Reward: 2049.5 | Running reward: 2141.5 | Max tile: 128 | Exploration: 0.78
2025-02-27 20:48:12,532 - INFO - Epoch 190/3000 | Reward: 1816.9 | Running reward: 2121.2 | Max tile: 128 | Exploration: 0.77
2025-02-27 20:48:34,591 - INFO - Epoch 200/3000 | Reward: 1730.6 | Running reward: 2117.3 | Max tile: 128 | Exploration: 0.77
2025-02-27 20:48:58,152 - INFO - Epoch 210/3000 | Reward: 2196.0 | Running reward: 2184.6 | Max tile: 256 | Exploration: 0.77
2025-02-27 20:49:18,118 - INFO - Epoch 220/3000 | Reward: 2127.6 | Running reward: 2095.1 | Max tile: 128 | Exploration: 0.77
2025-02-27 20:49:40,657 - INFO - Epoch 230/3000 | Reward: 1989.2 | Running reward: 2126.0 | Max tile: 128 | Exploration: 0.77
2025-02-27 20:50:01,733 - INFO - Epoch 240/3000 | Reward: 1175.5 | Running reward: 2073.5 | Max tile: 64 | Exploration: 0.77
2025-02-27 20:50:24,713 - INFO - Epoch 250/3000 | Reward: 1504.2 | Running reward: 2134.2 | Max tile: 128 | Exploration: 0.77
2025-02-27 20:50:43,619 - INFO - Epoch 260/3000 | Reward: 2348.3 | Running reward: 2078.6 | Max tile: 128 | Exploration: 0.77
2025-02-27 20:51:06,238 - INFO - Epoch 270/3000 | Reward: 2740.4 | Running reward: 2192.6 | Max tile: 256 | Exploration: 0.76
2025-02-27 20:51:25,899 - INFO - Epoch 280/3000 | Reward: 1869.0 | Running reward: 2070.2 | Max tile: 128 | Exploration: 0.76
2025-02-27 20:51:47,936 - INFO - Epoch 290/3000 | Reward: 1926.4 | Running reward: 2116.9 | Max tile: 128 | Exploration: 0.76
2025-02-27 20:52:10,476 - INFO - Epoch 300/3000 | Reward: 2410.8 | Running reward: 2172.3 | Max tile: 128 | Exploration: 0.76
2025-02-27 20:52:31,436 - INFO - Epoch 310/3000 | Reward: 2251.2 | Running reward: 2130.9 | Max tile: 128 | Exploration: 0.76
2025-02-27 20:52:53,799 - INFO - Epoch 320/3000 | Reward: 2051.3 | Running reward: 2115.3 | Max tile: 128 | Exploration: 0.76
2025-02-27 20:53:16,699 - INFO - Epoch 330/3000 | Reward: 2084.3 | Running reward: 2144.6 | Max tile: 128 | Exploration: 0.76
2025-02-27 20:53:39,001 - INFO - Epoch 340/3000 | Reward: 2866.3 | Running reward: 2174.5 | Max tile: 256 | Exploration: 0.75
2025-02-27 20:54:02,393 - INFO - Epoch 350/3000 | Reward: 2216.5 | Running reward: 2225.8 | Max tile: 128 | Exploration: 0.75
2025-02-27 20:54:24,534 - INFO - Epoch 360/3000 | Reward: 3477.4 | Running reward: 2223.7 | Max tile: 256 | Exploration: 0.75
2025-02-27 20:54:46,561 - INFO - Epoch 370/3000 | Reward: 2128.7 | Running reward: 2224.1 | Max tile: 128 | Exploration: 0.75
2025-02-27 20:55:08,002 - INFO - Epoch 380/3000 | Reward: 2062.6 | Running reward: 2186.5 | Max tile: 128 | Exploration: 0.75
2025-02-27 20:55:27,292 - INFO - Epoch 390/3000 | Reward: 2579.5 | Running reward: 2104.2 | Max tile: 128 | Exploration: 0.75
2025-02-27 20:55:47,493 - INFO - Epoch 400/3000 | Reward: 1851.5 | Running reward: 2059.3 | Max tile: 128 | Exploration: 0.75
2025-02-27 20:56:10,044 - INFO - Epoch 410/3000 | Reward: 2091.3 | Running reward: 2134.4 | Max tile: 128 | Exploration: 0.75
2025-02-27 20:56:33,308 - INFO - Epoch 420/3000 | Reward: 2788.6 | Running reward: 2195.2 | Max tile: 256 | Exploration: 0.74
2025-02-27 20:56:56,097 - INFO - Epoch 430/3000 | Reward: 2585.5 | Running reward: 2228.7 | Max tile: 128 | Exploration: 0.74
2025-02-27 20:57:19,358 - INFO - Epoch 440/3000 | Reward: 2435.7 | Running reward: 2262.7 | Max tile: 128 | Exploration: 0.74
2025-02-27 20:57:41,546 - INFO - Epoch 450/3000 | Reward: 2168.0 | Running reward: 2236.8 | Max tile: 128 | Exploration: 0.74
2025-02-27 20:58:03,788 - INFO - Epoch 460/3000 | Reward: 1906.3 | Running reward: 2237.2 | Max tile: 128 | Exploration: 0.74
2025-02-27 20:58:25,123 - INFO - Epoch 470/3000 | Reward: 2335.4 | Running reward: 2218.8 | Max tile: 128 | Exploration: 0.74
2025-02-27 20:58:47,778 - INFO - Epoch 480/3000 | Reward: 1809.0 | Running reward: 2233.5 | Max tile: 128 | Exploration: 0.74
2025-02-27 20:59:09,410 - INFO - Epoch 490/3000 | Reward: 1764.8 | Running reward: 2186.3 | Max tile: 128 | Exploration: 0.73
2025-02-27 20:59:34,514 - INFO - Epoch 500/3000 | Reward: 2167.6 | Running reward: 2290.6 | Max tile: 128 | Exploration: 0.73
2025-02-27 20:59:56,745 - INFO - Epoch 510/3000 | Reward: 2386.4 | Running reward: 2269.9 | Max tile: 128 | Exploration: 0.73
2025-02-27 21:00:20,876 - INFO - Epoch 520/3000 | Reward: 2149.6 | Running reward: 2289.1 | Max tile: 128 | Exploration: 0.73
2025-02-27 21:00:45,420 - INFO - Epoch 530/3000 | Reward: 2146.3 | Running reward: 2325.5 | Max tile: 128 | Exploration: 0.73
2025-02-27 21:01:08,765 - INFO - Epoch 540/3000 | Reward: 2065.9 | Running reward: 2312.8 | Max tile: 128 | Exploration: 0.73
2025-02-27 21:01:31,302 - INFO - Epoch 550/3000 | Reward: 1995.2 | Running reward: 2287.4 | Max tile: 128 | Exploration: 0.73
2025-02-27 21:01:52,085 - INFO - Epoch 560/3000 | Reward: 1654.4 | Running reward: 2204.6 | Max tile: 64 | Exploration: 0.73
2025-02-27 21:02:12,232 - INFO - Epoch 570/3000 | Reward: 2464.7 | Running reward: 2144.3 | Max tile: 256 | Exploration: 0.72
2025-02-27 21:02:33,383 - INFO - Epoch 580/3000 | Reward: 1922.3 | Running reward: 2153.5 | Max tile: 128 | Exploration: 0.72
2025-02-27 21:02:54,071 - INFO - Epoch 590/3000 | Reward: 1910.5 | Running reward: 2155.4 | Max tile: 128 | Exploration: 0.72
2025-02-27 21:03:16,293 - INFO - Epoch 600/3000 | Reward: 2171.2 | Running reward: 2210.6 | Max tile: 128 | Exploration: 0.72
2025-02-27 21:03:36,306 - INFO - Epoch 610/3000 | Reward: 2166.5 | Running reward: 2111.5 | Max tile: 128 | Exploration: 0.72
2025-02-27 21:03:58,196 - INFO - Epoch 620/3000 | Reward: 2055.1 | Running reward: 2122.3 | Max tile: 256 | Exploration: 0.72
2025-02-27 21:04:18,893 - INFO - Epoch 630/3000 | Reward: 2473.7 | Running reward: 2109.9 | Max tile: 128 | Exploration: 0.72
2025-02-27 21:04:41,705 - INFO - Epoch 640/3000 | Reward: 1828.1 | Running reward: 2152.9 | Max tile: 64 | Exploration: 0.71
2025-02-27 21:05:05,885 - INFO - Epoch 650/3000 | Reward: 2475.3 | Running reward: 2254.0 | Max tile: 256 | Exploration: 0.71
2025-02-27 21:05:27,803 - INFO - Epoch 660/3000 | Reward: 2259.1 | Running reward: 2237.3 | Max tile: 128 | Exploration: 0.71
2025-02-27 21:05:47,444 - INFO - Epoch 670/3000 | Reward: 1745.5 | Running reward: 2109.9 | Max tile: 64 | Exploration: 0.71
2025-02-27 21:06:07,521 - INFO - Epoch 680/3000 | Reward: 1915.9 | Running reward: 2045.3 | Max tile: 256 | Exploration: 0.71
2025-02-27 21:06:29,234 - INFO - Epoch 690/3000 | Reward: 2062.1 | Running reward: 2074.7 | Max tile: 128 | Exploration: 0.71
2025-02-27 21:06:49,450 - INFO - Epoch 700/3000 | Reward: 1998.2 | Running reward: 2055.0 | Max tile: 128 | Exploration: 0.71
2025-02-27 21:07:12,856 - INFO - Epoch 710/3000 | Reward: 1894.0 | Running reward: 2140.7 | Max tile: 128 | Exploration: 0.71
2025-02-27 21:07:35,024 - INFO - Epoch 720/3000 | Reward: 2409.3 | Running reward: 2186.5 | Max tile: 128 | Exploration: 0.70
2025-02-27 21:07:58,571 - INFO - Epoch 730/3000 | Reward: 2159.4 | Running reward: 2232.7 | Max tile: 128 | Exploration: 0.70
2025-02-27 21:08:21,345 - INFO - Epoch 740/3000 | Reward: 1575.8 | Running reward: 2234.8 | Max tile: 64 | Exploration: 0.70
2025-02-27 21:08:43,618 - INFO - Epoch 750/3000 | Reward: 2906.7 | Running reward: 2236.0 | Max tile: 256 | Exploration: 0.70
2025-02-27 21:09:05,751 - INFO - Epoch 760/3000 | Reward: 2462.8 | Running reward: 2234.8 | Max tile: 128 | Exploration: 0.70
2025-02-27 21:09:27,370 - INFO - Epoch 770/3000 | Reward: 2257.6 | Running reward: 2211.7 | Max tile: 256 | Exploration: 0.70
2025-02-27 21:09:51,038 - INFO - Epoch 780/3000 | Reward: 2176.5 | Running reward: 2259.3 | Max tile: 128 | Exploration: 0.70
2025-02-27 21:10:14,862 - INFO - Epoch 790/3000 | Reward: 1671.2 | Running reward: 2282.4 | Max tile: 64 | Exploration: 0.69
2025-02-27 21:10:37,317 - INFO - Epoch 800/3000 | Reward: 2398.7 | Running reward: 2255.6 | Max tile: 256 | Exploration: 0.69
2025-02-27 21:10:57,576 - INFO - Epoch 810/3000 | Reward: 1742.5 | Running reward: 2164.2 | Max tile: 128 | Exploration: 0.69
2025-02-27 21:11:19,124 - INFO - Epoch 820/3000 | Reward: 2282.4 | Running reward: 2142.4 | Max tile: 128 | Exploration: 0.69
2025-02-27 21:11:39,178 - INFO - Epoch 830/3000 | Reward: 1749.1 | Running reward: 2079.5 | Max tile: 128 | Exploration: 0.69
2025-02-27 21:12:01,765 - INFO - Epoch 840/3000 | Reward: 2629.8 | Running reward: 2171.8 | Max tile: 256 | Exploration: 0.69
2025-02-27 21:12:24,912 - INFO - Epoch 850/3000 | Reward: 2332.8 | Running reward: 2252.5 | Max tile: 128 | Exploration: 0.69
2025-02-27 21:12:48,076 - INFO - Epoch 860/3000 | Reward: 2509.8 | Running reward: 2286.3 | Max tile: 128 | Exploration: 0.69
2025-02-27 21:13:09,964 - INFO - Epoch 870/3000 | Reward: 2417.4 | Running reward: 2243.6 | Max tile: 128 | Exploration: 0.68
2025-02-27 21:13:33,168 - INFO - Epoch 880/3000 | Reward: 2804.3 | Running reward: 2248.3 | Max tile: 128 | Exploration: 0.68
2025-02-27 21:13:55,266 - INFO - Epoch 890/3000 | Reward: 2261.2 | Running reward: 2210.7 | Max tile: 128 | Exploration: 0.68
2025-02-27 21:14:19,674 - INFO - Epoch 900/3000 | Reward: 2044.8 | Running reward: 2320.1 | Max tile: 256 | Exploration: 0.68
2025-02-27 21:14:42,205 - INFO - Epoch 910/3000 | Reward: 2030.3 | Running reward: 2300.4 | Max tile: 128 | Exploration: 0.68
2025-02-27 21:15:03,017 - INFO - Epoch 920/3000 | Reward: 1721.3 | Running reward: 2207.2 | Max tile: 128 | Exploration: 0.68
2025-02-27 21:15:26,819 - INFO - Epoch 930/3000 | Reward: 2238.1 | Running reward: 2274.8 | Max tile: 256 | Exploration: 0.68
2025-02-27 21:15:50,979 - INFO - Epoch 940/3000 | Reward: 2683.9 | Running reward: 2305.5 | Max tile: 128 | Exploration: 0.67
2025-02-27 21:16:12,150 - INFO - Epoch 950/3000 | Reward: 2676.6 | Running reward: 2207.1 | Max tile: 256 | Exploration: 0.67
2025-02-27 21:16:34,518 - INFO - Epoch 960/3000 | Reward: 1672.9 | Running reward: 2188.1 | Max tile: 64 | Exploration: 0.67
2025-02-27 21:16:56,880 - INFO - Epoch 970/3000 | Reward: 2257.5 | Running reward: 2197.3 | Max tile: 128 | Exploration: 0.67
2025-02-27 21:17:20,466 - INFO - Epoch 980/3000 | Reward: 2397.5 | Running reward: 2232.0 | Max tile: 128 | Exploration: 0.67
2025-02-27 21:17:41,840 - INFO - Epoch 990/3000 | Reward: 2122.5 | Running reward: 2179.0 | Max tile: 128 | Exploration: 0.67
2025-02-27 21:18:02,645 - INFO - Epoch 1000/3000 | Reward: 2531.9 | Running reward: 2144.6 | Max tile: 128 | Exploration: 0.67
2025-02-27 21:18:26,739 - INFO - Epoch 1010/3000 | Reward: 2309.3 | Running reward: 2251.6 | Max tile: 128 | Exploration: 0.67
2025-02-27 21:18:50,724 - INFO - Epoch 1020/3000 | Reward: 2121.2 | Running reward: 2300.8 | Max tile: 128 | Exploration: 0.66
2025-02-27 21:19:13,579 - INFO - Epoch 1030/3000 | Reward: 2004.6 | Running reward: 2292.0 | Max tile: 64 | Exploration: 0.66
2025-02-27 21:19:36,746 - INFO - Epoch 1040/3000 | Reward: 2022.3 | Running reward: 2266.2 | Max tile: 128 | Exploration: 0.66
2025-02-27 21:20:00,938 - INFO - Epoch 1050/3000 | Reward: 2136.0 | Running reward: 2316.1 | Max tile: 128 | Exploration: 0.66
2025-02-27 21:20:24,694 - INFO - Epoch 1060/3000 | Reward: 2153.7 | Running reward: 2324.7 | Max tile: 128 | Exploration: 0.66
2025-02-27 21:20:46,471 - INFO - Epoch 1070/3000 | Reward: 2144.2 | Running reward: 2257.0 | Max tile: 128 | Exploration: 0.66
2025-02-27 21:21:10,594 - INFO - Epoch 1080/3000 | Reward: 2437.6 | Running reward: 2307.9 | Max tile: 128 | Exploration: 0.66
2025-02-27 21:21:32,089 - INFO - Epoch 1090/3000 | Reward: 2538.8 | Running reward: 2272.3 | Max tile: 256 | Exploration: 0.65
2025-02-27 21:21:54,184 - INFO - Epoch 1100/3000 | Reward: 2553.4 | Running reward: 2316.2 | Max tile: 128 | Exploration: 0.65
2025-02-27 21:22:15,648 - INFO - Epoch 1110/3000 | Reward: 2477.9 | Running reward: 2251.1 | Max tile: 256 | Exploration: 0.65
2025-02-27 21:22:35,866 - INFO - Epoch 1120/3000 | Reward: 2152.7 | Running reward: 2162.7 | Max tile: 128 | Exploration: 0.65
2025-02-27 21:22:57,618 - INFO - Epoch 1130/3000 | Reward: 1712.1 | Running reward: 2153.2 | Max tile: 128 | Exploration: 0.65
2025-02-27 21:23:20,666 - INFO - Epoch 1140/3000 | Reward: 2115.1 | Running reward: 2212.1 | Max tile: 128 | Exploration: 0.65
2025-02-27 21:23:42,432 - INFO - Epoch 1150/3000 | Reward: 2161.9 | Running reward: 2196.9 | Max tile: 64 | Exploration: 0.65
2025-02-27 21:24:04,990 - INFO - Epoch 1160/3000 | Reward: 1936.3 | Running reward: 2223.1 | Max tile: 128 | Exploration: 0.65
2025-02-27 21:24:28,810 - INFO - Epoch 1170/3000 | Reward: 2606.9 | Running reward: 2275.2 | Max tile: 128 | Exploration: 0.64
2025-02-27 21:24:51,534 - INFO - Epoch 1180/3000 | Reward: 1911.2 | Running reward: 2256.7 | Max tile: 64 | Exploration: 0.64
2025-02-27 21:25:13,445 - INFO - Epoch 1190/3000 | Reward: 1730.8 | Running reward: 2222.4 | Max tile: 64 | Exploration: 0.64
2025-02-27 21:25:36,285 - INFO - Epoch 1200/3000 | Reward: 2336.8 | Running reward: 2252.1 | Max tile: 128 | Exploration: 0.64
2025-02-27 21:25:59,786 - INFO - Epoch 1210/3000 | Reward: 2581.7 | Running reward: 2273.4 | Max tile: 256 | Exploration: 0.64
2025-02-27 21:26:21,329 - INFO - Epoch 1220/3000 | Reward: 1716.1 | Running reward: 2209.0 | Max tile: 128 | Exploration: 0.64
2025-02-27 21:26:44,216 - INFO - Epoch 1230/3000 | Reward: 1782.0 | Running reward: 2235.5 | Max tile: 64 | Exploration: 0.64
2025-02-27 21:27:08,843 - INFO - Epoch 1240/3000 | Reward: 2978.2 | Running reward: 2338.6 | Max tile: 256 | Exploration: 0.63
2025-02-27 21:27:33,897 - INFO - Epoch 1250/3000 | Reward: 2922.5 | Running reward: 2399.0 | Max tile: 256 | Exploration: 0.63
2025-02-27 21:27:55,647 - INFO - Epoch 1260/3000 | Reward: 1635.9 | Running reward: 2297.6 | Max tile: 64 | Exploration: 0.63
2025-02-27 21:28:18,038 - INFO - Epoch 1270/3000 | Reward: 2142.3 | Running reward: 2250.6 | Max tile: 128 | Exploration: 0.63
2025-02-27 21:28:40,611 - INFO - Epoch 1280/3000 | Reward: 1781.7 | Running reward: 2232.1 | Max tile: 128 | Exploration: 0.63
2025-02-27 21:29:02,968 - INFO - Epoch 1290/3000 | Reward: 1950.7 | Running reward: 2242.1 | Max tile: 64 | Exploration: 0.63
2025-02-27 21:29:26,310 - INFO - Epoch 1300/3000 | Reward: 2387.9 | Running reward: 2267.3 | Max tile: 128 | Exploration: 0.63
2025-02-27 21:29:47,472 - INFO - Epoch 1310/3000 | Reward: 3044.4 | Running reward: 2208.6 | Max tile: 256 | Exploration: 0.63
2025-02-27 21:30:08,786 - INFO - Epoch 1320/3000 | Reward: 2365.5 | Running reward: 2190.1 | Max tile: 128 | Exploration: 0.62
2025-02-27 21:30:28,149 - INFO - Epoch 1330/3000 | Reward: 1775.6 | Running reward: 2065.6 | Max tile: 128 | Exploration: 0.62
2025-02-27 21:30:49,680 - INFO - Epoch 1340/3000 | Reward: 2208.6 | Running reward: 2112.3 | Max tile: 64 | Exploration: 0.62
2025-02-27 21:31:13,650 - INFO - Epoch 1350/3000 | Reward: 2788.6 | Running reward: 2236.0 | Max tile: 256 | Exploration: 0.62
2025-02-27 21:31:34,683 - INFO - Epoch 1360/3000 | Reward: 2218.7 | Running reward: 2177.5 | Max tile: 128 | Exploration: 0.62
2025-02-27 21:31:57,576 - INFO - Epoch 1370/3000 | Reward: 2649.4 | Running reward: 2212.1 | Max tile: 256 | Exploration: 0.62
2025-02-27 21:32:20,314 - INFO - Epoch 1380/3000 | Reward: 2369.2 | Running reward: 2220.6 | Max tile: 128 | Exploration: 0.62
2025-02-27 21:32:43,530 - INFO - Epoch 1390/3000 | Reward: 2474.0 | Running reward: 2256.8 | Max tile: 128 | Exploration: 0.61
2025-02-27 21:33:05,617 - INFO - Epoch 1400/3000 | Reward: 2478.6 | Running reward: 2204.7 | Max tile: 128 | Exploration: 0.61
2025-02-27 21:33:27,296 - INFO - Epoch 1410/3000 | Reward: 1870.9 | Running reward: 2189.3 | Max tile: 128 | Exploration: 0.61
2025-02-27 21:33:45,455 - INFO - Epoch 1420/3000 | Reward: 2240.7 | Running reward: 2046.7 | Max tile: 128 | Exploration: 0.61
2025-02-27 21:34:07,547 - INFO - Epoch 1430/3000 | Reward: 1537.6 | Running reward: 2113.9 | Max tile: 64 | Exploration: 0.61
2025-02-27 21:34:30,685 - INFO - Epoch 1440/3000 | Reward: 1969.3 | Running reward: 2183.9 | Max tile: 128 | Exploration: 0.61
2025-02-27 21:34:53,240 - INFO - Epoch 1450/3000 | Reward: 2223.0 | Running reward: 2230.7 | Max tile: 256 | Exploration: 0.61
2025-02-27 21:35:13,984 - INFO - Epoch 1460/3000 | Reward: 1998.3 | Running reward: 2167.4 | Max tile: 128 | Exploration: 0.61
2025-02-27 21:35:36,993 - INFO - Epoch 1470/3000 | Reward: 1833.0 | Running reward: 2211.6 | Max tile: 128 | Exploration: 0.60
2025-02-27 21:36:00,003 - INFO - Epoch 1480/3000 | Reward: 2427.4 | Running reward: 2265.3 | Max tile: 128 | Exploration: 0.60
2025-02-27 21:36:22,958 - INFO - Epoch 1490/3000 | Reward: 2643.1 | Running reward: 2259.6 | Max tile: 256 | Exploration: 0.60
2025-02-27 21:36:46,641 - INFO - Epoch 1500/3000 | Reward: 1551.4 | Running reward: 2278.6 | Max tile: 64 | Exploration: 0.60
2025-02-27 21:37:08,206 - INFO - Epoch 1510/3000 | Reward: 2229.3 | Running reward: 2230.7 | Max tile: 128 | Exploration: 0.60
2025-02-27 21:37:30,592 - INFO - Epoch 1520/3000 | Reward: 2162.2 | Running reward: 2237.4 | Max tile: 256 | Exploration: 0.60
2025-02-27 21:37:53,779 - INFO - Epoch 1530/3000 | Reward: 1905.0 | Running reward: 2282.7 | Max tile: 128 | Exploration: 0.60
2025-02-27 21:38:16,663 - INFO - Epoch 1540/3000 | Reward: 2480.1 | Running reward: 2293.0 | Max tile: 256 | Exploration: 0.59
2025-02-27 21:38:40,683 - INFO - Epoch 1550/3000 | Reward: 2352.0 | Running reward: 2323.2 | Max tile: 128 | Exploration: 0.59
2025-02-27 21:39:02,403 - INFO - Epoch 1560/3000 | Reward: 2038.4 | Running reward: 2262.9 | Max tile: 128 | Exploration: 0.59
2025-02-27 21:39:26,409 - INFO - Epoch 1570/3000 | Reward: 1984.1 | Running reward: 2326.5 | Max tile: 128 | Exploration: 0.59
2025-02-27 21:39:49,198 - INFO - Epoch 1580/3000 | Reward: 1735.2 | Running reward: 2308.6 | Max tile: 128 | Exploration: 0.59
2025-02-27 21:40:10,468 - INFO - Epoch 1590/3000 | Reward: 2435.6 | Running reward: 2234.8 | Max tile: 128 | Exploration: 0.59
2025-02-27 21:40:36,744 - INFO - Epoch 1600/3000 | Reward: 2723.9 | Running reward: 2417.8 | Max tile: 128 | Exploration: 0.59
2025-02-27 21:40:58,501 - INFO - Epoch 1610/3000 | Reward: 2737.3 | Running reward: 2334.8 | Max tile: 256 | Exploration: 0.59
2025-02-27 21:41:22,630 - INFO - Epoch 1620/3000 | Reward: 1876.8 | Running reward: 2357.5 | Max tile: 128 | Exploration: 0.58
2025-02-27 21:41:45,464 - INFO - Epoch 1630/3000 | Reward: 2715.8 | Running reward: 2345.8 | Max tile: 128 | Exploration: 0.58
2025-02-27 21:42:07,964 - INFO - Epoch 1640/3000 | Reward: 1880.3 | Running reward: 2302.8 | Max tile: 64 | Exploration: 0.58
2025-02-27 21:42:28,520 - INFO - Epoch 1650/3000 | Reward: 1820.5 | Running reward: 2196.5 | Max tile: 128 | Exploration: 0.58
2025-02-27 21:42:49,711 - INFO - Epoch 1660/3000 | Reward: 2229.8 | Running reward: 2165.7 | Max tile: 128 | Exploration: 0.58
2025-02-27 21:43:11,782 - INFO - Epoch 1670/3000 | Reward: 1577.5 | Running reward: 2182.9 | Max tile: 128 | Exploration: 0.58
2025-02-27 21:43:35,456 - INFO - Epoch 1680/3000 | Reward: 2748.8 | Running reward: 2273.4 | Max tile: 128 | Exploration: 0.58
2025-02-27 21:43:57,241 - INFO - Epoch 1690/3000 | Reward: 2668.0 | Running reward: 2250.9 | Max tile: 128 | Exploration: 0.57
2025-02-27 21:44:20,409 - INFO - Epoch 1700/3000 | Reward: 1984.5 | Running reward: 2278.3 | Max tile: 128 | Exploration: 0.57
2025-02-27 21:44:40,782 - INFO - Epoch 1710/3000 | Reward: 1509.8 | Running reward: 2164.5 | Max tile: 64 | Exploration: 0.57
2025-02-27 21:45:01,311 - INFO - Epoch 1720/3000 | Reward: 2493.4 | Running reward: 2149.0 | Max tile: 128 | Exploration: 0.57
2025-02-27 21:45:24,621 - INFO - Epoch 1730/3000 | Reward: 1896.0 | Running reward: 2226.8 | Max tile: 128 | Exploration: 0.57
2025-02-27 21:45:48,201 - INFO - Epoch 1740/3000 | Reward: 2912.6 | Running reward: 2301.1 | Max tile: 256 | Exploration: 0.57
2025-02-27 21:46:11,032 - INFO - Epoch 1750/3000 | Reward: 1735.3 | Running reward: 2299.0 | Max tile: 64 | Exploration: 0.57
2025-02-27 21:46:33,613 - INFO - Epoch 1760/3000 | Reward: 2138.1 | Running reward: 2297.9 | Max tile: 128 | Exploration: 0.57
2025-02-27 21:46:55,577 - INFO - Epoch 1770/3000 | Reward: 3059.4 | Running reward: 2273.1 | Max tile: 256 | Exploration: 0.56
2025-02-27 21:47:18,522 - INFO - Epoch 1780/3000 | Reward: 1793.6 | Running reward: 2255.2 | Max tile: 128 | Exploration: 0.56
2025-02-27 21:47:40,068 - INFO - Epoch 1790/3000 | Reward: 2372.5 | Running reward: 2225.2 | Max tile: 128 | Exploration: 0.56
2025-02-27 21:48:05,156 - INFO - Epoch 1800/3000 | Reward: 2502.9 | Running reward: 2345.1 | Max tile: 128 | Exploration: 0.56
2025-02-27 21:48:28,298 - INFO - Epoch 1810/3000 | Reward: 2465.5 | Running reward: 2346.8 | Max tile: 256 | Exploration: 0.56
2025-02-27 21:48:51,205 - INFO - Epoch 1820/3000 | Reward: 2104.9 | Running reward: 2307.2 | Max tile: 128 | Exploration: 0.56
2025-02-27 21:49:14,402 - INFO - Epoch 1830/3000 | Reward: 3033.6 | Running reward: 2309.1 | Max tile: 256 | Exploration: 0.56
2025-02-27 21:49:37,175 - INFO - Epoch 1840/3000 | Reward: 2428.0 | Running reward: 2307.6 | Max tile: 256 | Exploration: 0.55
2025-02-27 21:50:00,679 - INFO - Epoch 1850/3000 | Reward: 2356.8 | Running reward: 2324.1 | Max tile: 128 | Exploration: 0.55
2025-02-27 21:50:22,743 - INFO - Epoch 1860/3000 | Reward: 1842.9 | Running reward: 2276.5 | Max tile: 128 | Exploration: 0.55
2025-02-27 21:50:43,517 - INFO - Epoch 1870/3000 | Reward: 2710.6 | Running reward: 2206.8 | Max tile: 256 | Exploration: 0.55
2025-02-27 21:51:04,088 - INFO - Epoch 1880/3000 | Reward: 1576.9 | Running reward: 2125.5 | Max tile: 64 | Exploration: 0.55
2025-02-27 21:51:27,057 - INFO - Epoch 1890/3000 | Reward: 2581.4 | Running reward: 2196.8 | Max tile: 128 | Exploration: 0.55
2025-02-27 21:51:50,058 - INFO - Epoch 1900/3000 | Reward: 1975.5 | Running reward: 2200.1 | Max tile: 128 | Exploration: 0.55
2025-02-27 21:52:13,420 - INFO - Epoch 1910/3000 | Reward: 2298.9 | Running reward: 2237.4 | Max tile: 128 | Exploration: 0.55
2025-02-27 21:52:34,936 - INFO - Epoch 1920/3000 | Reward: 2106.3 | Running reward: 2179.6 | Max tile: 128 | Exploration: 0.54
2025-02-27 21:52:57,570 - INFO - Epoch 1930/3000 | Reward: 2741.5 | Running reward: 2192.8 | Max tile: 256 | Exploration: 0.54
2025-02-27 21:53:18,428 - INFO - Epoch 1940/3000 | Reward: 2323.1 | Running reward: 2121.9 | Max tile: 128 | Exploration: 0.54
2025-02-27 21:53:39,497 - INFO - Epoch 1950/3000 | Reward: 1964.2 | Running reward: 2128.5 | Max tile: 128 | Exploration: 0.54
2025-02-27 21:54:01,809 - INFO - Epoch 1960/3000 | Reward: 2350.7 | Running reward: 2131.5 | Max tile: 256 | Exploration: 0.54
2025-02-27 21:54:25,852 - INFO - Epoch 1970/3000 | Reward: 2064.8 | Running reward: 2253.1 | Max tile: 128 | Exploration: 0.54
2025-02-27 21:54:48,663 - INFO - Epoch 1980/3000 | Reward: 2829.1 | Running reward: 2254.2 | Max tile: 256 | Exploration: 0.54
2025-02-27 21:55:11,750 - INFO - Epoch 1990/3000 | Reward: 2119.9 | Running reward: 2259.9 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:55:32,868 - INFO - Epoch 2000/3000 | Reward: 1531.7 | Running reward: 2177.5 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:55:51,073 - INFO - Epoch 2010/3000 | Reward: 1926.5 | Running reward: 2011.6 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:56:15,608 - INFO - Epoch 2020/3000 | Reward: 2214.5 | Running reward: 2212.1 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:56:38,813 - INFO - Epoch 2030/3000 | Reward: 2100.6 | Running reward: 2219.0 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:57:02,284 - INFO - Epoch 2040/3000 | Reward: 2066.0 | Running reward: 2217.2 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:57:26,494 - INFO - Epoch 2050/3000 | Reward: 1709.9 | Running reward: 2303.9 | Max tile: 64 | Exploration: 0.53
2025-02-27 21:57:49,286 - INFO - Epoch 2060/3000 | Reward: 2150.6 | Running reward: 2240.8 | Max tile: 128 | Exploration: 0.53
2025-02-27 21:58:13,843 - INFO - Epoch 2070/3000 | Reward: 2357.0 | Running reward: 2232.6 | Max tile: 128 | Exploration: 0.52
2025-02-27 21:58:37,249 - INFO - Epoch 2080/3000 | Reward: 1884.7 | Running reward: 2209.0 | Max tile: 128 | Exploration: 0.52
2025-02-27 21:59:00,380 - INFO - Epoch 2090/3000 | Reward: 2269.3 | Running reward: 2192.5 | Max tile: 128 | Exploration: 0.52
2025-02-27 21:59:23,397 - INFO - Epoch 2100/3000 | Reward: 2409.0 | Running reward: 2192.4 | Max tile: 128 | Exploration: 0.52
2025-02-27 21:59:45,701 - INFO - Epoch 2110/3000 | Reward: 1579.4 | Running reward: 2162.4 | Max tile: 64 | Exploration: 0.52
2025-02-27 22:00:12,444 - INFO - Epoch 2120/3000 | Reward: 1915.4 | Running reward: 2340.9 | Max tile: 64 | Exploration: 0.52
2025-02-27 22:00:34,925 - INFO - Epoch 2130/3000 | Reward: 2513.3 | Running reward: 2304.5 | Max tile: 128 | Exploration: 0.52
2025-02-27 22:00:57,476 - INFO - Epoch 2140/3000 | Reward: 2193.4 | Running reward: 2281.7 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:01:17,484 - INFO - Epoch 2150/3000 | Reward: 1775.7 | Running reward: 2158.2 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:01:38,353 - INFO - Epoch 2160/3000 | Reward: 2226.1 | Running reward: 2151.9 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:02:02,053 - INFO - Epoch 2170/3000 | Reward: 2023.5 | Running reward: 2171.5 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:02:27,034 - INFO - Epoch 2180/3000 | Reward: 2531.3 | Running reward: 2235.3 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:02:51,303 - INFO - Epoch 2190/3000 | Reward: 1903.4 | Running reward: 2246.8 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:03:13,418 - INFO - Epoch 2200/3000 | Reward: 2164.5 | Running reward: 2242.1 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:03:35,843 - INFO - Epoch 2210/3000 | Reward: 2143.5 | Running reward: 2212.8 | Max tile: 128 | Exploration: 0.51
2025-02-27 22:03:56,571 - INFO - Epoch 2220/3000 | Reward: 2123.8 | Running reward: 2122.7 | Max tile: 128 | Exploration: 0.50
2025-02-27 22:04:18,859 - INFO - Epoch 2230/3000 | Reward: 2358.2 | Running reward: 2169.6 | Max tile: 256 | Exploration: 0.50
2025-02-27 22:04:40,701 - INFO - Epoch 2240/3000 | Reward: 2482.7 | Running reward: 2171.0 | Max tile: 128 | Exploration: 0.50
2025-02-27 22:05:03,352 - INFO - Epoch 2250/3000 | Reward: 2009.9 | Running reward: 2205.6 | Max tile: 128 | Exploration: 0.50
2025-02-27 22:05:27,462 - INFO - Epoch 2260/3000 | Reward: 2174.4 | Running reward: 2256.8 | Max tile: 128 | Exploration: 0.50
2025-02-27 22:05:54,183 - INFO - Epoch 2270/3000 | Reward: 3110.2 | Running reward: 2390.3 | Max tile: 256 | Exploration: 0.50
2025-02-27 22:06:16,472 - INFO - Epoch 2280/3000 | Reward: 1752.3 | Running reward: 2298.8 | Max tile: 64 | Exploration: 0.50
2025-02-27 22:06:41,733 - INFO - Epoch 2290/3000 | Reward: 1911.9 | Running reward: 2354.4 | Max tile: 64 | Exploration: 0.49
2025-02-27 22:07:04,611 - INFO - Epoch 2300/3000 | Reward: 1837.4 | Running reward: 2314.8 | Max tile: 128 | Exploration: 0.49
2025-02-27 22:07:26,292 - INFO - Epoch 2310/3000 | Reward: 2313.6 | Running reward: 2237.0 | Max tile: 128 | Exploration: 0.49
2025-02-27 22:07:47,558 - INFO - Epoch 2320/3000 | Reward: 1411.5 | Running reward: 2155.4 | Max tile: 64 | Exploration: 0.49
2025-02-27 22:08:08,844 - INFO - Epoch 2330/3000 | Reward: 1824.7 | Running reward: 2127.3 | Max tile: 128 | Exploration: 0.49
2025-02-27 22:08:31,226 - INFO - Epoch 2340/3000 | Reward: 2238.0 | Running reward: 2155.2 | Max tile: 128 | Exploration: 0.49
2025-02-27 22:08:55,335 - INFO - Epoch 2350/3000 | Reward: 3261.8 | Running reward: 2245.6 | Max tile: 256 | Exploration: 0.49
2025-02-27 22:09:21,648 - INFO - Epoch 2360/3000 | Reward: 2713.6 | Running reward: 2399.7 | Max tile: 128 | Exploration: 0.49
2025-02-27 22:09:43,866 - INFO - Epoch 2370/3000 | Reward: 1998.3 | Running reward: 2289.8 | Max tile: 128 | Exploration: 0.48
2025-02-27 22:10:03,918 - INFO - Epoch 2380/3000 | Reward: 1796.0 | Running reward: 2169.3 | Max tile: 64 | Exploration: 0.48
2025-02-27 22:10:26,801 - INFO - Epoch 2390/3000 | Reward: 2925.7 | Running reward: 2189.8 | Max tile: 256 | Exploration: 0.48
2025-02-27 22:10:49,982 - INFO - Epoch 2400/3000 | Reward: 2106.8 | Running reward: 2219.6 | Max tile: 128 | Exploration: 0.48
2025-02-27 22:11:14,956 - INFO - Epoch 2410/3000 | Reward: 2209.3 | Running reward: 2295.9 | Max tile: 128 | Exploration: 0.48
2025-02-27 22:11:38,668 - INFO - Epoch 2420/3000 | Reward: 2928.1 | Running reward: 2315.5 | Max tile: 256 | Exploration: 0.48
2025-02-27 22:12:02,350 - INFO - Epoch 2430/3000 | Reward: 2528.3 | Running reward: 2341.5 | Max tile: 128 | Exploration: 0.48
2025-02-27 22:12:23,905 - INFO - Epoch 2440/3000 | Reward: 1879.6 | Running reward: 2228.6 | Max tile: 128 | Exploration: 0.47
2025-02-27 22:12:45,843 - INFO - Epoch 2450/3000 | Reward: 3121.0 | Running reward: 2239.4 | Max tile: 256 | Exploration: 0.47
2025-02-27 22:13:08,206 - INFO - Epoch 2460/3000 | Reward: 1749.6 | Running reward: 2200.4 | Max tile: 64 | Exploration: 0.47
2025-02-27 22:13:29,995 - INFO - Epoch 2470/3000 | Reward: 1816.5 | Running reward: 2161.4 | Max tile: 64 | Exploration: 0.47
2025-02-27 22:13:53,001 - INFO - Epoch 2480/3000 | Reward: 2489.0 | Running reward: 2198.7 | Max tile: 128 | Exploration: 0.47
2025-02-27 22:14:15,023 - INFO - Epoch 2490/3000 | Reward: 2145.7 | Running reward: 2184.9 | Max tile: 128 | Exploration: 0.47
2025-02-27 22:14:40,249 - INFO - Epoch 2500/3000 | Reward: 2004.0 | Running reward: 2254.1 | Max tile: 128 | Exploration: 0.47
2025-02-27 22:15:01,848 - INFO - Epoch 2510/3000 | Reward: 2316.3 | Running reward: 2153.5 | Max tile: 128 | Exploration: 0.47
2025-02-27 22:15:26,019 - INFO - Epoch 2520/3000 | Reward: 1906.0 | Running reward: 2210.2 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:15:46,685 - INFO - Epoch 2530/3000 | Reward: 2629.2 | Running reward: 2160.4 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:16:08,785 - INFO - Epoch 2540/3000 | Reward: 1960.7 | Running reward: 2152.7 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:16:34,008 - INFO - Epoch 2550/3000 | Reward: 2644.9 | Running reward: 2269.9 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:16:56,697 - INFO - Epoch 2560/3000 | Reward: 2269.1 | Running reward: 2257.7 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:17:20,177 - INFO - Epoch 2570/3000 | Reward: 2908.3 | Running reward: 2297.1 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:17:42,274 - INFO - Epoch 2580/3000 | Reward: 1748.3 | Running reward: 2271.2 | Max tile: 128 | Exploration: 0.46
2025-02-27 22:18:05,853 - INFO - Epoch 2590/3000 | Reward: 2112.3 | Running reward: 2320.9 | Max tile: 128 | Exploration: 0.45
2025-02-27 22:18:29,263 - INFO - Epoch 2600/3000 | Reward: 1847.8 | Running reward: 2337.6 | Max tile: 128 | Exploration: 0.45
2025-02-27 22:18:52,312 - INFO - Epoch 2610/3000 | Reward: 2652.3 | Running reward: 2292.4 | Max tile: 256 | Exploration: 0.45
2025-02-27 22:19:14,967 - INFO - Epoch 2620/3000 | Reward: 2499.5 | Running reward: 2289.1 | Max tile: 128 | Exploration: 0.45
2025-02-27 22:19:39,316 - INFO - Epoch 2630/3000 | Reward: 1803.6 | Running reward: 2358.4 | Max tile: 128 | Exploration: 0.45
2025-02-27 22:20:00,554 - INFO - Epoch 2640/3000 | Reward: 2097.1 | Running reward: 2270.0 | Max tile: 128 | Exploration: 0.45
2025-02-27 22:20:23,091 - INFO - Epoch 2650/3000 | Reward: 1848.6 | Running reward: 2273.3 | Max tile: 64 | Exploration: 0.45
2025-02-27 22:20:47,032 - INFO - Epoch 2660/3000 | Reward: 2534.8 | Running reward: 2330.2 | Max tile: 128 | Exploration: 0.45
2025-02-27 22:21:07,477 - INFO - Epoch 2670/3000 | Reward: 2153.6 | Running reward: 2195.9 | Max tile: 128 | Exploration: 0.44
2025-02-27 22:21:28,502 - INFO - Epoch 2680/3000 | Reward: 1297.3 | Running reward: 2130.5 | Max tile: 64 | Exploration: 0.44
2025-02-27 22:21:51,388 - INFO - Epoch 2690/3000 | Reward: 2165.6 | Running reward: 2178.6 | Max tile: 128 | Exploration: 0.44
2025-02-27 22:22:14,926 - INFO - Epoch 2700/3000 | Reward: 2736.7 | Running reward: 2239.2 | Max tile: 128 | Exploration: 0.44
2025-02-27 22:22:37,831 - INFO - Epoch 2710/3000 | Reward: 2948.6 | Running reward: 2280.1 | Max tile: 128 | Exploration: 0.44
2025-02-27 22:23:00,329 - INFO - Epoch 2720/3000 | Reward: 1915.8 | Running reward: 2296.8 | Max tile: 64 | Exploration: 0.44
2025-02-27 22:23:21,286 - INFO - Epoch 2730/3000 | Reward: 2190.0 | Running reward: 2263.7 | Max tile: 128 | Exploration: 0.44
2025-02-27 22:23:40,387 - INFO - Epoch 2740/3000 | Reward: 1480.1 | Running reward: 2096.5 | Max tile: 64 | Exploration: 0.43
2025-02-27 22:23:59,918 - INFO - Epoch 2750/3000 | Reward: 1877.8 | Running reward: 2075.7 | Max tile: 128 | Exploration: 0.43
2025-02-27 22:24:21,919 - INFO - Epoch 2760/3000 | Reward: 2405.6 | Running reward: 2144.4 | Max tile: 128 | Exploration: 0.43
2025-02-27 22:24:42,311 - INFO - Epoch 2770/3000 | Reward: 1888.4 | Running reward: 2130.1 | Max tile: 128 | Exploration: 0.43
2025-02-27 22:25:05,380 - INFO - Epoch 2780/3000 | Reward: 1906.3 | Running reward: 2212.6 | Max tile: 128 | Exploration: 0.43
2025-02-27 22:25:28,091 - INFO - Epoch 2790/3000 | Reward: 1664.5 | Running reward: 2248.8 | Max tile: 64 | Exploration: 0.43
2025-02-27 22:25:50,367 - INFO - Epoch 2800/3000 | Reward: 3096.1 | Running reward: 2300.7 | Max tile: 256 | Exploration: 0.43
2025-02-27 22:26:11,959 - INFO - Epoch 2810/3000 | Reward: 2504.3 | Running reward: 2279.2 | Max tile: 128 | Exploration: 0.43
2025-02-27 22:26:32,314 - INFO - Epoch 2820/3000 | Reward: 2648.7 | Running reward: 2210.5 | Max tile: 128 | Exploration: 0.42
2025-02-27 22:26:53,593 - INFO - Epoch 2830/3000 | Reward: 2391.6 | Running reward: 2204.6 | Max tile: 256 | Exploration: 0.42
2025-02-27 22:27:15,266 - INFO - Epoch 2840/3000 | Reward: 1593.6 | Running reward: 2198.4 | Max tile: 64 | Exploration: 0.42
2025-02-27 22:27:35,341 - INFO - Epoch 2850/3000 | Reward: 2705.1 | Running reward: 2131.9 | Max tile: 128 | Exploration: 0.42
2025-02-27 22:27:56,780 - INFO - Epoch 2860/3000 | Reward: 2060.8 | Running reward: 2187.1 | Max tile: 128 | Exploration: 0.42
2025-02-27 22:28:18,851 - INFO - Epoch 2870/3000 | Reward: 1645.8 | Running reward: 2223.8 | Max tile: 64 | Exploration: 0.42
2025-02-27 22:28:43,223 - INFO - Epoch 2880/3000 | Reward: 2066.2 | Running reward: 2407.9 | Max tile: 128 | Exploration: 0.42
2025-02-27 22:29:07,272 - INFO - Epoch 2890/3000 | Reward: 2057.2 | Running reward: 2447.5 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:29:30,685 - INFO - Epoch 2900/3000 | Reward: 1967.7 | Running reward: 2421.6 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:29:50,701 - INFO - Epoch 2910/3000 | Reward: 1988.2 | Running reward: 2251.7 | Max tile: 64 | Exploration: 0.41
2025-02-27 22:30:08,925 - INFO - Epoch 2920/3000 | Reward: 2297.3 | Running reward: 2079.4 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:30:29,930 - INFO - Epoch 2930/3000 | Reward: 2088.6 | Running reward: 2129.8 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:30:53,279 - INFO - Epoch 2940/3000 | Reward: 2818.7 | Running reward: 2271.1 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:31:14,861 - INFO - Epoch 2950/3000 | Reward: 2751.1 | Running reward: 2270.9 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:31:36,718 - INFO - Epoch 2960/3000 | Reward: 2444.2 | Running reward: 2256.7 | Max tile: 128 | Exploration: 0.41
2025-02-27 22:32:00,716 - INFO - Epoch 2970/3000 | Reward: 3067.6 | Running reward: 2333.7 | Max tile: 256 | Exploration: 0.40
2025-02-27 22:32:19,392 - INFO - Epoch 2980/3000 | Reward: 1708.0 | Running reward: 2135.5 | Max tile: 64 | Exploration: 0.40
2025-02-27 22:32:38,060 - INFO - Epoch 2990/3000 | Reward: 2283.9 | Running reward: 2038.3 | Max tile: 128 | Exploration: 0.40
2025-02-27 22:33:00,694 - INFO - Epoch 3000/3000 | Reward: 1827.2 | Running reward: 2173.6 | Max tile: 128 | Exploration: 0.40
2025-02-27 22:33:00,694 - INFO - Training complete!
2025-02-27 22:33:00,694 - INFO - Best reward achieved: 2550.7
2025-02-27 22:33:00,695 - INFO - Highest tile achieved: 512
2025-02-27 22:33:00,699 - INFO - Running final evaluation
2025-02-27 22:33:01,512 - INFO - Game 1: Score = 1548, Max Tile = 128
2025-02-27 22:33:02,338 - INFO - Game 2: Score = 1540, Max Tile = 128
2025-02-27 22:33:03,378 - INFO - Game 3: Score = 2328, Max Tile = 256
2025-02-27 22:33:04,480 - INFO - Game 4: Score = 2204, Max Tile = 128
2025-02-27 22:33:05,111 - INFO - Game 5: Score = 1116, Max Tile = 128
2025-02-27 22:33:06,047 - INFO - Game 6: Score = 2168, Max Tile = 256
2025-02-27 22:33:06,961 - INFO - Game 7: Score = 1708, Max Tile = 128
2025-02-27 22:33:08,440 - INFO - Game 8: Score = 3604, Max Tile = 256
2025-02-27 22:33:09,760 - INFO - Game 9: Score = 3088, Max Tile = 256
2025-02-27 22:33:10,521 - INFO - Game 10: Score = 1356, Max Tile = 128
2025-02-27 22:33:11,535 - INFO - Game 11: Score = 2292, Max Tile = 256
2025-02-27 22:33:12,791 - INFO - Game 12: Score = 2864, Max Tile = 256
2025-02-27 22:33:14,119 - INFO - Game 13: Score = 3100, Max Tile = 256
2025-02-27 22:33:15,623 - INFO - Game 14: Score = 3444, Max Tile = 256
2025-02-27 22:33:16,482 - INFO - Game 15: Score = 1628, Max Tile = 128
2025-02-27 22:33:17,338 - INFO - Game 16: Score = 1612, Max Tile = 128
2025-02-27 22:33:18,166 - INFO - Game 17: Score = 1452, Max Tile = 128
2025-02-27 22:33:19,595 - INFO - Game 18: Score = 3348, Max Tile = 256
2025-02-27 22:33:20,726 - INFO - Game 19: Score = 2480, Max Tile = 256
2025-02-27 22:33:22,425 - INFO - Game 20: Score = 3888, Max Tile = 256
2025-02-27 22:33:22,425 - INFO - ========================================
2025-02-27 22:33:22,426 - INFO - Evaluation over 20 games:
2025-02-27 22:33:22,426 - INFO - Average Score: 2338.4
2025-02-27 22:33:22,426 - INFO - Average Max Tile: 198.4
2025-02-27 22:33:22,426 - INFO - Best Max Tile: 256
2025-02-27 22:33:22,427 - INFO - Tile distribution:
2025-02-27 22:33:22,427 - INFO -   128: 9 games (45.0%)
2025-02-27 22:33:22,427 - INFO -   256: 11 games (55.0%)
2025-02-27 22:33:22,428 - INFO - Final best tile: 256
2025-02-28 00:42:51,589 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-28 00:42:51,590 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-28 00:42:51,590 - INFO - MCTS Simulations: 75
2025-02-28 00:42:51,590 - INFO - MCTS Temperature: 1.0
2025-02-28 00:42:51,590 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 00:42:51,590 - INFO - Learning rate: 0.0008
2025-02-28 00:42:51,590 - INFO - Device: cuda
2025-02-28 00:42:51,591 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 00:42:51,710 - INFO - Resuming from epoch 1
2025-02-28 00:42:51,710 - INFO - Running evaluation
2025-02-28 00:46:24,595 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-28 00:46:24,595 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-28 00:46:24,596 - INFO - MCTS Simulations: 75
2025-02-28 00:46:24,596 - INFO - MCTS Temperature: 1.0
2025-02-28 00:46:24,596 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 00:46:24,597 - INFO - Learning rate: 0.0008
2025-02-28 00:46:24,597 - INFO - Device: cuda
2025-02-28 00:46:24,597 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 00:46:24,704 - INFO - Resuming from epoch 1
2025-02-28 00:46:24,704 - INFO - Running evaluation
2025-02-28 00:49:26,905 - INFO - Game 1: Score = 3076, Max Tile = 256
2025-02-28 00:54:22,692 - INFO - Game 2: Score = 5280, Max Tile = 512
2025-02-28 00:59:41,190 - INFO - Game 3: Score = 5648, Max Tile = 512
2025-02-28 00:59:41,191 - INFO - ========================================
2025-02-28 00:59:41,191 - INFO - Evaluation over 3 games:
2025-02-28 00:59:41,192 - INFO - Average Score: 4668.0
2025-02-28 00:59:41,192 - INFO - Average Max Tile: 426.7
2025-02-28 00:59:41,192 - INFO - Best Max Tile: 512
2025-02-28 00:59:41,193 - INFO - Tile distribution:
2025-02-28 00:59:41,193 - INFO -   256: 1 games (33.3%)
2025-02-28 00:59:41,193 - INFO -   512: 2 games (66.7%)
2025-02-28 00:59:41,193 - INFO - Evaluation complete. Best tile: 512
2025-02-28 01:09:36,659 - INFO - === 2048 Enhanced Training/Evaluation ===
2025-02-28 01:09:36,659 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 01:09:36,659 - INFO - Learning rate: 0.0008
2025-02-28 01:09:36,660 - INFO - Device: cuda
2025-02-28 01:09:36,661 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 01:09:36,765 - INFO - Resuming from epoch 1
2025-02-28 01:09:36,765 - INFO - Running evaluation
2025-02-28 01:09:36,774 - INFO - Comparing regular agent with MCTS agent (75 simulations)
2025-02-28 01:09:36,775 - INFO - Evaluating regular agent...
2025-02-28 01:09:36,775 - INFO - Starting game 1/5
2025-02-28 01:09:37,243 - INFO - Game 1: Achieved 64 tile!
2025-02-28 01:09:37,818 - INFO - Game 1: Achieved 128 tile!
2025-02-28 01:09:37,945 - INFO - Game 1/5 completed: Score = 2032, Max Tile = 128, Steps = 179
2025-02-28 01:09:37,946 - INFO - Starting game 2/5
2025-02-28 01:09:38,246 - INFO - Game 2: Achieved 64 tile!
2025-02-28 01:09:38,310 - INFO - Game 2: Achieved 128 tile!
2025-02-28 01:09:38,782 - INFO - Game 2/5 completed: Score = 1556, Max Tile = 128, Steps = 158
2025-02-28 01:09:38,783 - INFO - Starting game 3/5
2025-02-28 01:09:39,050 - INFO - Game 3: Achieved 64 tile!
2025-02-28 01:09:39,273 - INFO - Game 3: Achieved 128 tile!
2025-02-28 01:09:39,647 - INFO - Game 3/5 completed: Score = 1696, Max Tile = 128, Steps = 160
2025-02-28 01:09:39,648 - INFO - Starting game 4/5
2025-02-28 01:09:39,945 - INFO - Game 4: Achieved 64 tile!
2025-02-28 01:09:40,264 - INFO - Game 4/5 completed: Score = 976, Max Tile = 64, Steps = 112
2025-02-28 01:09:40,265 - INFO - Starting game 5/5
2025-02-28 01:09:40,543 - INFO - Game 5: Achieved 64 tile!
2025-02-28 01:09:40,808 - INFO - Game 5: Achieved 128 tile!
2025-02-28 01:09:41,189 - INFO - Game 5: Achieved 256 tile!
2025-02-28 01:09:41,877 - INFO - Game 5/5 completed: Score = 3872, Max Tile = 256, Steps = 303
2025-02-28 01:09:41,877 - INFO - ========================================
2025-02-28 01:09:41,878 - INFO - Evaluation over 5 games:
2025-02-28 01:09:41,878 - INFO - Average Max Tile: 140.8
2025-02-28 01:09:41,879 - INFO - Average Score: 2026.4
2025-02-28 01:09:41,879 - INFO - Average Steps: 182.4
2025-02-28 01:09:41,879 - INFO - Best Max Tile: 256
2025-02-28 01:09:41,879 - INFO - Tile distribution:
2025-02-28 01:09:41,879 - INFO -   64: 1 games (20.0%)
2025-02-28 01:09:41,880 - INFO -   128: 3 games (60.0%)
2025-02-28 01:09:41,880 - INFO -   256: 1 games (20.0%)
2025-02-28 01:09:41,880 - INFO - Average steps to achieve tile:
2025-02-28 01:09:41,880 - INFO -   16: 13.6 steps
2025-02-28 01:09:41,881 - INFO -   32: 28.4 steps
2025-02-28 01:09:41,881 - INFO - 
Evaluating MCTS agent...
2025-02-28 01:09:41,881 - INFO - Starting game 1/5
2025-02-28 01:10:21,513 - INFO - Game 1: Achieved 64 tile!
2025-02-28 01:10:48,508 - INFO - Game 1: Achieved 128 tile!
2025-02-28 01:11:31,813 - INFO - Game 1: Achieved 256 tile!
2025-02-28 07:33:02,316 - INFO - Game 1/5 completed: Score = 3228, Max Tile = 256, Steps = 253
2025-02-28 07:33:02,317 - INFO - Starting game 2/5
2025-02-28 07:33:36,217 - INFO - Game 2: Achieved 64 tile!
2025-02-28 07:33:59,826 - INFO - Game 2: Achieved 128 tile!
2025-02-28 07:35:02,811 - INFO - Game 2: Achieved 256 tile!
2025-02-28 07:36:56,968 - INFO - Game 2: Achieved 512 tile!
2025-02-28 07:39:41,489 - INFO - Game 2/5 completed: Score = 6912, Max Tile = 512, Steps = 441
2025-02-28 07:39:41,490 - INFO - Starting game 3/5
2025-02-28 07:40:10,638 - INFO - Game 3: Achieved 64 tile!
2025-02-28 07:40:59,773 - INFO - Game 3: Achieved 128 tile!
2025-02-28 07:41:20,959 - INFO - Game 3: Achieved 256 tile!
2025-02-28 07:42:08,703 - INFO - Game 3/5 completed: Score = 2308, Max Tile = 256, Steps = 186
2025-02-28 07:42:08,703 - INFO - Starting game 4/5
2025-02-28 07:42:53,133 - INFO - Game 4: Achieved 64 tile!
2025-02-28 07:43:03,699 - INFO - Game 4: Achieved 128 tile!
2025-02-28 07:44:00,702 - INFO - Game 4: Achieved 256 tile!
2025-02-28 07:46:01,270 - INFO - Game 4: Achieved 512 tile!
2025-02-28 07:49:52,729 - INFO - Game 4/5 completed: Score = 7256, Max Tile = 512, Steps = 470
2025-02-28 07:49:52,730 - INFO - Starting game 5/5
2025-02-28 07:50:28,606 - INFO - Game 5: Achieved 64 tile!
2025-02-28 07:50:51,882 - INFO - Game 5: Achieved 128 tile!
2025-02-28 07:51:44,147 - INFO - Game 5: Achieved 256 tile!
2025-02-28 07:52:24,590 - INFO - Game 5/5 completed: Score = 2412, Max Tile = 256, Steps = 192
2025-02-28 07:52:24,590 - INFO - ========================================
2025-02-28 07:52:24,591 - INFO - Evaluation over 5 games:
2025-02-28 07:52:24,591 - INFO - Average Max Tile: 358.4
2025-02-28 07:52:24,591 - INFO - Average Score: 4423.2
2025-02-28 07:52:24,591 - INFO - Average Steps: 308.4
2025-02-28 07:52:24,591 - INFO - Best Max Tile: 512
2025-02-28 07:52:24,592 - INFO - Tile distribution:
2025-02-28 07:52:24,592 - INFO -   256: 3 games (60.0%)
2025-02-28 07:52:24,592 - INFO -   512: 2 games (40.0%)
2025-02-28 07:52:24,592 - INFO - Average steps to achieve tile:
2025-02-28 07:52:24,593 - INFO -   16: 10.2 steps
2025-02-28 07:52:24,593 - INFO -   32: 28.8 steps
2025-02-28 07:52:24,593 - INFO - 
==================================================
2025-02-28 07:52:24,593 - INFO - COMPARISON RESULTS:
2025-02-28 07:52:24,593 - INFO - Average Max Tile: Regular = 140.8, MCTS = 358.4
2025-02-28 07:52:24,594 - INFO - Average Score: Regular = 2026.4, MCTS = 4423.2
2025-02-28 07:52:24,594 - INFO - Best Max Tile: Regular = 256, MCTS = 512
2025-02-28 07:52:26,846 - INFO - Testing with 5 simulations...
2025-02-28 07:52:26,846 - INFO - Starting game 1/2
2025-02-28 07:52:29,143 - INFO - Game 1: Achieved 64 tile!
2025-02-28 07:52:30,671 - INFO - Game 1/2 completed: Score = 768, Max Tile = 64, Steps = 87
2025-02-28 07:52:30,672 - INFO - Starting game 2/2
2025-02-28 07:52:32,959 - INFO - Game 2: Achieved 64 tile!
2025-02-28 07:52:35,376 - INFO - Game 2: Achieved 128 tile!
2025-02-28 07:52:35,865 - INFO - Game 2/2 completed: Score = 1196, Max Tile = 128, Steps = 120
2025-02-28 07:52:35,866 - INFO - ========================================
2025-02-28 07:52:35,866 - INFO - Evaluation over 2 games:
2025-02-28 07:52:35,867 - INFO - Average Max Tile: 96.0
2025-02-28 07:52:35,867 - INFO - Average Score: 982.0
2025-02-28 07:52:35,867 - INFO - Average Steps: 103.5
2025-02-28 07:52:35,867 - INFO - Best Max Tile: 128
2025-02-28 07:52:35,867 - INFO - Tile distribution:
2025-02-28 07:52:35,867 - INFO -   64: 1 games (50.0%)
2025-02-28 07:52:35,867 - INFO -   128: 1 games (50.0%)
2025-02-28 07:52:35,867 - INFO - Average steps to achieve tile:
2025-02-28 07:52:35,867 - INFO -   16: 11.5 steps
2025-02-28 07:52:35,868 - INFO -   32: 25.0 steps
2025-02-28 07:52:35,868 - INFO - Testing with 10 simulations...
2025-02-28 07:52:35,868 - INFO - Starting game 1/2
2025-02-28 07:52:40,709 - INFO - Game 1: Achieved 64 tile!
2025-02-28 07:52:41,874 - INFO - Game 1: Achieved 128 tile!
2025-02-28 07:52:46,107 - INFO - Game 1/2 completed: Score = 1272, Max Tile = 128, Steps = 124
2025-02-28 07:52:46,107 - INFO - Starting game 2/2
2025-02-28 07:52:49,808 - INFO - Game 2: Achieved 64 tile!
2025-02-28 07:52:52,233 - INFO - Game 2/2 completed: Score = 596, Max Tile = 64, Steps = 76
2025-02-28 07:52:52,234 - INFO - ========================================
2025-02-28 07:52:52,235 - INFO - Evaluation over 2 games:
2025-02-28 07:52:52,235 - INFO - Average Max Tile: 96.0
2025-02-28 07:52:52,235 - INFO - Average Score: 934.0
2025-02-28 07:52:52,235 - INFO - Average Steps: 100.0
2025-02-28 07:52:52,235 - INFO - Best Max Tile: 128
2025-02-28 07:52:52,236 - INFO - Tile distribution:
2025-02-28 07:52:52,236 - INFO -   64: 1 games (50.0%)
2025-02-28 07:52:52,236 - INFO -   128: 1 games (50.0%)
2025-02-28 07:52:52,236 - INFO - Average steps to achieve tile:
2025-02-28 07:52:52,237 - INFO -   16: 11.5 steps
2025-02-28 07:52:52,237 - INFO -   32: 24.0 steps
2025-02-28 07:52:52,237 - INFO - Testing with 25 simulations...
2025-02-28 07:52:52,237 - INFO - Starting game 1/2
2025-02-28 07:53:03,595 - INFO - Game 1: Achieved 64 tile!
2025-02-28 07:53:16,423 - INFO - Game 1: Achieved 128 tile!
2025-02-28 07:53:24,289 - INFO - Game 1: Achieved 256 tile!
2025-02-28 07:53:51,979 - INFO - Game 1: Achieved 512 tile!
2025-02-28 07:54:21,884 - INFO - Game 1/2 completed: Score = 5252, Max Tile = 512, Steps = 348
2025-02-28 07:54:21,885 - INFO - Starting game 2/2
2025-02-28 07:54:33,328 - INFO - Game 2: Achieved 64 tile!
2025-02-28 07:54:41,248 - INFO - Game 2: Achieved 128 tile!
2025-02-28 07:54:53,728 - INFO - Game 2: Achieved 256 tile!
2025-02-28 07:55:17,828 - INFO - Game 2/2 completed: Score = 3252, Max Tile = 256, Steps = 249
2025-02-28 07:55:17,828 - INFO - ========================================
2025-02-28 07:55:17,828 - INFO - Evaluation over 2 games:
2025-02-28 07:55:17,829 - INFO - Average Max Tile: 384.0
2025-02-28 07:55:17,829 - INFO - Average Score: 4252.0
2025-02-28 07:55:17,830 - INFO - Average Steps: 298.5
2025-02-28 07:55:17,830 - INFO - Best Max Tile: 512
2025-02-28 07:55:17,830 - INFO - Tile distribution:
2025-02-28 07:55:17,830 - INFO -   256: 1 games (50.0%)
2025-02-28 07:55:17,831 - INFO -   512: 1 games (50.0%)
2025-02-28 07:55:17,831 - INFO - Average steps to achieve tile:
2025-02-28 07:55:17,831 - INFO -   16: 8.0 steps
2025-02-28 07:55:17,831 - INFO -   32: 20.0 steps
2025-02-28 07:55:17,831 - INFO - Testing with 50 simulations...
2025-02-28 07:55:17,832 - INFO - Starting game 1/2
2025-02-28 07:55:41,114 - INFO - Game 1: Achieved 64 tile!
2025-02-28 07:55:51,094 - INFO - Game 1: Achieved 128 tile!
2025-02-28 07:56:23,159 - INFO - Game 1: Achieved 256 tile!
2025-02-28 07:57:26,073 - INFO - Game 1: Achieved 512 tile!
2025-02-28 08:00:05,852 - INFO - Game 1/2 completed: Score = 7324, Max Tile = 512, Steps = 471
2025-02-28 08:00:05,852 - INFO - Starting game 2/2
2025-02-28 08:00:24,160 - INFO - Game 2: Achieved 64 tile!
2025-02-28 08:00:55,639 - INFO - Game 2: Achieved 128 tile!
2025-02-28 08:01:24,599 - INFO - Game 2: Achieved 256 tile!
2025-02-28 08:02:05,134 - INFO - Game 2/2 completed: Score = 3080, Max Tile = 256, Steps = 244
2025-02-28 08:02:05,135 - INFO - ========================================
2025-02-28 08:02:05,135 - INFO - Evaluation over 2 games:
2025-02-28 08:02:05,135 - INFO - Average Max Tile: 384.0
2025-02-28 08:02:05,136 - INFO - Average Score: 5202.0
2025-02-28 08:02:05,136 - INFO - Average Steps: 357.5
2025-02-28 08:02:05,136 - INFO - Best Max Tile: 512
2025-02-28 08:02:05,137 - INFO - Tile distribution:
2025-02-28 08:02:05,137 - INFO -   256: 1 games (50.0%)
2025-02-28 08:02:05,137 - INFO -   512: 1 games (50.0%)
2025-02-28 08:02:05,137 - INFO - Average steps to achieve tile:
2025-02-28 08:02:05,137 - INFO -   16: 13.0 steps
2025-02-28 08:02:05,137 - INFO -   32: 22.5 steps
2025-02-28 08:02:05,137 - INFO - Testing with 100 simulations...
2025-02-28 08:02:05,138 - INFO - Starting game 1/2
2025-02-28 08:02:51,971 - INFO - Game 1: Achieved 64 tile!
2025-02-28 08:03:27,476 - INFO - Game 1: Achieved 128 tile!
2025-02-28 08:04:11,893 - INFO - Game 1: Achieved 256 tile!
2025-02-28 08:06:49,404 - INFO - Game 1: Achieved 512 tile!
2025-02-28 08:10:16,443 - INFO - Game 1/2 completed: Score = 6124, Max Tile = 512, Steps = 389
2025-02-28 08:10:16,443 - INFO - Starting game 2/2
2025-02-28 08:11:06,222 - INFO - Game 2: Achieved 64 tile!
2025-02-28 08:11:38,967 - INFO - Game 2: Achieved 128 tile!
2025-02-28 08:12:31,918 - INFO - Game 2: Achieved 256 tile!
2025-02-28 08:14:40,897 - INFO - Game 2: Achieved 512 tile!
2025-02-28 08:21:05,052 - INFO - Game 2: Achieved 1024 tile!
2025-02-28 08:28:11,850 - INFO - Game 2/2 completed: Score = 11892, Max Tile = 1024, Steps = 664
2025-02-28 08:28:11,850 - INFO - ========================================
2025-02-28 08:28:11,850 - INFO - Evaluation over 2 games:
2025-02-28 08:28:11,852 - INFO - Average Max Tile: 768.0
2025-02-28 08:28:11,852 - INFO - Average Score: 9008.0
2025-02-28 08:28:11,852 - INFO - Average Steps: 526.5
2025-02-28 08:28:11,852 - INFO - Best Max Tile: 1024
2025-02-28 08:28:11,852 - INFO - Tile distribution:
2025-02-28 08:28:11,853 - INFO -   512: 1 games (50.0%)
2025-02-28 08:28:11,853 - INFO -   1024: 1 games (50.0%)
2025-02-28 08:28:11,853 - INFO - Average steps to achieve tile:
2025-02-28 08:28:11,853 - INFO -   16: 10.0 steps
2025-02-28 08:28:11,853 - INFO -   32: 21.5 steps
2025-02-28 08:28:11,854 - INFO - Testing with 200 simulations...
2025-02-28 08:28:11,854 - INFO - Starting game 1/2
2025-02-28 08:29:30,971 - INFO - Game 1: Achieved 64 tile!
2025-02-28 08:31:18,365 - INFO - Game 1: Achieved 128 tile!
2025-02-28 08:33:01,474 - INFO - Game 1: Achieved 256 tile!
2025-02-28 08:37:30,972 - INFO - Game 1: Achieved 512 tile!
2025-02-28 08:51:55,944 - INFO - Game 1/2 completed: Score = 7460, Max Tile = 512, Steps = 484
2025-02-28 08:51:55,945 - INFO - Starting game 2/2
2025-02-28 08:53:52,997 - INFO - Game 2: Achieved 64 tile!
2025-02-28 08:55:27,723 - INFO - Game 2: Achieved 128 tile!
2025-02-28 08:56:46,424 - INFO - Game 2: Achieved 256 tile!
2025-02-28 09:01:22,949 - INFO - Game 2: Achieved 512 tile!
2025-02-28 09:15:10,806 - INFO - Game 2: Achieved 1024 tile!
2025-02-28 09:45:51,132 - INFO - Game 2/2 completed: Score = 15480, Max Tile = 1024, Steps = 848
2025-02-28 09:45:51,133 - INFO - ========================================
2025-02-28 09:45:51,133 - INFO - Evaluation over 2 games:
2025-02-28 09:45:51,134 - INFO - Average Max Tile: 768.0
2025-02-28 09:45:51,134 - INFO - Average Score: 11470.0
2025-02-28 09:45:51,134 - INFO - Average Steps: 666.0
2025-02-28 09:45:51,135 - INFO - Best Max Tile: 1024
2025-02-28 09:45:51,135 - INFO - Tile distribution:
2025-02-28 09:45:51,135 - INFO -   512: 1 games (50.0%)
2025-02-28 09:45:51,135 - INFO -   1024: 1 games (50.0%)
2025-02-28 09:45:51,135 - INFO - Average steps to achieve tile:
2025-02-28 09:45:51,136 - INFO -   16: 10.0 steps
2025-02-28 09:45:51,136 - INFO -   32: 19.0 steps
2025-02-28 09:45:51,144 - INFO - Testing with temperature 0.1...
2025-02-28 09:45:51,144 - INFO - Starting game 1/2
2025-02-28 09:46:22,395 - INFO - Game 1: Achieved 64 tile!
2025-02-28 09:46:54,188 - INFO - Game 1: Achieved 128 tile!
2025-02-28 09:47:23,118 - INFO - Game 1: Achieved 256 tile!
2025-02-28 09:48:57,606 - INFO - Game 1/2 completed: Score = 3080, Max Tile = 256, Steps = 238
2025-02-28 09:48:57,606 - INFO - Starting game 2/2
2025-02-28 09:49:28,572 - INFO - Game 2: Achieved 64 tile!
2025-02-28 09:50:03,833 - INFO - Game 2: Achieved 128 tile!
2025-02-28 09:50:30,446 - INFO - Game 2/2 completed: Score = 1316, Max Tile = 128, Steps = 131
2025-02-28 09:50:30,447 - INFO - ========================================
2025-02-28 09:50:30,447 - INFO - Evaluation over 2 games:
2025-02-28 09:50:30,447 - INFO - Average Max Tile: 192.0
2025-02-28 09:50:30,447 - INFO - Average Score: 2198.0
2025-02-28 09:50:30,448 - INFO - Average Steps: 184.5
2025-02-28 09:50:30,449 - INFO - Best Max Tile: 256
2025-02-28 09:50:30,449 - INFO - Tile distribution:
2025-02-28 09:50:30,449 - INFO -   128: 1 games (50.0%)
2025-02-28 09:50:30,449 - INFO -   256: 1 games (50.0%)
2025-02-28 09:50:30,450 - INFO - Average steps to achieve tile:
2025-02-28 09:50:30,450 - INFO -   16: 7.0 steps
2025-02-28 09:50:30,450 - INFO -   32: 26.0 steps
2025-02-28 09:50:30,450 - INFO - Testing with temperature 0.5...
2025-02-28 09:50:30,450 - INFO - Starting game 1/2
2025-02-28 09:50:57,106 - INFO - Game 1: Achieved 64 tile!
2025-02-28 09:51:19,527 - INFO - Game 1: Achieved 128 tile!
2025-02-28 09:52:26,352 - INFO - Game 1: Achieved 256 tile!
2025-02-28 09:52:59,691 - INFO - Game 1/2 completed: Score = 2548, Max Tile = 256, Steps = 202
2025-02-28 09:52:59,692 - INFO - Starting game 2/2
2025-02-28 09:53:27,885 - INFO - Game 2: Achieved 64 tile!
2025-02-28 09:53:59,280 - INFO - Game 2: Achieved 128 tile!
2025-02-28 09:54:38,731 - INFO - Game 2: Achieved 256 tile!
2025-02-28 09:56:21,224 - INFO - Game 2: Achieved 512 tile!
2025-02-28 10:00:44,246 - INFO - Game 2: Achieved 1024 tile!
2025-02-28 10:03:16,466 - INFO - Game 2/2 completed: Score = 10356, Max Tile = 1024, Steps = 571
2025-02-28 10:03:16,466 - INFO - ========================================
2025-02-28 10:03:16,467 - INFO - Evaluation over 2 games:
2025-02-28 10:03:16,467 - INFO - Average Max Tile: 640.0
2025-02-28 10:03:16,467 - INFO - Average Score: 6452.0
2025-02-28 10:03:16,467 - INFO - Average Steps: 386.5
2025-02-28 10:03:16,467 - INFO - Best Max Tile: 1024
2025-02-28 10:03:16,468 - INFO - Tile distribution:
2025-02-28 10:03:16,468 - INFO -   256: 1 games (50.0%)
2025-02-28 10:03:16,468 - INFO -   1024: 1 games (50.0%)
2025-02-28 10:03:16,468 - INFO - Average steps to achieve tile:
2025-02-28 10:03:16,469 - INFO -   16: 10.0 steps
2025-02-28 10:03:16,469 - INFO -   32: 19.5 steps
2025-02-28 10:03:16,469 - INFO - Testing with temperature 1.0...
2025-02-28 10:03:16,469 - INFO - Starting game 1/2
2025-02-28 10:03:50,003 - INFO - Game 1: Achieved 64 tile!
2025-02-28 10:04:15,312 - INFO - Game 1: Achieved 128 tile!
2025-02-28 10:04:56,595 - INFO - Game 1: Achieved 256 tile!
2025-02-28 10:06:32,675 - INFO - Game 1/2 completed: Score = 3152, Max Tile = 256, Steps = 251
2025-02-28 10:06:32,676 - INFO - Starting game 2/2
2025-02-28 10:07:00,992 - INFO - Game 2: Achieved 64 tile!
2025-02-28 10:07:23,776 - INFO - Game 2: Achieved 128 tile!
2025-02-28 10:08:46,824 - INFO - Game 2: Achieved 256 tile!
2025-02-28 10:09:41,777 - INFO - Game 2/2 completed: Score = 3180, Max Tile = 256, Steps = 257
2025-02-28 10:09:41,778 - INFO - ========================================
2025-02-28 10:09:41,778 - INFO - Evaluation over 2 games:
2025-02-28 10:09:41,778 - INFO - Average Max Tile: 256.0
2025-02-28 10:09:41,778 - INFO - Average Score: 3166.0
2025-02-28 10:09:41,779 - INFO - Average Steps: 254.0
2025-02-28 10:09:41,779 - INFO - Best Max Tile: 256
2025-02-28 10:09:41,780 - INFO - Tile distribution:
2025-02-28 10:09:41,780 - INFO -   256: 2 games (100.0%)
2025-02-28 10:09:41,780 - INFO - Average steps to achieve tile:
2025-02-28 10:09:41,780 - INFO -   16: 13.0 steps
2025-02-28 10:09:41,781 - INFO -   32: 19.5 steps
2025-02-28 10:09:41,781 - INFO - Testing with temperature 1.5...
2025-02-28 10:09:41,781 - INFO - Starting game 1/2
2025-02-28 10:10:09,843 - INFO - Game 1: Achieved 64 tile!
2025-02-28 10:10:32,252 - INFO - Game 1: Achieved 128 tile!
2025-02-28 10:11:25,330 - INFO - Game 1: Achieved 256 tile!
2025-02-28 10:14:06,082 - INFO - Game 1: Achieved 512 tile!
2025-02-28 10:16:37,620 - INFO - Game 1/2 completed: Score = 6972, Max Tile = 512, Steps = 454
2025-02-28 10:16:37,621 - INFO - Starting game 2/2
2025-02-28 10:17:10,901 - INFO - Game 2: Achieved 64 tile!
2025-02-28 10:17:19,996 - INFO - Game 2: Achieved 128 tile!
2025-02-28 10:18:23,247 - INFO - Game 2/2 completed: Score = 1588, Max Tile = 128, Steps = 150
2025-02-28 10:18:23,248 - INFO - ========================================
2025-02-28 10:18:23,248 - INFO - Evaluation over 2 games:
2025-02-28 10:18:23,248 - INFO - Average Max Tile: 320.0
2025-02-28 10:18:23,248 - INFO - Average Score: 4280.0
2025-02-28 10:18:23,249 - INFO - Average Steps: 302.0
2025-02-28 10:18:23,249 - INFO - Best Max Tile: 512
2025-02-28 10:18:23,249 - INFO - Tile distribution:
2025-02-28 10:18:23,249 - INFO -   128: 1 games (50.0%)
2025-02-28 10:18:23,250 - INFO -   512: 1 games (50.0%)
2025-02-28 10:18:23,250 - INFO - Average steps to achieve tile:
2025-02-28 10:18:23,250 - INFO -   16: 14.5 steps
2025-02-28 10:18:23,250 - INFO -   32: 23.5 steps
2025-02-28 10:18:23,251 - INFO - Testing with temperature 2.0...
2025-02-28 10:18:23,251 - INFO - Starting game 1/2
2025-02-28 10:18:58,567 - INFO - Game 1: Achieved 64 tile!
2025-02-28 10:19:17,085 - INFO - Game 1: Achieved 128 tile!
2025-02-28 10:20:04,660 - INFO - Game 1: Achieved 256 tile!
2025-02-28 10:21:57,713 - INFO - Game 1: Achieved 512 tile!
2025-02-28 10:25:31,816 - INFO - Game 1/2 completed: Score = 7152, Max Tile = 512, Steps = 460
2025-02-28 10:25:31,818 - INFO - Starting game 2/2
2025-02-28 10:25:55,521 - INFO - Game 2: Achieved 64 tile!
2025-02-28 10:26:21,546 - INFO - Game 2: Achieved 128 tile!
2025-02-28 10:27:12,244 - INFO - Game 2: Achieved 256 tile!
2025-02-28 10:28:46,039 - INFO - Game 2: Achieved 512 tile!
2025-02-28 10:32:21,178 - INFO - Game 2/2 completed: Score = 6836, Max Tile = 512, Steps = 440
2025-02-28 10:32:21,179 - INFO - ========================================
2025-02-28 10:32:21,179 - INFO - Evaluation over 2 games:
2025-02-28 10:32:21,180 - INFO - Average Max Tile: 512.0
2025-02-28 10:32:21,180 - INFO - Average Score: 6994.0
2025-02-28 10:32:21,180 - INFO - Average Steps: 450.0
2025-02-28 10:32:21,180 - INFO - Best Max Tile: 512
2025-02-28 10:32:21,180 - INFO - Tile distribution:
2025-02-28 10:32:21,181 - INFO -   512: 2 games (100.0%)
2025-02-28 10:32:21,181 - INFO - Average steps to achieve tile:
2025-02-28 10:32:21,181 - INFO -   16: 9.0 steps
2025-02-28 10:32:21,181 - INFO -   32: 28.5 steps
2025-02-28 14:45:58,800 - INFO - === 2048 Enhanced Training/Evaluation ===
2025-02-28 14:45:58,801 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 14:45:58,801 - INFO - Learning rate: 0.0008
2025-02-28 14:45:58,801 - INFO - Device: cuda
2025-02-28 14:45:58,802 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 14:45:58,921 - INFO - Resuming from epoch 1
2025-02-28 14:45:58,921 - INFO - Running evaluation
2025-02-28 14:45:58,925 - INFO - Comparing regular agent with MCTS agent (75 simulations)
2025-02-28 14:45:58,925 - INFO - Evaluating regular agent...
2025-02-28 14:45:58,926 - INFO - Starting game 1/5
2025-02-28 14:45:59,369 - INFO - Game 1: Achieved 64 tile!
2025-02-28 14:45:59,938 - INFO - Game 1: Achieved 128 tile!
2025-02-28 14:46:00,060 - INFO - Game 1/5 completed: Score = 2032, Max Tile = 128, Steps = 179
2025-02-28 14:46:00,061 - INFO - Starting game 2/5
2025-02-28 14:46:00,364 - INFO - Game 2: Achieved 64 tile!
2025-02-28 14:46:00,435 - INFO - Game 2: Achieved 128 tile!
2025-02-28 14:46:00,914 - INFO - Game 2/5 completed: Score = 1556, Max Tile = 128, Steps = 158
2025-02-28 14:46:00,915 - INFO - Starting game 3/5
2025-02-28 14:46:01,170 - INFO - Game 3: Achieved 64 tile!
2025-02-28 14:46:01,395 - INFO - Game 3: Achieved 128 tile!
2025-02-28 14:46:01,756 - INFO - Game 3/5 completed: Score = 1696, Max Tile = 128, Steps = 160
2025-02-28 14:46:01,757 - INFO - Starting game 4/5
2025-02-28 14:46:02,046 - INFO - Game 4: Achieved 64 tile!
2025-02-28 14:46:02,361 - INFO - Game 4/5 completed: Score = 976, Max Tile = 64, Steps = 112
2025-02-28 14:46:02,362 - INFO - Starting game 5/5
2025-02-28 14:46:02,633 - INFO - Game 5: Achieved 64 tile!
2025-02-28 14:46:02,895 - INFO - Game 5: Achieved 128 tile!
2025-02-28 14:46:03,272 - INFO - Game 5: Achieved 256 tile!
2025-02-28 14:46:03,975 - INFO - Game 5/5 completed: Score = 3872, Max Tile = 256, Steps = 303
2025-02-28 14:46:03,976 - INFO - ========================================
2025-02-28 14:46:03,976 - INFO - Evaluation over 5 games:
2025-02-28 14:46:03,976 - INFO - Average Max Tile: 140.8
2025-02-28 14:46:03,976 - INFO - Average Score: 2026.4
2025-02-28 14:46:03,978 - INFO - Average Steps: 182.4
2025-02-28 14:46:03,978 - INFO - Best Max Tile: 256
2025-02-28 14:46:03,978 - INFO - Tile distribution:
2025-02-28 14:46:03,978 - INFO -   64: 1 games (20.0%)
2025-02-28 14:46:03,979 - INFO -   128: 3 games (60.0%)
2025-02-28 14:46:03,979 - INFO -   256: 1 games (20.0%)
2025-02-28 14:46:03,979 - INFO - Average steps to achieve tile:
2025-02-28 14:46:03,979 - INFO -   16: 13.6 steps
2025-02-28 14:46:03,980 - INFO -   32: 28.4 steps
2025-02-28 14:46:03,980 - INFO - 
Evaluating MCTS agent...
2025-02-28 14:46:03,980 - INFO - Starting game 1/5
2025-02-28 14:46:43,223 - INFO - Game 1: Achieved 64 tile!
2025-02-28 14:47:10,349 - INFO - Game 1: Achieved 128 tile!
2025-02-28 14:47:54,742 - INFO - Game 1: Achieved 256 tile!
2025-02-28 14:49:17,052 - INFO - Game 1/5 completed: Score = 3228, Max Tile = 256, Steps = 253
2025-02-28 14:49:17,053 - INFO - Starting game 2/5
2025-02-28 14:49:49,698 - INFO - Game 2: Achieved 64 tile!
2025-02-28 14:50:12,971 - INFO - Game 2: Achieved 128 tile!
2025-02-28 14:51:15,021 - INFO - Game 2: Achieved 256 tile!
2025-02-28 14:53:07,755 - INFO - Game 2: Achieved 512 tile!
2025-02-28 14:55:51,354 - INFO - Game 2/5 completed: Score = 6912, Max Tile = 512, Steps = 441
2025-02-28 14:55:51,354 - INFO - Starting game 3/5
2025-02-28 14:56:18,577 - INFO - Game 3: Achieved 64 tile!
2025-02-28 14:57:04,338 - INFO - Game 3: Achieved 128 tile!
2025-02-28 14:57:23,983 - INFO - Game 3: Achieved 256 tile!
2025-02-28 14:58:08,704 - INFO - Game 3/5 completed: Score = 2308, Max Tile = 256, Steps = 186
2025-02-28 14:58:08,705 - INFO - Starting game 4/5
2025-02-28 14:58:49,505 - INFO - Game 4: Achieved 64 tile!
2025-02-28 14:58:59,426 - INFO - Game 4: Achieved 128 tile!
2025-02-28 14:59:52,359 - INFO - Game 4: Achieved 256 tile!
2025-02-28 15:01:45,513 - INFO - Game 4: Achieved 512 tile!
2025-02-28 15:05:28,742 - INFO - Game 4/5 completed: Score = 7256, Max Tile = 512, Steps = 470
2025-02-28 15:05:28,742 - INFO - Starting game 5/5
2025-02-28 15:06:04,745 - INFO - Game 5: Achieved 64 tile!
2025-02-28 15:06:28,153 - INFO - Game 5: Achieved 128 tile!
2025-02-28 15:07:18,648 - INFO - Game 5: Achieved 256 tile!
2025-02-28 15:07:58,870 - INFO - Game 5/5 completed: Score = 2412, Max Tile = 256, Steps = 192
2025-02-28 15:07:58,870 - INFO - ========================================
2025-02-28 15:07:58,871 - INFO - Evaluation over 5 games:
2025-02-28 15:07:58,871 - INFO - Average Max Tile: 358.4
2025-02-28 15:07:58,871 - INFO - Average Score: 4423.2
2025-02-28 15:07:58,872 - INFO - Average Steps: 308.4
2025-02-28 15:07:58,872 - INFO - Best Max Tile: 512
2025-02-28 15:07:58,872 - INFO - Tile distribution:
2025-02-28 15:07:58,872 - INFO -   256: 3 games (60.0%)
2025-02-28 15:07:58,872 - INFO -   512: 2 games (40.0%)
2025-02-28 15:07:58,873 - INFO - Average steps to achieve tile:
2025-02-28 15:07:58,873 - INFO -   16: 10.2 steps
2025-02-28 15:07:58,873 - INFO -   32: 28.8 steps
2025-02-28 15:07:58,873 - INFO - 
==================================================
2025-02-28 15:07:58,874 - INFO - COMPARISON RESULTS:
2025-02-28 15:07:58,874 - INFO - Average Max Tile: Regular = 140.8, MCTS = 358.4
2025-02-28 15:07:58,874 - INFO - Average Score: Regular = 2026.4, MCTS = 4423.2
2025-02-28 15:07:58,874 - INFO - Best Max Tile: Regular = 256, MCTS = 512
2025-02-28 15:08:01,148 - INFO - Testing with 5 simulations...
2025-02-28 15:08:01,149 - INFO - Starting game 1/2
2025-02-28 15:08:03,319 - INFO - Game 1: Achieved 64 tile!
2025-02-28 15:08:04,890 - INFO - Game 1/2 completed: Score = 768, Max Tile = 64, Steps = 87
2025-02-28 15:08:04,890 - INFO - Starting game 2/2
2025-02-28 15:08:07,025 - INFO - Game 2: Achieved 64 tile!
2025-02-28 15:08:09,407 - INFO - Game 2: Achieved 128 tile!
2025-02-28 15:08:09,896 - INFO - Game 2/2 completed: Score = 1196, Max Tile = 128, Steps = 120
2025-02-28 15:08:09,896 - INFO - ========================================
2025-02-28 15:08:09,897 - INFO - Evaluation over 2 games:
2025-02-28 15:08:09,897 - INFO - Average Max Tile: 96.0
2025-02-28 15:08:09,897 - INFO - Average Score: 982.0
2025-02-28 15:08:09,898 - INFO - Average Steps: 103.5
2025-02-28 15:08:09,898 - INFO - Best Max Tile: 128
2025-02-28 15:08:09,898 - INFO - Tile distribution:
2025-02-28 15:08:09,898 - INFO -   64: 1 games (50.0%)
2025-02-28 15:08:09,899 - INFO -   128: 1 games (50.0%)
2025-02-28 15:08:09,899 - INFO - Average steps to achieve tile:
2025-02-28 15:08:09,899 - INFO -   16: 11.5 steps
2025-02-28 15:08:09,899 - INFO -   32: 25.0 steps
2025-02-28 15:08:09,900 - INFO - Testing with 10 simulations...
2025-02-28 15:08:09,900 - INFO - Starting game 1/2
2025-02-28 15:08:14,904 - INFO - Game 1: Achieved 64 tile!
2025-02-28 15:08:16,105 - INFO - Game 1: Achieved 128 tile!
2025-02-28 15:08:20,536 - INFO - Game 1/2 completed: Score = 1272, Max Tile = 128, Steps = 124
2025-02-28 15:08:20,536 - INFO - Starting game 2/2
2025-02-28 15:08:24,367 - INFO - Game 2: Achieved 64 tile!
2025-02-28 15:08:26,868 - INFO - Game 2/2 completed: Score = 596, Max Tile = 64, Steps = 76
2025-02-28 15:08:26,869 - INFO - ========================================
2025-02-28 15:08:26,869 - INFO - Evaluation over 2 games:
2025-02-28 15:08:26,870 - INFO - Average Max Tile: 96.0
2025-02-28 15:08:26,870 - INFO - Average Score: 934.0
2025-02-28 15:08:26,870 - INFO - Average Steps: 100.0
2025-02-28 15:08:26,871 - INFO - Best Max Tile: 128
2025-02-28 15:08:26,871 - INFO - Tile distribution:
2025-02-28 15:08:26,871 - INFO -   64: 1 games (50.0%)
2025-02-28 15:08:26,871 - INFO -   128: 1 games (50.0%)
2025-02-28 15:08:26,872 - INFO - Average steps to achieve tile:
2025-02-28 15:08:26,872 - INFO -   16: 11.5 steps
2025-02-28 15:08:26,872 - INFO -   32: 24.0 steps
2025-02-28 15:08:26,872 - INFO - Testing with 25 simulations...
2025-02-28 15:08:26,873 - INFO - Starting game 1/2
2025-02-28 15:08:38,884 - INFO - Game 1: Achieved 64 tile!
2025-02-28 15:08:52,607 - INFO - Game 1: Achieved 128 tile!
2025-02-28 15:09:01,140 - INFO - Game 1: Achieved 256 tile!
2025-02-28 15:09:30,493 - INFO - Game 1: Achieved 512 tile!
2025-02-28 15:10:03,146 - INFO - Game 1/2 completed: Score = 5252, Max Tile = 512, Steps = 348
2025-02-28 15:10:03,147 - INFO - Starting game 2/2
2025-02-28 15:10:14,974 - INFO - Game 2: Achieved 64 tile!
2025-02-28 15:10:22,933 - INFO - Game 2: Achieved 128 tile!
2025-02-28 15:10:36,479 - INFO - Game 2: Achieved 256 tile!
2025-02-28 15:11:02,893 - INFO - Game 2/2 completed: Score = 3252, Max Tile = 256, Steps = 249
2025-02-28 15:11:02,894 - INFO - ========================================
2025-02-28 15:11:02,894 - INFO - Evaluation over 2 games:
2025-02-28 15:11:02,895 - INFO - Average Max Tile: 384.0
2025-02-28 15:11:02,895 - INFO - Average Score: 4252.0
2025-02-28 15:11:02,896 - INFO - Average Steps: 298.5
2025-02-28 15:11:02,896 - INFO - Best Max Tile: 512
2025-02-28 15:11:02,896 - INFO - Tile distribution:
2025-02-28 15:11:02,896 - INFO -   256: 1 games (50.0%)
2025-02-28 15:11:02,896 - INFO -   512: 1 games (50.0%)
2025-02-28 15:11:02,897 - INFO - Average steps to achieve tile:
2025-02-28 15:11:02,897 - INFO -   16: 8.0 steps
2025-02-28 15:11:02,897 - INFO -   32: 20.0 steps
2025-02-28 15:11:02,897 - INFO - Testing with 50 simulations...
2025-02-28 15:11:02,898 - INFO - Starting game 1/2
2025-02-28 15:11:27,801 - INFO - Game 1: Achieved 64 tile!
2025-02-28 15:11:38,590 - INFO - Game 1: Achieved 128 tile!
2025-02-28 15:12:13,073 - INFO - Game 1: Achieved 256 tile!
2025-02-28 15:13:20,979 - INFO - Game 1: Achieved 512 tile!
2025-02-28 15:16:11,887 - INFO - Game 1/2 completed: Score = 7324, Max Tile = 512, Steps = 471
2025-02-28 15:16:11,887 - INFO - Starting game 2/2
2025-02-28 15:16:30,142 - INFO - Game 2: Achieved 64 tile!
2025-02-28 15:17:02,118 - INFO - Game 2: Achieved 128 tile!
2025-02-28 15:17:31,286 - INFO - Game 2: Achieved 256 tile!
2025-02-28 15:18:12,257 - INFO - Game 2/2 completed: Score = 3080, Max Tile = 256, Steps = 244
2025-02-28 15:18:12,257 - INFO - ========================================
2025-02-28 15:18:12,257 - INFO - Evaluation over 2 games:
2025-02-28 15:18:12,257 - INFO - Average Max Tile: 384.0
2025-02-28 15:18:12,257 - INFO - Average Score: 5202.0
2025-02-28 15:18:12,257 - INFO - Average Steps: 357.5
2025-02-28 15:18:12,257 - INFO - Best Max Tile: 512
2025-02-28 15:18:12,259 - INFO - Tile distribution:
2025-02-28 15:18:12,259 - INFO -   256: 1 games (50.0%)
2025-02-28 15:18:12,259 - INFO -   512: 1 games (50.0%)
2025-02-28 15:18:12,259 - INFO - Average steps to achieve tile:
2025-02-28 15:18:12,260 - INFO -   16: 13.0 steps
2025-02-28 15:18:12,260 - INFO -   32: 22.5 steps
2025-02-28 15:18:12,260 - INFO - Testing with 100 simulations...
2025-02-28 15:18:12,260 - INFO - Starting game 1/2
2025-02-28 15:19:00,070 - INFO - Game 1: Achieved 64 tile!
2025-02-28 15:19:36,292 - INFO - Game 1: Achieved 128 tile!
2025-02-28 15:20:21,770 - INFO - Game 1: Achieved 256 tile!
2025-02-28 15:23:01,951 - INFO - Game 1: Achieved 512 tile!
2025-02-28 15:26:31,696 - INFO - Game 1/2 completed: Score = 6124, Max Tile = 512, Steps = 389
2025-02-28 15:26:31,696 - INFO - Starting game 2/2
2025-02-28 15:27:23,591 - INFO - Game 2: Achieved 64 tile!
2025-02-28 15:27:57,205 - INFO - Game 2: Achieved 128 tile!
2025-02-28 15:28:50,796 - INFO - Game 2: Achieved 256 tile!
2025-02-28 15:30:59,725 - INFO - Game 2: Achieved 512 tile!
2025-02-28 15:37:26,035 - INFO - Game 2: Achieved 1024 tile!
2025-02-28 15:44:33,786 - INFO - Game 2/2 completed: Score = 11892, Max Tile = 1024, Steps = 664
2025-02-28 15:44:33,786 - INFO - ========================================
2025-02-28 15:44:33,787 - INFO - Evaluation over 2 games:
2025-02-28 15:44:33,787 - INFO - Average Max Tile: 768.0
2025-02-28 15:44:33,787 - INFO - Average Score: 9008.0
2025-02-28 15:44:33,787 - INFO - Average Steps: 526.5
2025-02-28 15:44:33,787 - INFO - Best Max Tile: 1024
2025-02-28 15:44:33,788 - INFO - Tile distribution:
2025-02-28 15:44:33,788 - INFO -   512: 1 games (50.0%)
2025-02-28 15:44:33,788 - INFO -   1024: 1 games (50.0%)
2025-02-28 15:44:33,788 - INFO - Average steps to achieve tile:
2025-02-28 15:44:33,788 - INFO -   16: 10.0 steps
2025-02-28 15:44:33,789 - INFO -   32: 21.5 steps
2025-02-28 15:44:33,789 - INFO - Testing with 200 simulations...
2025-02-28 15:44:33,789 - INFO - Starting game 1/2
2025-02-28 15:45:52,808 - INFO - Game 1: Achieved 64 tile!
2025-02-28 15:47:40,382 - INFO - Game 1: Achieved 128 tile!
2025-02-28 15:49:28,923 - INFO - Game 1: Achieved 256 tile!
2025-02-28 15:54:00,257 - INFO - Game 1: Achieved 512 tile!
2025-02-28 16:08:02,480 - INFO - Game 1/2 completed: Score = 7460, Max Tile = 512, Steps = 484
2025-02-28 16:08:02,481 - INFO - Starting game 2/2
2025-02-28 16:09:50,692 - INFO - Game 2: Achieved 64 tile!
2025-02-28 16:11:19,574 - INFO - Game 2: Achieved 128 tile!
2025-02-28 16:12:37,063 - INFO - Game 2: Achieved 256 tile!
2025-02-28 16:17:07,747 - INFO - Game 2: Achieved 512 tile!
2025-02-28 16:30:16,083 - INFO - Game 2: Achieved 1024 tile!
2025-02-28 17:00:05,363 - INFO - Game 2/2 completed: Score = 15480, Max Tile = 1024, Steps = 848
2025-02-28 17:00:05,364 - INFO - ========================================
2025-02-28 17:00:05,365 - INFO - Evaluation over 2 games:
2025-02-28 17:00:05,365 - INFO - Average Max Tile: 768.0
2025-02-28 17:00:05,365 - INFO - Average Score: 11470.0
2025-02-28 17:00:05,365 - INFO - Average Steps: 666.0
2025-02-28 17:00:05,366 - INFO - Best Max Tile: 1024
2025-02-28 17:00:05,366 - INFO - Tile distribution:
2025-02-28 17:00:05,366 - INFO -   512: 1 games (50.0%)
2025-02-28 17:00:05,366 - INFO -   1024: 1 games (50.0%)
2025-02-28 17:00:05,367 - INFO - Average steps to achieve tile:
2025-02-28 17:00:05,367 - INFO -   16: 10.0 steps
2025-02-28 17:00:05,367 - INFO -   32: 19.0 steps
2025-02-28 17:00:05,374 - INFO - Testing with temperature 0.1...
2025-02-28 17:00:05,374 - INFO - Starting game 1/2
2025-02-28 17:00:35,616 - INFO - Game 1: Achieved 64 tile!
2025-02-28 17:01:06,753 - INFO - Game 1: Achieved 128 tile!
2025-02-28 17:01:35,059 - INFO - Game 1: Achieved 256 tile!
2025-02-28 17:03:07,341 - INFO - Game 1/2 completed: Score = 3080, Max Tile = 256, Steps = 238
2025-02-28 17:03:07,341 - INFO - Starting game 2/2
2025-02-28 17:03:37,709 - INFO - Game 2: Achieved 64 tile!
2025-02-28 17:04:12,158 - INFO - Game 2: Achieved 128 tile!
2025-02-28 17:04:38,569 - INFO - Game 2/2 completed: Score = 1316, Max Tile = 128, Steps = 131
2025-02-28 17:04:38,569 - INFO - ========================================
2025-02-28 17:04:38,570 - INFO - Evaluation over 2 games:
2025-02-28 17:04:38,570 - INFO - Average Max Tile: 192.0
2025-02-28 17:04:38,570 - INFO - Average Score: 2198.0
2025-02-28 17:04:38,571 - INFO - Average Steps: 184.5
2025-02-28 17:04:38,571 - INFO - Best Max Tile: 256
2025-02-28 17:04:38,571 - INFO - Tile distribution:
2025-02-28 17:04:38,571 - INFO -   128: 1 games (50.0%)
2025-02-28 17:04:38,572 - INFO -   256: 1 games (50.0%)
2025-02-28 17:04:38,572 - INFO - Average steps to achieve tile:
2025-02-28 17:04:38,572 - INFO -   16: 7.0 steps
2025-02-28 17:04:38,572 - INFO -   32: 26.0 steps
2025-02-28 17:04:38,572 - INFO - Testing with temperature 0.5...
2025-02-28 17:04:38,573 - INFO - Starting game 1/2
2025-02-28 17:05:04,633 - INFO - Game 1: Achieved 64 tile!
2025-02-28 17:05:26,460 - INFO - Game 1: Achieved 128 tile!
2025-02-28 17:06:32,069 - INFO - Game 1: Achieved 256 tile!
2025-02-28 17:07:04,641 - INFO - Game 1/2 completed: Score = 2548, Max Tile = 256, Steps = 202
2025-02-28 17:07:04,642 - INFO - Starting game 2/2
2025-02-28 17:07:32,598 - INFO - Game 2: Achieved 64 tile!
2025-02-28 17:08:03,440 - INFO - Game 2: Achieved 128 tile!
2025-02-28 17:08:42,476 - INFO - Game 2: Achieved 256 tile!
2025-02-28 17:10:23,345 - INFO - Game 2: Achieved 512 tile!
2025-02-28 17:14:32,364 - INFO - Game 2: Achieved 1024 tile!
2025-02-28 17:16:55,234 - INFO - Game 2/2 completed: Score = 10356, Max Tile = 1024, Steps = 571
2025-02-28 17:16:55,234 - INFO - ========================================
2025-02-28 17:16:55,235 - INFO - Evaluation over 2 games:
2025-02-28 17:16:55,235 - INFO - Average Max Tile: 640.0
2025-02-28 17:16:55,235 - INFO - Average Score: 6452.0
2025-02-28 17:16:55,236 - INFO - Average Steps: 386.5
2025-02-28 17:16:55,236 - INFO - Best Max Tile: 1024
2025-02-28 17:16:55,236 - INFO - Tile distribution:
2025-02-28 17:16:55,237 - INFO -   256: 1 games (50.0%)
2025-02-28 17:16:55,237 - INFO -   1024: 1 games (50.0%)
2025-02-28 17:16:55,237 - INFO - Average steps to achieve tile:
2025-02-28 17:16:55,237 - INFO -   16: 10.0 steps
2025-02-28 17:16:55,237 - INFO -   32: 19.5 steps
2025-02-28 17:16:55,237 - INFO - Testing with temperature 1.0...
2025-02-28 17:16:55,238 - INFO - Starting game 1/2
2025-02-28 17:17:28,587 - INFO - Game 1: Achieved 64 tile!
2025-02-28 17:17:53,316 - INFO - Game 1: Achieved 128 tile!
2025-02-28 17:18:35,684 - INFO - Game 1: Achieved 256 tile!
2025-02-28 17:20:14,127 - INFO - Game 1/2 completed: Score = 3152, Max Tile = 256, Steps = 251
2025-02-28 17:20:14,128 - INFO - Starting game 2/2
2025-02-28 17:20:43,342 - INFO - Game 2: Achieved 64 tile!
2025-02-28 17:21:06,679 - INFO - Game 2: Achieved 128 tile!
2025-02-28 17:22:33,340 - INFO - Game 2: Achieved 256 tile!
2025-02-28 17:23:30,463 - INFO - Game 2/2 completed: Score = 3180, Max Tile = 256, Steps = 257
2025-02-28 17:23:30,463 - INFO - ========================================
2025-02-28 17:23:30,463 - INFO - Evaluation over 2 games:
2025-02-28 17:23:30,464 - INFO - Average Max Tile: 256.0
2025-02-28 17:23:30,464 - INFO - Average Score: 3166.0
2025-02-28 17:23:30,464 - INFO - Average Steps: 254.0
2025-02-28 17:23:30,464 - INFO - Best Max Tile: 256
2025-02-28 17:23:30,464 - INFO - Tile distribution:
2025-02-28 17:23:30,465 - INFO -   256: 2 games (100.0%)
2025-02-28 17:23:30,465 - INFO - Average steps to achieve tile:
2025-02-28 17:23:30,465 - INFO -   16: 13.0 steps
2025-02-28 17:23:30,465 - INFO -   32: 19.5 steps
2025-02-28 17:23:30,465 - INFO - Testing with temperature 1.5...
2025-02-28 17:23:30,467 - INFO - Starting game 1/2
2025-02-28 17:23:58,893 - INFO - Game 1: Achieved 64 tile!
2025-02-28 17:24:22,641 - INFO - Game 1: Achieved 128 tile!
2025-02-28 17:25:18,457 - INFO - Game 1: Achieved 256 tile!
2025-02-28 17:28:03,112 - INFO - Game 1: Achieved 512 tile!
2025-02-28 17:30:27,818 - INFO - Game 1/2 completed: Score = 6972, Max Tile = 512, Steps = 454
2025-02-28 17:30:27,818 - INFO - Starting game 2/2
2025-02-28 17:31:01,198 - INFO - Game 2: Achieved 64 tile!
2025-02-28 17:31:10,260 - INFO - Game 2: Achieved 128 tile!
2025-02-28 17:32:13,772 - INFO - Game 2/2 completed: Score = 1588, Max Tile = 128, Steps = 150
2025-02-28 17:32:13,773 - INFO - ========================================
2025-02-28 17:32:13,773 - INFO - Evaluation over 2 games:
2025-02-28 17:32:13,773 - INFO - Average Max Tile: 320.0
2025-02-28 17:32:13,773 - INFO - Average Score: 4280.0
2025-02-28 17:32:13,774 - INFO - Average Steps: 302.0
2025-02-28 17:32:13,774 - INFO - Best Max Tile: 512
2025-02-28 17:32:13,774 - INFO - Tile distribution:
2025-02-28 17:32:13,774 - INFO -   128: 1 games (50.0%)
2025-02-28 17:32:13,774 - INFO -   512: 1 games (50.0%)
2025-02-28 17:32:13,775 - INFO - Average steps to achieve tile:
2025-02-28 17:32:13,775 - INFO -   16: 14.5 steps
2025-02-28 17:32:13,775 - INFO -   32: 23.5 steps
2025-02-28 17:32:13,775 - INFO - Testing with temperature 2.0...
2025-02-28 17:32:13,775 - INFO - Starting game 1/2
2025-02-28 17:32:49,212 - INFO - Game 1: Achieved 64 tile!
2025-02-28 17:33:07,988 - INFO - Game 1: Achieved 128 tile!
2025-02-28 17:33:55,015 - INFO - Game 1: Achieved 256 tile!
2025-02-28 17:35:50,039 - INFO - Game 1: Achieved 512 tile!
2025-02-28 17:39:30,799 - INFO - Game 1/2 completed: Score = 7152, Max Tile = 512, Steps = 460
2025-02-28 17:39:30,799 - INFO - Starting game 2/2
2025-02-28 17:39:55,110 - INFO - Game 2: Achieved 64 tile!
2025-02-28 17:40:21,789 - INFO - Game 2: Achieved 128 tile!
2025-02-28 17:41:14,214 - INFO - Game 2: Achieved 256 tile!
2025-02-28 17:42:50,649 - INFO - Game 2: Achieved 512 tile!
2025-02-28 17:46:31,202 - INFO - Game 2/2 completed: Score = 6836, Max Tile = 512, Steps = 440
2025-02-28 17:46:31,203 - INFO - ========================================
2025-02-28 17:46:31,203 - INFO - Evaluation over 2 games:
2025-02-28 17:46:31,203 - INFO - Average Max Tile: 512.0
2025-02-28 17:46:31,204 - INFO - Average Score: 6994.0
2025-02-28 17:46:31,204 - INFO - Average Steps: 450.0
2025-02-28 17:46:31,204 - INFO - Best Max Tile: 512
2025-02-28 17:46:31,205 - INFO - Tile distribution:
2025-02-28 17:46:31,205 - INFO -   512: 2 games (100.0%)
2025-02-28 17:46:31,205 - INFO - Average steps to achieve tile:
2025-02-28 17:46:31,205 - INFO -   16: 9.0 steps
2025-02-28 17:46:31,205 - INFO -   32: 28.5 steps
2025-02-28 18:30:26,847 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-28 18:30:26,848 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-28 18:30:26,848 - INFO - MCTS Simulations: 75
2025-02-28 18:30:26,848 - INFO - MCTS Temperature: 0.5
2025-02-28 18:30:26,848 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 18:30:26,849 - INFO - Learning rate: 0.0008
2025-02-28 18:30:26,849 - INFO - Device: cuda
2025-02-28 18:30:26,850 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 18:30:26,956 - INFO - Resuming from epoch 1
2025-02-28 18:30:26,956 - INFO - Running evaluation
2025-02-28 18:31:47,017 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-28 18:31:47,017 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-28 18:31:47,017 - INFO - MCTS Simulations: 200
2025-02-28 18:31:47,018 - INFO - MCTS Temperature: 0.5
2025-02-28 18:31:47,018 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 18:31:47,018 - INFO - Learning rate: 0.0008
2025-02-28 18:31:47,019 - INFO - Device: cuda
2025-02-28 18:31:47,019 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 18:31:47,129 - INFO - Resuming from epoch 1
2025-02-28 18:31:47,130 - INFO - Running evaluation
2025-02-28 18:47:42,413 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-28 18:47:42,413 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-28 18:47:42,414 - INFO - MCTS Simulations: 200
2025-02-28 18:47:42,414 - INFO - MCTS Temperature: 0.5
2025-02-28 18:47:42,414 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 18:47:42,414 - INFO - Learning rate: 0.0008
2025-02-28 18:47:42,415 - INFO - Device: cuda
2025-02-28 18:47:42,415 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 18:47:42,521 - INFO - Resuming from epoch 1
2025-02-28 18:47:42,521 - INFO - Running evaluation
2025-02-28 19:11:06,819 - INFO - Created optimizer for the base agent within the MCTS wrapper
2025-02-28 19:11:06,820 - INFO - === 2048 Mcts Training/Evaluation ===
2025-02-28 19:11:06,820 - INFO - MCTS Simulations: 200
2025-02-28 19:11:06,821 - INFO - MCTS Temperature: 0.5
2025-02-28 19:11:06,821 - INFO - Training for 2000 epochs with batch size 96
2025-02-28 19:11:06,821 - INFO - Learning rate: 0.0008
2025-02-28 19:11:06,821 - INFO - Device: cuda
2025-02-28 19:11:06,822 - INFO - Loading checkpoint: checkpoints/enhanced/best_model.pt
2025-02-28 19:11:06,932 - INFO - Resuming from epoch 1
2025-02-28 19:11:06,932 - INFO - Running evaluation
2025-02-28 19:37:58,920 - INFO - Game 1: Score = 7764, Max Tile = 512
2025-02-28 20:36:29,436 - INFO - Game 2: Score = 15824, Max Tile = 1024
2025-02-28 20:41:19,789 - INFO - Game 3: Score = 1276, Max Tile = 128
2025-02-28 21:28:59,046 - INFO - Game 4: Score = 13820, Max Tile = 1024
2025-02-28 22:12:35,972 - INFO - Game 5: Score = 12224, Max Tile = 1024
2025-02-28 22:12:35,972 - INFO - ========================================
2025-02-28 22:12:35,973 - INFO - Evaluation over 5 games:
2025-02-28 22:12:35,973 - INFO - Average Score: 10181.6
2025-02-28 22:12:35,974 - INFO - Average Max Tile: 742.4
2025-02-28 22:12:35,974 - INFO - Best Max Tile: 1024
2025-02-28 22:12:35,974 - INFO - Tile distribution:
2025-02-28 22:12:35,974 - INFO -   128: 1 games (20.0%)
2025-02-28 22:12:35,975 - INFO -   512: 1 games (20.0%)
2025-02-28 22:12:35,975 - INFO -   1024: 3 games (60.0%)
2025-02-28 22:12:35,975 - INFO - Evaluation complete. Best tile: 1024
2025-03-01 11:51:32,764 - INFO - Loading model from checkpoints/enhanced/best_model.pt
2025-03-01 11:52:22,358 - INFO - Loading model from checkpoints/enhanced/best_model.pt
2025-03-01 11:52:22,537 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 11:54:51,396 - INFO - Loading model from checkpoints/enhanced/best_model.pt
2025-03-01 11:54:51,573 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 11:56:19,870 - INFO - Loading model from checkpoints/enhanced/best_model.pt
2025-03-01 11:56:20,033 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 12:35:39,950 - INFO - Using device: cuda
2025-03-01 12:35:39,951 - INFO - Arguments: Namespace(episodes=10000, max_steps=2000, hidden_dim=256, buffer_size=100000, batch_size=64, min_buffer_size=10000, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.9995, target_update_freq=1000, log_interval=100, eval_interval=500, eval_episodes=10, output_dir='dqn_results', checkpoint=None, seed=42)
2025-03-01 12:37:46,652 - INFO - Using device: cuda
2025-03-01 12:37:46,652 - INFO - Arguments: Namespace(episodes=10000, max_steps=2000, hidden_dim=256, buffer_size=100000, batch_size=64, min_buffer_size=10000, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.9995, target_update_freq=1000, log_interval=100, eval_interval=500, eval_episodes=10, output_dir='dqn_results', checkpoint=None, seed=42)
2025-03-01 12:38:21,373 - INFO - Using device: cuda
2025-03-01 12:38:21,374 - INFO - Arguments: Namespace(episodes=10000, max_steps=2000, hidden_dim=256, buffer_size=100000, batch_size=64, min_buffer_size=10000, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.9995, target_update_freq=1000, log_interval=100, eval_interval=500, eval_episodes=10, output_dir='dqn_results', checkpoint=None, seed=42)
2025-03-01 12:38:21,561 - INFO - Filling replay buffer with 10000 experiences...
2025-03-01 12:38:52,317 - INFO - Starting training for 10000 episodes...
2025-03-01 12:40:58,698 - INFO - Using device: cuda
2025-03-01 12:40:58,699 - INFO - Arguments: Namespace(episodes=5000, max_steps=2000, hidden_dim=256, buffer_size=100000, batch_size=64, min_buffer_size=10000, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.9995, target_update_freq=1000, log_interval=100, eval_interval=1000, eval_episodes=10, output_dir='dqn_results', checkpoint=None, seed=42)
2025-03-01 12:40:58,880 - INFO - Filling replay buffer with 10000 experiences...
2025-03-01 12:41:29,860 - INFO - Starting training for 5000 episodes...
2025-03-01 12:52:04,573 - INFO - Episode 100/5000 | Avg Reward: 2801.0 | Avg Max Tile: 121.1 | Avg Length: 129.4 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 13:03:32,606 - INFO - Episode 200/5000 | Avg Reward: 2890.2 | Avg Max Tile: 123.5 | Avg Length: 135.3 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 13:10:12,116 - INFO - Using device: cuda
2025-03-01 13:10:12,116 - INFO - Arguments: Namespace(episodes=5000, max_steps=2000, hidden_dim=256, buffer_size=100000, batch_size=128, min_buffer_size=10000, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.9995, target_update_freq=1000, update_freq=4, learning_rate=0.0001, log_interval=250, eval_interval=1000, eval_episodes=5, output_dir='dqn_results', checkpoint=None, seed=42)
2025-03-01 13:11:24,036 - INFO - Using device: cuda
2025-03-01 13:11:24,036 - INFO - Arguments: Namespace(episodes=5000, max_steps=2000, hidden_dim=256, buffer_size=100000, batch_size=128, min_buffer_size=10000, gamma=0.99, epsilon_start=1.0, epsilon_end=0.1, epsilon_decay=0.9995, target_update_freq=1000, update_freq=4, learning_rate=0.0001, log_interval=250, eval_interval=1000, eval_episodes=5, output_dir='dqn_results', checkpoint=None, seed=42)
2025-03-01 13:11:26,095 - INFO - Filling replay buffer with 10000 experiences...
2025-03-01 13:11:56,917 - INFO - Starting training for 5000 episodes...
2025-03-01 13:21:58,387 - INFO - Episode 250/5000 | Avg Reward: 2590.6 | Avg Max Tile: 114.9 | Avg Length: 120.0 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 13:32:46,139 - INFO - Episode 500/5000 | Avg Reward: 2736.7 | Avg Max Tile: 118.7 | Avg Length: 126.8 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 13:43:40,572 - INFO - Episode 750/5000 | Avg Reward: 2772.5 | Avg Max Tile: 120.0 | Avg Length: 128.3 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 13:54:52,439 - INFO - Episode 1000/5000 | Avg Reward: 2849.3 | Avg Max Tile: 122.1 | Avg Length: 131.7 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 13:54:59,438 - INFO - Evaluation | Avg Score: 4699.2 | Avg Max Tile: 204.8 | Best Max Tile: 256
2025-03-01 13:54:59,494 - INFO - Saved checkpoint to dqn_results\checkpoint_episode_1000.pt
2025-03-01 13:54:59,537 - INFO - Saved best model to dqn_results\best_model.pt
2025-03-01 14:06:01,406 - INFO - Episode 1250/5000 | Avg Reward: 2792.5 | Avg Max Tile: 122.8 | Avg Length: 128.8 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 14:16:50,915 - INFO - Episode 1500/5000 | Avg Reward: 2739.1 | Avg Max Tile: 116.6 | Avg Length: 127.4 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 14:27:58,004 - INFO - Episode 1750/5000 | Avg Reward: 2827.0 | Avg Max Tile: 120.6 | Avg Length: 131.3 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 14:39:00,740 - INFO - Episode 2000/5000 | Avg Reward: 2849.5 | Avg Max Tile: 126.6 | Avg Length: 130.6 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 14:39:06,826 - INFO - Evaluation | Avg Score: 4218.3 | Avg Max Tile: 179.2 | Best Max Tile: 256
2025-03-01 14:39:06,890 - INFO - Saved checkpoint to dqn_results\checkpoint_episode_2000.pt
2025-03-01 14:50:00,548 - INFO - Episode 2250/5000 | Avg Reward: 2765.0 | Avg Max Tile: 118.1 | Avg Length: 128.7 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 15:01:03,814 - INFO - Episode 2500/5000 | Avg Reward: 2808.3 | Avg Max Tile: 121.1 | Avg Length: 130.2 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 15:12:49,159 - INFO - Episode 2750/5000 | Avg Reward: 2986.6 | Avg Max Tile: 131.7 | Avg Length: 137.2 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 15:24:15,303 - INFO - Episode 3000/5000 | Avg Reward: 2926.8 | Avg Max Tile: 128.6 | Avg Length: 134.2 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 15:24:20,753 - INFO - Evaluation | Avg Score: 3860.6 | Avg Max Tile: 166.4 | Best Max Tile: 256
2025-03-01 15:24:20,820 - INFO - Saved checkpoint to dqn_results\checkpoint_episode_3000.pt
2025-03-01 15:34:49,821 - INFO - Episode 3250/5000 | Avg Reward: 2607.5 | Avg Max Tile: 107.8 | Avg Length: 123.6 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 15:45:43,057 - INFO - Episode 3500/5000 | Avg Reward: 2731.1 | Avg Max Tile: 115.3 | Avg Length: 127.9 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 15:55:46,140 - INFO - Episode 3750/5000 | Avg Reward: 2505.9 | Avg Max Tile: 106.8 | Avg Length: 118.3 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 16:06:23,694 - INFO - Episode 4000/5000 | Avg Reward: 2735.4 | Avg Max Tile: 119.8 | Avg Length: 125.4 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 16:06:29,594 - INFO - Evaluation | Avg Score: 3901.5 | Avg Max Tile: 153.6 | Best Max Tile: 256
2025-03-01 16:06:29,672 - INFO - Saved checkpoint to dqn_results\checkpoint_episode_4000.pt
2025-03-01 16:18:14,615 - INFO - Episode 4250/5000 | Avg Reward: 2993.5 | Avg Max Tile: 129.7 | Avg Length: 138.4 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 16:29:06,054 - INFO - Episode 4500/5000 | Avg Reward: 2716.4 | Avg Max Tile: 113.7 | Avg Length: 128.1 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 16:39:46,634 - INFO - Episode 4750/5000 | Avg Reward: 2755.4 | Avg Max Tile: 117.1 | Avg Length: 128.4 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 16:50:57,949 - INFO - Episode 5000/5000 | Avg Reward: 2832.2 | Avg Max Tile: 121.6 | Avg Length: 131.7 | Avg Loss: inf | Epsilon: 0.1000
2025-03-01 16:51:03,920 - INFO - Evaluation | Avg Score: 3954.1 | Avg Max Tile: 169.6 | Best Max Tile: 512
2025-03-01 16:51:04,022 - INFO - Saved checkpoint to dqn_results\checkpoint_episode_5000.pt
2025-03-01 16:51:04,059 - INFO - Saved final model to dqn_results\final_model.pt
2025-03-01 16:51:05,106 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-01 16:51:05,107 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-01 16:55:19,453 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 16:57:13,152 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 16:57:15,260 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 16:57:15,260 - INFO - Evaluating regular agent...
2025-03-01 16:57:16,668 - INFO - Game 1/10 completed: Max Tile = 128
2025-03-01 16:57:17,596 - INFO - Game 2/10 completed: Max Tile = 128
2025-03-01 16:57:18,148 - INFO - Game 3/10 completed: Max Tile = 64
2025-03-01 16:57:19,550 - INFO - Game 4/10 completed: Max Tile = 256
2025-03-01 16:57:20,579 - INFO - Game 5/10 completed: Max Tile = 128
2025-03-01 16:57:21,230 - INFO - Game 6/10 completed: Max Tile = 128
2025-03-01 16:57:22,025 - INFO - Game 7/10 completed: Max Tile = 128
2025-03-01 16:57:22,970 - INFO - Game 8/10 completed: Max Tile = 128
2025-03-01 16:57:24,028 - INFO - Game 9/10 completed: Max Tile = 128
2025-03-01 16:57:25,611 - INFO - Game 10/10 completed: Max Tile = 256
2025-03-01 16:57:25,611 - INFO - ========================================
2025-03-01 16:57:25,612 - INFO - Evaluation over 10 games:
2025-03-01 16:57:25,612 - INFO - Average Max Tile: 147.2
2025-03-01 16:57:25,612 - INFO - Average Score: 1704.8
2025-03-01 16:57:25,612 - INFO - Average Steps: 159.5
2025-03-01 16:57:25,612 - INFO - Best Max Tile: 256
2025-03-01 16:57:25,613 - INFO - Tile distribution:
2025-03-01 16:57:25,613 - INFO -   64: 1 games (10.0%)
2025-03-01 16:57:25,613 - INFO -   128: 7 games (70.0%)
2025-03-01 16:57:25,614 - INFO -   256: 2 games (20.0%)
2025-03-01 16:57:25,614 - INFO - Average steps to achieve tile:
2025-03-01 16:57:25,614 - INFO - 
Evaluating MCTS agent...
2025-03-01 17:01:12,164 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 17:01:14,208 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 17:01:14,208 - INFO - Evaluating regular agent...
2025-03-01 17:01:15,568 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-01 17:01:16,488 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-01 17:01:17,030 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-01 17:01:18,347 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-01 17:01:19,302 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-01 17:01:19,302 - INFO - ========================================
2025-03-01 17:01:19,303 - INFO - Evaluation over 5 games:
2025-03-01 17:01:19,303 - INFO - Average Max Tile: 140.8
2025-03-01 17:01:19,303 - INFO - Average Score: 1634.4
2025-03-01 17:01:19,304 - INFO - Average Steps: 155.2
2025-03-01 17:01:19,305 - INFO - Best Max Tile: 256
2025-03-01 17:01:19,305 - INFO - Tile distribution:
2025-03-01 17:01:19,305 - INFO -   64: 1 games (20.0%)
2025-03-01 17:01:19,305 - INFO -   128: 3 games (60.0%)
2025-03-01 17:01:19,306 - INFO -   256: 1 games (20.0%)
2025-03-01 17:01:19,306 - INFO - Average steps to achieve tile:
2025-03-01 17:01:19,306 - INFO - 
Evaluating MCTS agent...
2025-03-01 17:07:35,414 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 17:07:37,470 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 17:13:41,478 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 17:13:43,575 - INFO - Creating MCTS agent with 200 simulations
2025-03-01 17:13:43,575 - INFO - Evaluating regular agent...
2025-03-01 17:13:44,971 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-01 17:13:45,914 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-01 17:13:46,476 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-01 17:13:47,928 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-01 17:13:49,015 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-01 17:13:49,015 - INFO - ========================================
2025-03-01 17:13:49,016 - INFO - Evaluation over 5 games:
2025-03-01 17:13:49,016 - INFO - Average Max Tile: 140.8
2025-03-01 17:13:49,016 - INFO - Average Score: 1634.4
2025-03-01 17:13:49,016 - INFO - Average Steps: 155.2
2025-03-01 17:13:49,016 - INFO - Best Max Tile: 256
2025-03-01 17:13:49,018 - INFO - Tile distribution:
2025-03-01 17:13:49,018 - INFO -   64: 1 games (20.0%)
2025-03-01 17:13:49,018 - INFO -   128: 3 games (60.0%)
2025-03-01 17:13:49,018 - INFO -   256: 1 games (20.0%)
2025-03-01 17:13:49,018 - INFO - Average steps to achieve tile:
2025-03-01 17:13:49,018 - INFO - 
Evaluating MCTS agent...
2025-03-01 17:15:39,247 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 17:15:41,353 - INFO - Creating MCTS agent with 100 simulations
2025-03-01 17:16:05,811 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 17:16:07,859 - INFO - Creating MCTS agent with 300 simulations
2025-03-01 17:20:08,315 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 17:20:10,357 - INFO - Creating MCTS agent with 150 simulations
2025-03-01 17:20:10,357 - INFO - Evaluating regular agent...
2025-03-01 17:20:11,686 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-01 17:20:12,624 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-01 17:20:13,182 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-01 17:20:14,573 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-01 17:20:15,574 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-01 17:20:15,574 - INFO - ========================================
2025-03-01 17:20:15,574 - INFO - Evaluation over 5 games:
2025-03-01 17:20:15,575 - INFO - Average Max Tile: 140.8
2025-03-01 17:20:15,575 - INFO - Average Score: 1634.4
2025-03-01 17:20:15,575 - INFO - Average Steps: 155.2
2025-03-01 17:20:15,576 - INFO - Best Max Tile: 256
2025-03-01 17:20:15,576 - INFO - Tile distribution:
2025-03-01 17:20:15,576 - INFO -   64: 1 games (20.0%)
2025-03-01 17:20:15,576 - INFO -   128: 3 games (60.0%)
2025-03-01 17:20:15,576 - INFO -   256: 1 games (20.0%)
2025-03-01 17:20:15,576 - INFO - Average steps to achieve tile:
2025-03-01 17:20:15,576 - INFO - 
Evaluating MCTS agent...
2025-03-01 17:46:39,292 - INFO - Game 1/5 completed: Max Tile = 512
2025-03-01 18:12:31,876 - INFO - Game 2/5 completed: Max Tile = 512
2025-03-01 18:26:38,270 - INFO - Loading model from dqn_results/final_model.pt
2025-03-01 18:26:40,342 - INFO - Creating MCTS agent with 50 simulations
2025-03-01 18:26:40,343 - INFO - Evaluating regular agent...
2025-03-01 18:26:41,684 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-01 18:26:42,582 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-01 18:26:43,135 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-01 18:26:44,523 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-01 18:26:45,548 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-01 18:26:45,549 - INFO - ========================================
2025-03-01 18:26:45,549 - INFO - Evaluation over 5 games:
2025-03-01 18:26:45,550 - INFO - Average Max Tile: 140.8
2025-03-01 18:26:45,550 - INFO - Average Score: 1634.4
2025-03-01 18:26:45,550 - INFO - Average Steps: 155.2
2025-03-01 18:26:45,550 - INFO - Best Max Tile: 256
2025-03-01 18:26:45,551 - INFO - Tile distribution:
2025-03-01 18:26:45,551 - INFO -   64: 1 games (20.0%)
2025-03-01 18:26:45,551 - INFO -   128: 3 games (60.0%)
2025-03-01 18:26:45,551 - INFO -   256: 1 games (20.0%)
2025-03-01 18:26:45,551 - INFO - Average steps to achieve tile:
2025-03-01 18:26:45,552 - INFO - 
Evaluating MCTS agent...
2025-03-01 18:32:32,684 - INFO - Game 1/5 completed: Max Tile = 512
2025-03-01 18:37:34,289 - INFO - Game 2/5 completed: Max Tile = 512
2025-03-01 18:40:34,098 - INFO - Game 3/5 completed: Max Tile = 256
2025-03-01 18:42:15,094 - INFO - Game 4/5 completed: Max Tile = 128
2025-03-01 18:47:22,781 - INFO - Game 5/5 completed: Max Tile = 512
2025-03-01 18:47:22,782 - INFO - ========================================
2025-03-01 18:47:22,783 - INFO - Evaluation over 5 games:
2025-03-01 18:47:22,783 - INFO - Average Max Tile: 384.0
2025-03-01 18:47:22,783 - INFO - Average Score: 4485.6
2025-03-01 18:47:22,783 - INFO - Average Steps: 302.2
2025-03-01 18:47:22,784 - INFO - Best Max Tile: 512
2025-03-01 18:47:22,784 - INFO - Tile distribution:
2025-03-01 18:47:22,784 - INFO -   128: 1 games (20.0%)
2025-03-01 18:47:22,784 - INFO -   256: 1 games (20.0%)
2025-03-01 18:47:22,785 - INFO -   512: 3 games (60.0%)
2025-03-01 18:47:22,785 - INFO - Average steps to achieve tile:
2025-03-01 18:47:22,785 - INFO - 
==================================================
2025-03-01 18:47:22,785 - INFO - COMPARISON RESULTS:
2025-03-01 18:47:22,785 - INFO - Average Max Tile: Regular = 140.8, MCTS = 384.0
2025-03-01 18:47:22,786 - INFO - Average Score: Regular = 1634.4, MCTS = 4485.6
2025-03-01 18:47:22,786 - INFO - Best Max Tile: Regular = 256, MCTS = 512
2025-03-01 18:47:23,121 - INFO - Testing with 5 simulations...
2025-03-01 18:47:28,173 - INFO - Game 1/2 completed: Max Tile = 64
2025-03-01 18:47:36,724 - INFO - Game 2/2 completed: Max Tile = 128
2025-03-01 18:47:36,724 - INFO - ========================================
2025-03-01 18:47:36,725 - INFO - Evaluation over 2 games:
2025-03-01 18:47:36,725 - INFO - Average Max Tile: 96.0
2025-03-01 18:47:36,726 - INFO - Average Score: 1204.0
2025-03-01 18:47:36,726 - INFO - Average Steps: 126.5
2025-03-01 18:47:36,726 - INFO - Best Max Tile: 128
2025-03-01 18:47:36,726 - INFO - Tile distribution:
2025-03-01 18:47:36,726 - INFO -   64: 1 games (50.0%)
2025-03-01 18:47:36,727 - INFO -   128: 1 games (50.0%)
2025-03-01 18:47:36,727 - INFO - Average steps to achieve tile:
2025-03-01 18:47:36,727 - INFO - Testing with 10 simulations...
2025-03-01 18:47:51,949 - INFO - Game 1/2 completed: Max Tile = 128
2025-03-01 18:48:19,817 - INFO - Game 2/2 completed: Max Tile = 256
2025-03-01 18:48:19,817 - INFO - ========================================
2025-03-01 18:48:19,818 - INFO - Evaluation over 2 games:
2025-03-01 18:48:19,818 - INFO - Average Max Tile: 192.0
2025-03-01 18:48:19,818 - INFO - Average Score: 2194.0
2025-03-01 18:48:19,819 - INFO - Average Steps: 183.5
2025-03-01 18:48:19,819 - INFO - Best Max Tile: 256
2025-03-01 18:48:19,819 - INFO - Tile distribution:
2025-03-01 18:48:19,819 - INFO -   128: 1 games (50.0%)
2025-03-01 18:48:19,820 - INFO -   256: 1 games (50.0%)
2025-03-01 18:48:19,820 - INFO - Average steps to achieve tile:
2025-03-01 18:48:19,820 - INFO - Testing with 25 simulations...
2025-03-01 18:49:47,406 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-01 18:51:52,433 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 18:51:52,434 - INFO - ========================================
2025-03-01 18:51:52,434 - INFO - Evaluation over 2 games:
2025-03-01 18:51:52,434 - INFO - Average Max Tile: 384.0
2025-03-01 18:51:52,434 - INFO - Average Score: 4014.0
2025-03-01 18:51:52,436 - INFO - Average Steps: 282.5
2025-03-01 18:51:52,436 - INFO - Best Max Tile: 512
2025-03-01 18:51:52,436 - INFO - Tile distribution:
2025-03-01 18:51:52,436 - INFO -   256: 1 games (50.0%)
2025-03-01 18:51:52,436 - INFO -   512: 1 games (50.0%)
2025-03-01 18:51:52,436 - INFO - Average steps to achieve tile:
2025-03-01 18:51:52,437 - INFO - Testing with 50 simulations...
2025-03-01 18:56:26,578 - INFO - Game 1/2 completed: Max Tile = 512
2025-03-01 19:02:04,018 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 19:02:04,018 - INFO - ========================================
2025-03-01 19:02:04,019 - INFO - Evaluation over 2 games:
2025-03-01 19:02:04,019 - INFO - Average Max Tile: 512.0
2025-03-01 19:02:04,019 - INFO - Average Score: 5698.0
2025-03-01 19:02:04,019 - INFO - Average Steps: 362.0
2025-03-01 19:02:04,019 - INFO - Best Max Tile: 512
2025-03-01 19:02:04,019 - INFO - Tile distribution:
2025-03-01 19:02:04,020 - INFO -   512: 2 games (100.0%)
2025-03-01 19:02:04,020 - INFO - Average steps to achieve tile:
2025-03-01 19:02:04,020 - INFO - Testing with 100 simulations...
2025-03-01 19:16:46,372 - INFO - Game 1/2 completed: Max Tile = 512
2025-03-01 19:31:48,778 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 19:31:48,779 - INFO - ========================================
2025-03-01 19:31:48,779 - INFO - Evaluation over 2 games:
2025-03-01 19:31:48,780 - INFO - Average Max Tile: 512.0
2025-03-01 19:31:48,780 - INFO - Average Score: 6858.0
2025-03-01 19:31:48,781 - INFO - Average Steps: 443.0
2025-03-01 19:31:48,781 - INFO - Best Max Tile: 512
2025-03-01 19:31:48,781 - INFO - Tile distribution:
2025-03-01 19:31:48,782 - INFO -   512: 2 games (100.0%)
2025-03-01 19:31:48,782 - INFO - Average steps to achieve tile:
2025-03-01 19:31:48,782 - INFO - Testing with 200 simulations...
2025-03-01 20:28:33,476 - INFO - Game 1/2 completed: Max Tile = 1024
2025-03-01 21:01:57,412 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 21:01:57,413 - INFO - ========================================
2025-03-01 21:01:57,413 - INFO - Evaluation over 2 games:
2025-03-01 21:01:57,414 - INFO - Average Max Tile: 768.0
2025-03-01 21:01:57,414 - INFO - Average Score: 9086.0
2025-03-01 21:01:57,414 - INFO - Average Steps: 533.0
2025-03-01 21:01:57,415 - INFO - Best Max Tile: 1024
2025-03-01 21:01:57,415 - INFO - Tile distribution:
2025-03-01 21:01:57,415 - INFO -   512: 1 games (50.0%)
2025-03-01 21:01:57,415 - INFO -   1024: 1 games (50.0%)
2025-03-01 21:01:57,416 - INFO - Average steps to achieve tile:
2025-03-01 21:01:57,424 - INFO - Testing with temperature 0.1...
2025-03-01 21:05:27,047 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-01 21:12:01,684 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 21:12:01,685 - INFO - ========================================
2025-03-01 21:12:01,685 - INFO - Evaluation over 2 games:
2025-03-01 21:12:01,686 - INFO - Average Max Tile: 384.0
2025-03-01 21:12:01,686 - INFO - Average Score: 5196.0
2025-03-01 21:12:01,686 - INFO - Average Steps: 364.5
2025-03-01 21:12:01,686 - INFO - Best Max Tile: 512
2025-03-01 21:12:01,687 - INFO - Tile distribution:
2025-03-01 21:12:01,687 - INFO -   256: 1 games (50.0%)
2025-03-01 21:12:01,687 - INFO -   512: 1 games (50.0%)
2025-03-01 21:12:01,687 - INFO - Average steps to achieve tile:
2025-03-01 21:12:01,688 - INFO - Testing with temperature 0.5...
2025-03-01 21:13:21,859 - INFO - Game 1/2 completed: Max Tile = 128
2025-03-01 21:15:42,508 - INFO - Game 2/2 completed: Max Tile = 128
2025-03-01 21:15:42,509 - INFO - ========================================
2025-03-01 21:15:42,509 - INFO - Evaluation over 2 games:
2025-03-01 21:15:42,510 - INFO - Average Max Tile: 128.0
2025-03-01 21:15:42,510 - INFO - Average Score: 1662.0
2025-03-01 21:15:42,511 - INFO - Average Steps: 152.0
2025-03-01 21:15:42,511 - INFO - Best Max Tile: 128
2025-03-01 21:15:42,511 - INFO - Tile distribution:
2025-03-01 21:15:42,511 - INFO -   128: 2 games (100.0%)
2025-03-01 21:15:42,512 - INFO - Average steps to achieve tile:
2025-03-01 21:15:42,512 - INFO - Testing with temperature 1.0...
2025-03-01 21:21:30,384 - INFO - Game 1/2 completed: Max Tile = 512
2025-03-01 21:26:44,958 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 21:26:44,959 - INFO - ========================================
2025-03-01 21:26:44,959 - INFO - Evaluation over 2 games:
2025-03-01 21:26:44,959 - INFO - Average Max Tile: 512.0
2025-03-01 21:26:44,960 - INFO - Average Score: 6052.0
2025-03-01 21:26:44,960 - INFO - Average Steps: 386.5
2025-03-01 21:26:44,960 - INFO - Best Max Tile: 512
2025-03-01 21:26:44,961 - INFO - Tile distribution:
2025-03-01 21:26:44,961 - INFO -   512: 2 games (100.0%)
2025-03-01 21:26:44,961 - INFO - Average steps to achieve tile:
2025-03-01 21:26:44,961 - INFO - Testing with temperature 1.5...
2025-03-01 21:29:57,789 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-01 21:33:00,817 - INFO - Game 2/2 completed: Max Tile = 256
2025-03-01 21:33:00,817 - INFO - ========================================
2025-03-01 21:33:00,818 - INFO - Evaluation over 2 games:
2025-03-01 21:33:00,818 - INFO - Average Max Tile: 256.0
2025-03-01 21:33:00,818 - INFO - Average Score: 3028.0
2025-03-01 21:33:00,818 - INFO - Average Steps: 239.0
2025-03-01 21:33:00,818 - INFO - Best Max Tile: 256
2025-03-01 21:33:00,819 - INFO - Tile distribution:
2025-03-01 21:33:00,819 - INFO -   256: 2 games (100.0%)
2025-03-01 21:33:00,819 - INFO - Average steps to achieve tile:
2025-03-01 21:33:00,819 - INFO - Testing with temperature 2.0...
2025-03-01 21:35:44,928 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-01 21:38:44,130 - INFO - Game 2/2 completed: Max Tile = 256
2025-03-01 21:38:44,130 - INFO - ========================================
2025-03-01 21:38:44,131 - INFO - Evaluation over 2 games:
2025-03-01 21:38:44,131 - INFO - Average Max Tile: 256.0
2025-03-01 21:38:44,131 - INFO - Average Score: 2888.0
2025-03-01 21:38:44,131 - INFO - Average Steps: 223.0
2025-03-01 21:38:44,132 - INFO - Best Max Tile: 256
2025-03-01 21:38:44,132 - INFO - Tile distribution:
2025-03-01 21:38:44,132 - INFO -   256: 2 games (100.0%)
2025-03-01 21:38:44,132 - INFO - Average steps to achieve tile:
2025-03-01 21:38:45,069 - INFO - Analyzing position after 42 steps:
2025-03-01 21:38:45,070 - INFO - [[64  4  0  0]
 [16  2  0  0]
 [ 4  2  4  0]
 [ 8  4  2  0]]
2025-03-01 21:38:46,777 - INFO - MCTS Analysis with 100 simulations:
2025-03-01 21:38:46,777 - INFO - Time taken: 1.71 seconds
2025-03-01 21:38:46,777 - INFO - Network value estimate: 1.4019
2025-03-01 21:38:46,777 - INFO - 
Action analysis:
2025-03-01 21:38:46,778 - INFO - RIGHT: Visits=425, Value=1.8255, Prior=0.6459, Max Tile=64
2025-03-01 21:38:46,778 - INFO - LEFT: Visits=216, Value=1.8428, Prior=0.2191, Max Tile=64
2025-03-01 21:38:46,778 - INFO - DOWN: Visits=26, Value=1.6229, Prior=0.1350, Max Tile=64
2025-03-01 21:38:47,989 - INFO - 
Evaluation Summary:
2025-03-01 21:38:47,990 - INFO - Regular Agent - Avg Max Tile: 140.8, Best: 256
2025-03-01 21:38:47,990 - INFO - MCTS Agent (50 sims) - Avg Max Tile: 384.0, Best: 512
2025-03-01 21:38:47,990 - INFO - 
Testing different simulation counts:
2025-03-01 21:45:32,216 - INFO - Game 1/2 completed: Max Tile = 512
2025-03-01 21:48:49,582 - INFO - Game 2/2 completed: Max Tile = 256
2025-03-01 21:48:49,582 - INFO - ========================================
2025-03-01 21:48:49,583 - INFO - Evaluation over 2 games:
2025-03-01 21:48:49,583 - INFO - Average Max Tile: 384.0
2025-03-01 21:48:49,583 - INFO - Average Score: 5018.0
2025-03-01 21:48:49,584 - INFO - Average Steps: 344.0
2025-03-01 21:48:49,584 - INFO - Best Max Tile: 512
2025-03-01 21:48:49,584 - INFO - Tile distribution:
2025-03-01 21:48:49,585 - INFO -   256: 1 games (50.0%)
2025-03-01 21:48:49,585 - INFO -   512: 1 games (50.0%)
2025-03-01 21:48:49,585 - INFO - Average steps to achieve tile:
2025-03-01 21:48:49,585 - INFO - MCTS with 50 simulations: Avg Max Tile = 384.0, Best = 512
2025-03-01 21:58:46,602 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-01 22:07:41,168 - INFO - Game 2/2 completed: Max Tile = 256
2025-03-01 22:07:41,168 - INFO - ========================================
2025-03-01 22:07:41,169 - INFO - Evaluation over 2 games:
2025-03-01 22:07:41,169 - INFO - Average Max Tile: 256.0
2025-03-01 22:07:41,169 - INFO - Average Score: 4332.0
2025-03-01 22:07:41,169 - INFO - Average Steps: 324.0
2025-03-01 22:07:41,170 - INFO - Best Max Tile: 256
2025-03-01 22:07:41,170 - INFO - Tile distribution:
2025-03-01 22:07:41,170 - INFO -   256: 2 games (100.0%)
2025-03-01 22:07:41,170 - INFO - Average steps to achieve tile:
2025-03-01 22:07:41,171 - INFO - MCTS with 100 simulations: Avg Max Tile = 256.0, Best = 256
2025-03-01 22:47:40,504 - INFO - Game 1/2 completed: Max Tile = 512
2025-03-01 23:22:57,750 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-01 23:22:57,751 - INFO - ========================================
2025-03-01 23:22:57,751 - INFO - Evaluation over 2 games:
2025-03-01 23:22:57,751 - INFO - Average Max Tile: 512.0
2025-03-01 23:22:57,752 - INFO - Average Score: 7958.0
2025-03-01 23:22:57,752 - INFO - Average Steps: 511.5
2025-03-01 23:22:57,752 - INFO - Best Max Tile: 512
2025-03-01 23:22:57,752 - INFO - Tile distribution:
2025-03-01 23:22:57,753 - INFO -   512: 2 games (100.0%)
2025-03-01 23:22:57,753 - INFO - Average steps to achieve tile:
2025-03-01 23:22:57,753 - INFO - MCTS with 200 simulations: Avg Max Tile = 512.0, Best = 512
2025-03-02 12:27:31,926 - INFO - Loading model from dqn_results/final_model.pt
2025-03-02 12:27:34,232 - INFO - Creating MCTS agent with 150 simulations
2025-03-02 12:27:34,232 - INFO - 
Evaluating regular agent...
2025-03-02 12:27:35,533 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-02 12:27:36,416 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 12:27:36,951 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 12:27:38,342 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-02 12:27:39,339 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 12:27:39,339 - INFO - ========================================
2025-03-02 12:27:39,339 - INFO - Evaluation over 5 games:
2025-03-02 12:27:39,340 - INFO - Average Max Tile: 140.8
2025-03-02 12:27:39,340 - INFO - Average Score: 1634.4
2025-03-02 12:27:39,340 - INFO - Average Steps: 155.2
2025-03-02 12:27:39,340 - INFO - Best Max Tile: 256
2025-03-02 12:27:39,341 - INFO - Tile distribution:
2025-03-02 12:27:39,341 - INFO -   64: 1 games (20.0%)
2025-03-02 12:27:39,341 - INFO -   128: 3 games (60.0%)
2025-03-02 12:27:39,341 - INFO -   256: 1 games (20.0%)
2025-03-02 12:27:39,342 - INFO - Average steps to achieve tile:
2025-03-02 12:27:39,342 - INFO - 
Evaluating MCTS agent...
2025-03-02 12:42:40,499 - INFO - Loading model from dqn_results/final_model.pt
2025-03-02 12:42:42,857 - INFO - Creating MCTS agent with 50 simulations
2025-03-02 12:42:42,857 - INFO - 
Evaluating regular agent...
2025-03-02 12:42:44,193 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-02 12:42:45,129 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 12:42:45,750 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 12:42:47,191 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-02 12:42:48,213 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 12:42:48,214 - INFO - ========================================
2025-03-02 12:42:48,214 - INFO - Evaluation over 5 games:
2025-03-02 12:42:48,214 - INFO - Average Max Tile: 140.8
2025-03-02 12:42:48,214 - INFO - Average Score: 1634.4
2025-03-02 12:42:48,214 - INFO - Average Steps: 155.2
2025-03-02 12:42:48,215 - INFO - Best Max Tile: 256
2025-03-02 12:42:48,215 - INFO - Tile distribution:
2025-03-02 12:42:48,215 - INFO -   64: 1 games (20.0%)
2025-03-02 12:42:48,215 - INFO -   128: 3 games (60.0%)
2025-03-02 12:42:48,216 - INFO -   256: 1 games (20.0%)
2025-03-02 12:42:48,216 - INFO - Average steps to achieve tile:
2025-03-02 12:42:48,216 - INFO - 
Evaluating MCTS agent...
2025-03-02 12:46:26,729 - INFO - Game 1/5 completed: Max Tile = 256
2025-03-02 12:48:02,636 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 12:49:58,137 - INFO - Game 3/5 completed: Max Tile = 128
2025-03-02 12:53:49,451 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-02 12:56:03,857 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 12:56:03,858 - INFO - ========================================
2025-03-02 12:56:03,858 - INFO - Evaluation over 5 games:
2025-03-02 12:56:03,858 - INFO - Average Max Tile: 179.2
2025-03-02 12:56:03,859 - INFO - Average Score: 1823.2
2025-03-02 12:56:03,859 - INFO - Average Steps: 158.0
2025-03-02 12:56:03,859 - INFO - Best Max Tile: 256
2025-03-02 12:56:03,859 - INFO - Tile distribution:
2025-03-02 12:56:03,860 - INFO -   128: 3 games (60.0%)
2025-03-02 12:56:03,861 - INFO -   256: 2 games (40.0%)
2025-03-02 12:56:03,861 - INFO - Average steps to achieve tile:
2025-03-02 12:56:03,861 - INFO - 
==================================================
2025-03-02 12:56:03,861 - INFO - COMPARISON RESULTS:
2025-03-02 12:56:03,861 - INFO - Average Max Tile: Regular = 140.8, MCTS = 179.2
2025-03-02 12:56:03,861 - INFO - Average Score: Regular = 1634.4, MCTS = 1823.2
2025-03-02 12:56:03,862 - INFO - Best Max Tile: Regular = 256, MCTS = 256
2025-03-02 12:56:03,862 - INFO - 
Regular Agent Tile Distribution:
2025-03-02 12:56:03,862 - INFO -   64: 1 games (20.0%)
2025-03-02 12:56:03,862 - INFO -   128: 3 games (60.0%)
2025-03-02 12:56:03,862 - INFO -   256: 1 games (20.0%)
2025-03-02 12:56:03,862 - INFO - 
MCTS Agent Tile Distribution:
2025-03-02 12:56:03,863 - INFO -   128: 3 games (60.0%)
2025-03-02 12:56:03,863 - INFO -   256: 2 games (40.0%)
2025-03-02 13:05:28,492 - INFO - Loading model from dqn_results/final_model.pt
2025-03-02 13:05:30,586 - INFO - Creating MCTS agent with 150 simulations
2025-03-02 13:05:30,586 - INFO - 
Evaluating regular agent...
2025-03-02 13:05:31,928 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-02 13:05:32,840 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 13:05:33,405 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 13:05:34,808 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-02 13:05:35,869 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 13:05:35,870 - INFO - ========================================
2025-03-02 13:05:35,870 - INFO - Evaluation over 5 games:
2025-03-02 13:05:35,870 - INFO - Average Max Tile: 140.8
2025-03-02 13:05:35,871 - INFO - Average Score: 1634.4
2025-03-02 13:05:35,871 - INFO - Average Steps: 155.2
2025-03-02 13:05:35,871 - INFO - Best Max Tile: 256
2025-03-02 13:05:35,871 - INFO - Tile distribution:
2025-03-02 13:05:35,871 - INFO -   64: 1 games (20.0%)
2025-03-02 13:05:35,872 - INFO -   128: 3 games (60.0%)
2025-03-02 13:05:35,872 - INFO -   256: 1 games (20.0%)
2025-03-02 13:05:35,872 - INFO - Average steps to achieve tile:
2025-03-02 13:05:35,872 - INFO - 
Evaluating MCTS agent...
2025-03-02 13:18:53,707 - INFO - Game 1/5 completed: Max Tile = 256
2025-03-02 13:34:28,521 - INFO - Game 2/5 completed: Max Tile = 256
2025-03-02 13:41:18,433 - INFO - Game 3/5 completed: Max Tile = 128
2025-03-02 13:48:37,444 - INFO - Loading model from dqn_results/final_model.pt
2025-03-02 13:48:39,535 - INFO - Creating MCTS agent with 150 simulations
2025-03-02 13:48:39,536 - INFO - 
Evaluating regular agent...
2025-03-02 13:48:40,925 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-02 13:48:41,850 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 13:48:42,401 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 13:48:43,801 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-02 13:48:44,802 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 13:48:44,802 - INFO - ========================================
2025-03-02 13:48:44,802 - INFO - Evaluation over 5 games:
2025-03-02 13:48:44,803 - INFO - Average Max Tile: 140.8
2025-03-02 13:48:44,803 - INFO - Average Score: 1634.4
2025-03-02 13:48:44,803 - INFO - Average Steps: 155.2
2025-03-02 13:48:44,803 - INFO - Best Max Tile: 256
2025-03-02 13:48:44,804 - INFO - Tile distribution:
2025-03-02 13:48:44,804 - INFO -   64: 1 games (20.0%)
2025-03-02 13:48:44,804 - INFO -   128: 3 games (60.0%)
2025-03-02 13:48:44,805 - INFO -   256: 1 games (20.0%)
2025-03-02 13:48:44,805 - INFO - Average steps to achieve tile:
2025-03-02 13:48:44,805 - INFO - 
Evaluating MCTS agent...
2025-03-02 14:00:14,389 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-02 14:08:15,642 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 14:26:00,326 - INFO - Game 1/5 completed: Max Tile = 32
2025-03-02 14:26:00,658 - INFO - Game 2/5 completed: Max Tile = 32
2025-03-02 14:26:01,249 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 14:26:02,290 - INFO - Game 4/5 completed: Max Tile = 128
2025-03-02 14:26:03,081 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 14:26:03,082 - INFO - ========================================
2025-03-02 14:26:03,082 - INFO - Evaluation over 5 games:
2025-03-02 14:26:03,082 - INFO - Average Max Tile: 76.8
2025-03-02 14:26:03,082 - INFO - Average Score: 852.8
2025-03-02 14:26:03,083 - INFO - Average Steps: 98.4
2025-03-02 14:26:03,083 - INFO - Best Max Tile: 128
2025-03-02 14:26:03,083 - INFO - Tile distribution:
2025-03-02 14:26:03,084 - INFO -   32: 2 games (40.0%)
2025-03-02 14:26:03,084 - INFO -   64: 1 games (20.0%)
2025-03-02 14:26:03,084 - INFO -   128: 2 games (40.0%)
2025-03-02 14:26:03,084 - INFO - Average steps to achieve tile:
2025-03-02 14:26:25,416 - INFO - Game 1/5 completed: Max Tile = 32
2025-03-02 14:26:25,742 - INFO - Game 2/5 completed: Max Tile = 32
2025-03-02 14:26:26,323 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 14:26:27,310 - INFO - Game 4/5 completed: Max Tile = 128
2025-03-02 14:26:28,095 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 14:26:28,096 - INFO - ========================================
2025-03-02 14:26:28,096 - INFO - Evaluation over 5 games:
2025-03-02 14:26:28,096 - INFO - Average Max Tile: 76.8
2025-03-02 14:26:28,097 - INFO - Average Score: 852.8
2025-03-02 14:26:28,097 - INFO - Average Steps: 98.4
2025-03-02 14:26:28,097 - INFO - Best Max Tile: 128
2025-03-02 14:26:28,097 - INFO - Tile distribution:
2025-03-02 14:26:28,098 - INFO -   32: 2 games (40.0%)
2025-03-02 14:26:28,098 - INFO -   64: 1 games (20.0%)
2025-03-02 14:26:28,098 - INFO -   128: 2 games (40.0%)
2025-03-02 14:26:28,098 - INFO - Average steps to achieve tile:
2025-03-02 14:27:35,650 - INFO - Game 1/5 completed: Max Tile = 16
2025-03-02 14:28:37,489 - INFO - Game 2/5 completed: Max Tile = 16
2025-03-02 14:30:22,781 - INFO - Game 3/5 completed: Max Tile = 32
2025-03-02 14:31:39,063 - INFO - Game 4/5 completed: Max Tile = 16
2025-03-02 14:35:29,923 - INFO - Loading model from 5
2025-03-02 14:35:46,470 - INFO - Loading model from 5
2025-03-02 14:37:15,076 - INFO - Loading model from dqn_results/final_model.pt
2025-03-02 14:37:17,235 - INFO - Creating MCTS agent with 150 simulations
2025-03-02 14:37:17,235 - INFO - 
Evaluating regular agent...
2025-03-02 14:37:18,569 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-02 14:37:19,505 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-02 14:37:20,045 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-02 14:37:21,445 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-02 14:37:22,478 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-02 14:37:22,479 - INFO - ========================================
2025-03-02 14:37:22,479 - INFO - Evaluation over 5 games:
2025-03-02 14:37:22,479 - INFO - Average Max Tile: 140.8
2025-03-02 14:37:22,480 - INFO - Average Score: 1634.4
2025-03-02 14:37:22,480 - INFO - Average Steps: 155.2
2025-03-02 14:37:22,480 - INFO - Best Max Tile: 256
2025-03-02 14:37:22,480 - INFO - Tile distribution:
2025-03-02 14:37:22,481 - INFO -   64: 1 games (20.0%)
2025-03-02 14:37:22,481 - INFO -   128: 3 games (60.0%)
2025-03-02 14:37:22,481 - INFO -   256: 1 games (20.0%)
2025-03-02 14:37:22,481 - INFO - Average steps to achieve tile:
2025-03-02 14:37:22,482 - INFO - 
Evaluating MCTS agent...
2025-03-02 15:01:48,254 - INFO - Game 1/5 completed: Max Tile = 512
2025-03-02 15:26:29,226 - INFO - Game 2/5 completed: Max Tile = 512
2025-03-02 15:43:14,505 - INFO - Game 3/5 completed: Max Tile = 512
2025-03-02 15:57:59,933 - INFO - Game 4/5 completed: Max Tile = 512
2025-03-02 16:14:31,469 - INFO - Game 5/5 completed: Max Tile = 512
2025-03-02 16:14:31,469 - INFO - ========================================
2025-03-02 16:14:31,470 - INFO - Evaluation over 5 games:
2025-03-02 16:14:31,470 - INFO - Average Max Tile: 512.0
2025-03-02 16:14:31,471 - INFO - Average Score: 5884.0
2025-03-02 16:14:31,471 - INFO - Average Steps: 378.2
2025-03-02 16:14:31,471 - INFO - Best Max Tile: 512
2025-03-02 16:14:31,471 - INFO - Tile distribution:
2025-03-02 16:14:31,472 - INFO -   512: 5 games (100.0%)
2025-03-02 16:14:31,472 - INFO - Average steps to achieve tile:
2025-03-02 16:14:31,472 - INFO - 
==================================================
2025-03-02 16:14:31,473 - INFO - COMPARISON RESULTS:
2025-03-02 16:14:31,473 - INFO - Average Max Tile: Regular = 140.8, MCTS = 512.0
2025-03-02 16:14:31,473 - INFO - Average Score: Regular = 1634.4, MCTS = 5884.0
2025-03-02 16:14:31,473 - INFO - Best Max Tile: Regular = 256, MCTS = 512
2025-03-02 16:14:31,474 - INFO - 
Regular Agent Tile Distribution:
2025-03-02 16:14:31,474 - INFO -   64: 1 games (20.0%)
2025-03-02 16:14:31,474 - INFO -   128: 3 games (60.0%)
2025-03-02 16:14:31,474 - INFO -   256: 1 games (20.0%)
2025-03-02 16:14:31,474 - INFO - 
MCTS Agent Tile Distribution:
2025-03-02 16:14:31,475 - INFO -   512: 5 games (100.0%)
2025-03-02 16:39:51,101 - INFO - Loading model from dqn_results/final_model.pt
2025-03-02 16:39:53,209 - INFO - Creating enhanced MCTS agent with 250 simulations
2025-03-02 16:39:53,210 - INFO - 
Evaluating regular agent...
2025-03-02 16:39:54,541 - INFO - Game 1/3 completed: Max Tile = 128
2025-03-02 16:39:55,432 - INFO - Game 2/3 completed: Max Tile = 128
2025-03-02 16:39:56,008 - INFO - Game 3/3 completed: Max Tile = 64
2025-03-02 16:39:56,009 - INFO - ========================================
2025-03-02 16:39:56,009 - INFO - Evaluation over 3 games:
2025-03-02 16:39:56,009 - INFO - Average Max Tile: 106.7
2025-03-02 16:39:56,010 - INFO - Average Score: 1297.3
2025-03-02 16:39:56,010 - INFO - Average Steps: 133.3
2025-03-02 16:39:56,010 - INFO - Best Max Tile: 128
2025-03-02 16:39:56,011 - INFO - Tile distribution:
2025-03-02 16:39:56,011 - INFO -   64: 1 games (33.3%)
2025-03-02 16:39:56,011 - INFO -   128: 2 games (66.7%)
2025-03-02 16:39:56,011 - INFO - Average steps to achieve tile:
2025-03-02 16:39:56,012 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-02 17:11:29,376 - INFO - Game 1/3 completed: Max Tile = 256
2025-03-02 18:27:11,414 - INFO - Game 2/3 completed: Max Tile = 512
2025-03-02 19:09:17,871 - INFO - Game 3/3 completed: Max Tile = 256
2025-03-02 19:09:17,872 - INFO - ========================================
2025-03-02 19:09:17,872 - INFO - Evaluation over 3 games:
2025-03-02 19:09:17,872 - INFO - Average Max Tile: 341.3
2025-03-02 19:09:17,873 - INFO - Average Score: 4185.3
2025-03-02 19:09:17,873 - INFO - Average Steps: 297.3
2025-03-02 19:09:17,873 - INFO - Best Max Tile: 512
2025-03-02 19:09:17,873 - INFO - Tile distribution:
2025-03-02 19:09:17,873 - INFO -   256: 2 games (66.7%)
2025-03-02 19:09:17,873 - INFO -   512: 1 games (33.3%)
2025-03-02 19:09:17,874 - INFO - Average steps to achieve tile:
2025-03-02 19:09:17,874 - INFO - 
==================================================
2025-03-02 19:09:17,874 - INFO - COMPARISON RESULTS:
2025-03-02 19:09:17,875 - INFO - Average Max Tile: Regular = 106.7, Enhanced MCTS = 341.3
2025-03-02 19:09:17,875 - INFO - Average Score: Regular = 1297.3, Enhanced MCTS = 4185.3
2025-03-02 19:09:17,875 - INFO - Best Max Tile: Regular = 128, Enhanced MCTS = 512
2025-03-02 19:09:17,875 - INFO - 
Regular Agent Tile Distribution:
2025-03-02 19:09:17,876 - INFO -   64: 1 games (33.3%)
2025-03-02 19:09:17,876 - INFO -   128: 2 games (66.7%)
2025-03-02 19:09:17,876 - INFO - 
Enhanced MCTS Agent Tile Distribution:
2025-03-02 19:09:17,876 - INFO -   256: 2 games (66.7%)
2025-03-02 19:09:17,877 - INFO -   512: 1 games (33.3%)
2025-03-02 19:09:17,877 - INFO - 
==================================================
2025-03-02 19:09:17,877 - INFO - RUNNING SIMULATION COUNT COMPARISON
2025-03-02 19:09:17,877 - INFO - 
Evaluating with 50 simulations...
2025-03-02 19:25:15,760 - INFO - Game 1/2 completed: Max Tile = 512
2025-03-02 19:29:24,487 - INFO - Game 2/2 completed: Max Tile = 256
2025-03-02 19:29:24,488 - INFO - ========================================
2025-03-02 19:29:24,488 - INFO - Evaluation over 2 games:
2025-03-02 19:29:24,488 - INFO - Average Max Tile: 384.0
2025-03-02 19:29:24,489 - INFO - Average Score: 4682.0
2025-03-02 19:29:24,489 - INFO - Average Steps: 317.0
2025-03-02 19:29:24,489 - INFO - Best Max Tile: 512
2025-03-02 19:29:24,490 - INFO - Tile distribution:
2025-03-02 19:29:24,490 - INFO -   256: 1 games (50.0%)
2025-03-02 19:29:24,490 - INFO -   512: 1 games (50.0%)
2025-03-02 19:29:24,491 - INFO - Average steps to achieve tile:
2025-03-02 19:29:24,491 - INFO - 
Evaluating with 100 simulations...
2025-03-02 19:42:19,015 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-02 20:06:29,976 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-02 20:06:29,977 - INFO - ========================================
2025-03-02 20:06:29,977 - INFO - Evaluation over 2 games:
2025-03-02 20:06:29,978 - INFO - Average Max Tile: 384.0
2025-03-02 20:06:29,978 - INFO - Average Score: 3992.0
2025-03-02 20:06:29,978 - INFO - Average Steps: 284.0
2025-03-02 20:06:29,979 - INFO - Best Max Tile: 512
2025-03-02 20:06:29,979 - INFO - Tile distribution:
2025-03-02 20:06:29,979 - INFO -   256: 1 games (50.0%)
2025-03-02 20:06:29,980 - INFO -   512: 1 games (50.0%)
2025-03-02 20:06:29,980 - INFO - Average steps to achieve tile:
2025-03-02 20:06:29,980 - INFO - 
Evaluating with 200 simulations...
2025-03-02 21:42:40,430 - INFO - Game 1/2 completed: Max Tile = 1024
2025-03-02 22:48:47,465 - INFO - Game 2/2 completed: Max Tile = 512
2025-03-02 22:48:47,465 - INFO - ========================================
2025-03-02 22:48:47,466 - INFO - Evaluation over 2 games:
2025-03-02 22:48:47,466 - INFO - Average Max Tile: 768.0
2025-03-02 22:48:47,467 - INFO - Average Score: 9362.0
2025-03-02 22:48:47,467 - INFO - Average Steps: 552.5
2025-03-02 22:48:47,467 - INFO - Best Max Tile: 1024
2025-03-02 22:48:47,468 - INFO - Tile distribution:
2025-03-02 22:48:47,468 - INFO -   512: 1 games (50.0%)
2025-03-02 22:48:47,468 - INFO -   1024: 1 games (50.0%)
2025-03-02 22:48:47,469 - INFO - Average steps to achieve tile:
2025-03-02 22:48:47,469 - INFO - 
Evaluating with 300 simulations...
2025-03-02 23:27:58,468 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-03 08:08:30,555 - INFO - Loading model from dqn_results/final_model.pt
2025-03-03 08:08:32,723 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-03 08:08:32,723 - INFO - 
Evaluating regular agent...
2025-03-03 08:08:34,006 - INFO - Game 1/10 completed: Max Tile = 128
2025-03-03 08:08:34,876 - INFO - Game 2/10 completed: Max Tile = 128
2025-03-03 08:08:35,408 - INFO - Game 3/10 completed: Max Tile = 64
2025-03-03 08:08:36,763 - INFO - Game 4/10 completed: Max Tile = 256
2025-03-03 08:08:37,721 - INFO - Game 5/10 completed: Max Tile = 128
2025-03-03 08:08:38,378 - INFO - Game 6/10 completed: Max Tile = 128
2025-03-03 08:08:39,178 - INFO - Game 7/10 completed: Max Tile = 128
2025-03-03 08:08:40,133 - INFO - Game 8/10 completed: Max Tile = 128
2025-03-03 08:08:41,166 - INFO - Game 9/10 completed: Max Tile = 128
2025-03-03 08:08:42,711 - INFO - Game 10/10 completed: Max Tile = 256
2025-03-03 08:08:42,711 - INFO - ========================================
2025-03-03 08:08:42,712 - INFO - Evaluation over 10 games:
2025-03-03 08:08:42,712 - INFO - Average Max Tile: 147.2
2025-03-03 08:08:42,712 - INFO - Average Score: 1704.8
2025-03-03 08:08:42,712 - INFO - Average Steps: 159.5
2025-03-03 08:08:42,713 - INFO - Best Max Tile: 256
2025-03-03 08:08:42,713 - INFO - Tile distribution:
2025-03-03 08:08:42,713 - INFO -   64: 1 games (10.0%)
2025-03-03 08:08:42,714 - INFO -   128: 7 games (70.0%)
2025-03-03 08:08:42,714 - INFO -   256: 2 games (20.0%)
2025-03-03 08:08:42,714 - INFO - Average steps to achieve tile:
2025-03-03 08:08:42,714 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-03 09:03:04,822 - INFO - Game 1/10 completed: Max Tile = 512
2025-03-03 10:05:27,103 - INFO - Game 2/10 completed: Max Tile = 512
2025-03-03 11:00:21,912 - INFO - Game 3/10 completed: Max Tile = 512
2025-03-03 11:41:42,461 - INFO - Game 4/10 completed: Max Tile = 256
2025-03-03 12:30:50,687 - INFO - Game 5/10 completed: Max Tile = 512
2025-03-03 13:19:36,757 - INFO - Game 6/10 completed: Max Tile = 512
2025-03-03 13:44:07,348 - INFO - Game 7/10 completed: Max Tile = 256
2025-03-03 14:42:41,761 - INFO - Game 8/10 completed: Max Tile = 512
2025-03-03 15:21:43,353 - INFO - Game 9/10 completed: Max Tile = 256
2025-03-03 15:44:22,586 - INFO - Game 10/10 completed: Max Tile = 256
2025-03-03 15:44:22,587 - INFO - ========================================
2025-03-03 15:44:22,587 - INFO - Evaluation over 10 games:
2025-03-03 15:44:22,587 - INFO - Average Max Tile: 409.6
2025-03-03 15:44:22,588 - INFO - Average Score: 4882.8
2025-03-03 15:44:22,588 - INFO - Average Steps: 336.2
2025-03-03 15:44:22,588 - INFO - Best Max Tile: 512
2025-03-03 15:44:22,589 - INFO - Tile distribution:
2025-03-03 15:44:22,589 - INFO -   256: 4 games (40.0%)
2025-03-03 15:44:22,589 - INFO -   512: 6 games (60.0%)
2025-03-03 15:44:22,589 - INFO - Average steps to achieve tile:
2025-03-03 15:44:22,590 - INFO - 
==================================================
2025-03-03 15:44:22,590 - INFO - COMPARISON RESULTS:
2025-03-03 15:44:22,590 - INFO - Average Max Tile: Regular = 147.2, Enhanced MCTS = 409.6
2025-03-03 15:44:22,590 - INFO - Average Score: Regular = 1704.8, Enhanced MCTS = 4882.8
2025-03-03 15:44:22,591 - INFO - Best Max Tile: Regular = 256, Enhanced MCTS = 512
2025-03-03 15:44:22,591 - INFO - 
Regular Agent Tile Distribution:
2025-03-03 15:44:22,591 - INFO -   64: 1 games (10.0%)
2025-03-03 15:44:22,591 - INFO -   128: 7 games (70.0%)
2025-03-03 15:44:22,592 - INFO -   256: 2 games (20.0%)
2025-03-03 15:44:22,592 - INFO - 
Enhanced MCTS Agent Tile Distribution:
2025-03-03 15:44:22,592 - INFO -   256: 4 games (40.0%)
2025-03-03 15:44:22,593 - INFO -   512: 6 games (60.0%)
2025-03-03 16:55:07,089 - INFO - Loading base agent from models/dqn_agent.pt
2025-03-03 16:56:21,177 - INFO - Loading base agent from models/dqn_agent.pt
2025-03-03 16:57:49,469 - INFO - Loading base agent from models/dqn_agent.pt
2025-03-03 16:57:51,794 - INFO - Evaluating MCTS agent with 5 games
2025-03-03 16:58:06,312 - INFO - Loading base agent from models/dqn_agent.pt
2025-03-03 16:58:08,572 - INFO - Evaluating MCTS agent with 5 games
2025-03-03 16:59:09,900 - INFO - Loading base agent from models/dqn_agent.pt
2025-03-03 16:59:12,158 - INFO - Evaluating MCTS agent with 3 games
2025-03-03 17:06:57,505 - INFO - Results saved to results/enhanced_mcts_evaluation_20250303_170657.csv
2025-03-03 17:27:05,234 - INFO - Loading base agent from models/dqn_agent.pt
2025-03-03 17:27:07,597 - INFO - Evaluating MCTS agent with 3 games
2025-03-03 23:43:02,332 - INFO - Results saved to results/enhanced_mcts_evaluation_20250303_234302.csv
2025-03-04 09:50:48,635 - INFO - Loading model from dqn_results/final_model.pt
2025-03-04 09:50:50,901 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-04 09:50:50,901 - INFO - 
Evaluating regular agent...
2025-03-04 09:50:52,249 - INFO - Game 1/3 completed: Max Tile = 128
2025-03-04 09:50:53,118 - INFO - Game 2/3 completed: Max Tile = 128
2025-03-04 09:50:53,682 - INFO - Game 3/3 completed: Max Tile = 64
2025-03-04 09:50:53,683 - INFO - ========================================
2025-03-04 09:50:53,683 - INFO - Evaluation over 3 games:
2025-03-04 09:50:53,684 - INFO - Average Max Tile: 106.7
2025-03-04 09:50:53,684 - INFO - Average Score: 1297.3
2025-03-04 09:50:53,684 - INFO - Average Steps: 133.3
2025-03-04 09:50:53,684 - INFO - Best Max Tile: 128
2025-03-04 09:50:53,685 - INFO - Tile distribution:
2025-03-04 09:50:53,685 - INFO -   64: 1 games (33.3%)
2025-03-04 09:50:53,685 - INFO -   128: 2 games (66.7%)
2025-03-04 09:50:53,686 - INFO - Average steps to achieve tile:
2025-03-04 09:50:53,687 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-04 10:11:37,070 - INFO - Game 1/3 completed: Max Tile = 256
2025-03-04 10:20:25,186 - INFO - Loading model from dqn_results/final_model.pt
2025-03-04 10:20:27,198 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-04 10:20:27,198 - INFO - 
Evaluating regular agent...
2025-03-04 10:20:28,501 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-04 10:20:29,395 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-04 10:20:29,924 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-04 10:20:31,288 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-04 10:20:32,269 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-04 10:20:32,269 - INFO - ========================================
2025-03-04 10:20:32,270 - INFO - Evaluation over 5 games:
2025-03-04 10:20:32,270 - INFO - Average Max Tile: 140.8
2025-03-04 10:20:32,270 - INFO - Average Score: 1634.4
2025-03-04 10:20:32,270 - INFO - Average Steps: 155.2
2025-03-04 10:20:32,271 - INFO - Best Max Tile: 256
2025-03-04 10:20:32,271 - INFO - Tile distribution:
2025-03-04 10:20:32,271 - INFO -   64: 1 games (20.0%)
2025-03-04 10:20:32,272 - INFO -   128: 3 games (60.0%)
2025-03-04 10:20:32,272 - INFO -   256: 1 games (20.0%)
2025-03-04 10:20:32,272 - INFO - Average steps to achieve tile:
2025-03-04 10:20:32,272 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-04 10:35:29,362 - INFO - Game 1/5 completed: Max Tile = 256
2025-03-04 11:26:45,085 - INFO - Game 2/5 completed: Max Tile = 512
2025-03-04 11:55:54,698 - INFO - Game 3/5 completed: Max Tile = 512
2025-03-04 12:17:28,157 - INFO - Game 4/5 completed: Max Tile = 256
2025-03-04 12:29:10,112 - INFO - Game 5/5 completed: Max Tile = 256
2025-03-04 12:29:10,113 - INFO - ========================================
2025-03-04 12:29:10,113 - INFO - Evaluation over 5 games:
2025-03-04 12:29:10,113 - INFO - Average Max Tile: 358.4
2025-03-04 12:29:10,114 - INFO - Average Score: 3660.0
2025-03-04 12:29:10,114 - INFO - Average Steps: 261.6
2025-03-04 12:29:10,114 - INFO - Best Max Tile: 512
2025-03-04 12:29:10,114 - INFO - Tile distribution:
2025-03-04 12:29:10,115 - INFO -   256: 3 games (60.0%)
2025-03-04 12:29:10,115 - INFO -   512: 2 games (40.0%)
2025-03-04 12:29:10,115 - INFO - Average steps to achieve tile:
2025-03-04 12:29:10,115 - INFO - 
==================================================
2025-03-04 12:29:10,115 - INFO - COMPARISON RESULTS:
2025-03-04 12:29:10,116 - INFO - Average Max Tile: Regular = 140.8, Enhanced MCTS = 358.4
2025-03-04 12:29:10,116 - INFO - Average Score: Regular = 1634.4, Enhanced MCTS = 3660.0
2025-03-04 12:29:10,116 - INFO - Best Max Tile: Regular = 256, Enhanced MCTS = 512
2025-03-04 12:29:10,116 - INFO - 
Regular Agent Tile Distribution:
2025-03-04 12:29:10,116 - INFO -   64: 1 games (20.0%)
2025-03-04 12:29:10,117 - INFO -   128: 3 games (60.0%)
2025-03-04 12:29:10,117 - INFO -   256: 1 games (20.0%)
2025-03-04 12:29:10,117 - INFO - 
Enhanced MCTS Agent Tile Distribution:
2025-03-04 12:29:10,117 - INFO -   256: 3 games (60.0%)
2025-03-04 12:29:10,117 - INFO -   512: 2 games (40.0%)
2025-03-04 18:50:36,816 - INFO - Starting training with device: cuda
2025-03-04 18:50:36,817 - INFO - Model parameters: 3394954
2025-03-04 18:50:37,630 - INFO - New best score: 2970.731244033574 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:50:41,951 - INFO - New best score: 3082.1781187534325 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:51:02,566 - INFO - New best score: 3621.9281171381476 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:51:06,084 - INFO - New best score: 5388.059368750456 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:51:24,698 - INFO - New best score: 5601.296867364646 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:52:10,942 - INFO - New best score: 8558.146865475179 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:52:38,197 - INFO - New best score: 8783.762491774556 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:53:27,254 - INFO - Episode 100/100000 - Avg Reward: 3160.68 - Avg Max Tile: 139.20 - Epsilon: 0.010 - Beta: 0.401
2025-03-04 18:53:49,668 - INFO - New best score: 8995.178113901611 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:56:21,825 - INFO - New best score: 9658.728112649915 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 18:56:33,800 - INFO - Episode 200/100000 - Avg Reward: 3441.52 - Avg Max Tile: 150.08 - Epsilon: 0.010 - Beta: 0.401
2025-03-04 19:00:01,274 - INFO - Episode 300/100000 - Avg Reward: 3738.92 - Avg Max Tile: 164.80 - Epsilon: 0.010 - Beta: 0.402
2025-03-04 19:03:11,705 - INFO - Episode 400/100000 - Avg Reward: 3360.55 - Avg Max Tile: 143.84 - Epsilon: 0.010 - Beta: 0.402
2025-03-04 19:04:48,172 - INFO - New best score: 9913.071863532063 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:06:36,996 - INFO - Episode 500/100000 - Avg Reward: 3664.69 - Avg Max Tile: 160.64 - Epsilon: 0.010 - Beta: 0.403
2025-03-04 19:09:37,069 - INFO - Starting training with device: cuda
2025-03-04 19:09:37,069 - INFO - Model parameters: 3394954
2025-03-04 19:09:37,072 - INFO - New highest tile achieved: 2 (Episode 1)
2025-03-04 19:09:37,075 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-04 19:09:37,086 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-04 19:09:37,096 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-04 19:09:37,136 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-04 19:09:37,160 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-04 19:09:37,247 - INFO - New highest tile achieved: 128 (Episode 1)
2025-03-04 19:09:37,870 - INFO - New best score: 2970.731244033574 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:09:42,357 - INFO - New best score: 3082.1781187534325 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:10:03,475 - INFO - New best score: 3621.9281171381476 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:10:06,102 - INFO - New highest tile achieved: 256 (Episode 25)
2025-03-04 19:10:06,939 - INFO - New best score: 5388.059368750456 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:10:25,701 - INFO - New best score: 5601.296867364646 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:11:11,571 - INFO - New highest tile achieved: 512 (Episode 62)
2025-03-04 19:11:12,341 - INFO - New best score: 8558.146865475179 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:11:39,374 - INFO - New best score: 8783.762491774556 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:12:27,873 - INFO - Episode 100/50000 - Avg Reward: 3160.68 - Avg Max Tile: 139.20 - Epsilon: 0.010 - Beta: 0.401
2025-03-04 19:12:50,206 - INFO - New best score: 8995.178113901611 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:15:25,117 - INFO - New best score: 9658.728112649915 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:15:37,420 - INFO - Episode 200/50000 - Avg Reward: 3441.52 - Avg Max Tile: 150.08 - Epsilon: 0.010 - Beta: 0.401
2025-03-04 19:19:03,745 - INFO - Episode 300/50000 - Avg Reward: 3738.92 - Avg Max Tile: 164.80 - Epsilon: 0.010 - Beta: 0.402
2025-03-04 19:22:11,494 - INFO - Episode 400/50000 - Avg Reward: 3360.55 - Avg Max Tile: 143.84 - Epsilon: 0.010 - Beta: 0.402
2025-03-04 19:23:46,218 - INFO - New best score: 9913.071863532063 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:25:31,945 - INFO - Episode 500/50000 - Avg Reward: 3664.69 - Avg Max Tile: 160.64 - Epsilon: 0.010 - Beta: 0.403
2025-03-04 19:28:57,107 - INFO - Episode 600/50000 - Avg Reward: 3643.39 - Avg Max Tile: 156.48 - Epsilon: 0.010 - Beta: 0.404
2025-03-04 19:30:20,844 - INFO - New best score: 11576.696858221305 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:32:11,148 - INFO - Episode 700/50000 - Avg Reward: 3462.84 - Avg Max Tile: 149.76 - Epsilon: 0.010 - Beta: 0.404
2025-03-04 19:35:21,739 - INFO - Episode 800/50000 - Avg Reward: 3319.05 - Avg Max Tile: 140.16 - Epsilon: 0.010 - Beta: 0.405
2025-03-04 19:38:50,931 - INFO - Episode 900/50000 - Avg Reward: 3741.88 - Avg Max Tile: 165.76 - Epsilon: 0.010 - Beta: 0.405
2025-03-04 19:44:21,780 - INFO - Starting training with device: cuda
2025-03-04 19:44:21,782 - INFO - Model parameters: 3394954
2025-03-04 19:44:21,785 - INFO - New highest tile achieved: 2 (Episode 1)
2025-03-04 19:44:21,787 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-04 19:44:21,797 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-04 19:44:21,807 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-04 19:44:21,847 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-04 19:44:21,871 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-04 19:44:21,961 - INFO - New highest tile achieved: 128 (Episode 1)
2025-03-04 19:44:22,156 - INFO - New best score: 2970.731244033574 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:44:22,989 - INFO - New best score: 3509.028116792443 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:44:49,261 - INFO - New highest tile achieved: 256 (Episode 26)
2025-03-04 19:44:49,966 - INFO - New best score: 4835.187491637467 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:45:08,405 - INFO - Starting training with device: cuda
2025-03-04 19:45:08,406 - INFO - Model parameters: 3394954
2025-03-04 19:45:08,409 - INFO - New highest tile achieved: 2 (Episode 1)
2025-03-04 19:45:08,411 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-04 19:45:08,421 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-04 19:45:08,431 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-04 19:45:08,471 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-04 19:45:08,498 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-04 19:45:08,587 - INFO - New highest tile achieved: 128 (Episode 1)
2025-03-04 19:45:08,783 - INFO - New best score: 2970.731244033574 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:45:09,613 - INFO - New best score: 3509.028116792443 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:45:36,314 - INFO - New highest tile achieved: 256 (Episode 26)
2025-03-04 19:45:36,983 - INFO - New best score: 4835.187491637467 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:46:13,958 - INFO - New best score: 4909.731243944167 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:47:07,681 - INFO - New best score: 6226.09373958707 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:47:41,910 - INFO - Episode 100/50000 - Avg Reward: 2694.14 - Avg Max Tile: 112.32 - Epsilon: 0.100 - Beta: 0.401
2025-03-04 19:50:28,586 - INFO - Episode 200/50000 - Avg Reward: 2791.80 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.401
2025-03-04 19:51:41,828 - INFO - New highest tile achieved: 512 (Episode 244)
2025-03-04 19:51:42,036 - INFO - New best score: 8041.97499014735 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 19:53:06,434 - INFO - Episode 300/50000 - Avg Reward: 2811.57 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.402
2025-03-04 19:55:47,988 - INFO - Episode 400/50000 - Avg Reward: 2770.25 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.402
2025-03-04 19:58:20,779 - INFO - Episode 500/50000 - Avg Reward: 2528.76 - Avg Max Tile: 107.52 - Epsilon: 0.100 - Beta: 0.403
2025-03-04 20:01:09,058 - INFO - Episode 600/50000 - Avg Reward: 2785.58 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.404
2025-03-04 20:04:02,452 - INFO - Episode 700/50000 - Avg Reward: 2884.78 - Avg Max Tile: 124.96 - Epsilon: 0.100 - Beta: 0.404
2025-03-04 20:06:45,175 - INFO - Episode 800/50000 - Avg Reward: 2628.61 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.405
2025-03-04 20:09:22,854 - INFO - Episode 900/50000 - Avg Reward: 2579.21 - Avg Max Tile: 111.20 - Epsilon: 0.100 - Beta: 0.405
2025-03-04 20:12:13,432 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-04 20:12:13,432 - INFO - Episode 1000/50000 - Avg Reward: 2820.63 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.406
2025-03-04 20:15:06,328 - INFO - Episode 1100/50000 - Avg Reward: 2807.89 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.407
2025-03-04 20:18:08,728 - INFO - Episode 1200/50000 - Avg Reward: 3040.88 - Avg Max Tile: 132.48 - Epsilon: 0.100 - Beta: 0.407
2025-03-04 20:20:50,874 - INFO - Episode 1300/50000 - Avg Reward: 2720.38 - Avg Max Tile: 121.44 - Epsilon: 0.100 - Beta: 0.408
2025-03-04 20:23:46,334 - INFO - Episode 1400/50000 - Avg Reward: 2886.43 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.408
2025-03-04 20:26:23,917 - INFO - Episode 1500/50000 - Avg Reward: 2556.60 - Avg Max Tile: 109.12 - Epsilon: 0.100 - Beta: 0.409
2025-03-04 20:29:19,444 - INFO - Episode 1600/50000 - Avg Reward: 2886.16 - Avg Max Tile: 123.68 - Epsilon: 0.100 - Beta: 0.410
2025-03-04 20:32:07,204 - INFO - Episode 1700/50000 - Avg Reward: 2778.67 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.410
2025-03-04 20:34:58,524 - INFO - Episode 1800/50000 - Avg Reward: 2891.89 - Avg Max Tile: 130.40 - Epsilon: 0.100 - Beta: 0.411
2025-03-04 20:37:43,810 - INFO - Episode 1900/50000 - Avg Reward: 2693.82 - Avg Max Tile: 113.28 - Epsilon: 0.100 - Beta: 0.411
2025-03-04 20:40:39,249 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_2000.pt
2025-03-04 20:40:39,250 - INFO - Episode 2000/50000 - Avg Reward: 2908.77 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.412
2025-03-04 20:41:30,311 - INFO - New best score: 8202.134363359217 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 20:42:16,474 - INFO - New best score: 8497.553115448356 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 20:43:40,060 - INFO - Episode 2100/50000 - Avg Reward: 2997.32 - Avg Max Tile: 131.20 - Epsilon: 0.100 - Beta: 0.413
2025-03-04 20:46:29,579 - INFO - Episode 2200/50000 - Avg Reward: 2804.07 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.413
2025-03-04 20:49:18,340 - INFO - Episode 2300/50000 - Avg Reward: 2769.87 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.414
2025-03-04 20:51:58,827 - INFO - New best score: 8534.337485402822 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 20:52:12,192 - INFO - Episode 2400/50000 - Avg Reward: 2870.45 - Avg Max Tile: 125.76 - Epsilon: 0.100 - Beta: 0.414
2025-03-04 20:54:10,715 - INFO - New best score: 8590.412485092878 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 20:55:10,823 - INFO - Episode 2500/50000 - Avg Reward: 2949.45 - Avg Max Tile: 131.04 - Epsilon: 0.100 - Beta: 0.415
2025-03-04 20:58:02,663 - INFO - Episode 2600/50000 - Avg Reward: 2847.42 - Avg Max Tile: 124.80 - Epsilon: 0.100 - Beta: 0.416
2025-03-04 21:00:57,223 - INFO - Episode 2700/50000 - Avg Reward: 2869.33 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.416
2025-03-04 21:03:39,522 - INFO - Episode 2800/50000 - Avg Reward: 2617.92 - Avg Max Tile: 112.00 - Epsilon: 0.100 - Beta: 0.417
2025-03-04 21:06:29,095 - INFO - Episode 2900/50000 - Avg Reward: 2804.35 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.417
2025-03-04 21:09:22,017 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_3000.pt
2025-03-04 21:09:22,018 - INFO - Episode 3000/50000 - Avg Reward: 2881.27 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.418
2025-03-04 21:12:14,578 - INFO - Episode 3100/50000 - Avg Reward: 2700.39 - Avg Max Tile: 113.60 - Epsilon: 0.100 - Beta: 0.419
2025-03-04 21:15:15,315 - INFO - Episode 3200/50000 - Avg Reward: 2930.96 - Avg Max Tile: 126.56 - Epsilon: 0.100 - Beta: 0.419
2025-03-04 21:18:01,294 - INFO - Episode 3300/50000 - Avg Reward: 2700.32 - Avg Max Tile: 116.48 - Epsilon: 0.100 - Beta: 0.420
2025-03-04 21:21:06,121 - INFO - Episode 3400/50000 - Avg Reward: 3014.82 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.420
2025-03-04 21:23:51,126 - INFO - Episode 3500/50000 - Avg Reward: 2791.39 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.421
2025-03-04 21:26:50,330 - INFO - Episode 3600/50000 - Avg Reward: 2906.27 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.422
2025-03-04 21:29:34,013 - INFO - Episode 3700/50000 - Avg Reward: 2715.67 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.422
2025-03-04 21:32:21,943 - INFO - Episode 3800/50000 - Avg Reward: 2744.17 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.423
2025-03-04 21:35:20,135 - INFO - Episode 3900/50000 - Avg Reward: 2947.04 - Avg Max Tile: 128.64 - Epsilon: 0.100 - Beta: 0.423
2025-03-04 21:38:05,803 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_4000.pt
2025-03-04 21:38:05,804 - INFO - Episode 4000/50000 - Avg Reward: 2712.43 - Avg Max Tile: 113.60 - Epsilon: 0.100 - Beta: 0.424
2025-03-04 21:40:53,273 - INFO - Episode 4100/50000 - Avg Reward: 2737.95 - Avg Max Tile: 116.16 - Epsilon: 0.100 - Beta: 0.425
2025-03-04 21:43:43,970 - INFO - Episode 4200/50000 - Avg Reward: 2833.75 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.425
2025-03-04 21:46:36,376 - INFO - Episode 4300/50000 - Avg Reward: 2824.37 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.426
2025-03-04 21:49:27,347 - INFO - Episode 4400/50000 - Avg Reward: 2847.78 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.426
2025-03-04 21:52:10,027 - INFO - Episode 4500/50000 - Avg Reward: 2615.45 - Avg Max Tile: 106.56 - Epsilon: 0.100 - Beta: 0.427
2025-03-04 21:55:09,675 - INFO - Episode 4600/50000 - Avg Reward: 3027.17 - Avg Max Tile: 136.00 - Epsilon: 0.100 - Beta: 0.428
2025-03-04 21:57:58,229 - INFO - Episode 4700/50000 - Avg Reward: 2803.33 - Avg Max Tile: 120.32 - Epsilon: 0.100 - Beta: 0.428
2025-03-04 22:00:55,353 - INFO - Episode 4800/50000 - Avg Reward: 2897.29 - Avg Max Tile: 124.16 - Epsilon: 0.100 - Beta: 0.429
2025-03-04 22:03:48,096 - INFO - Episode 4900/50000 - Avg Reward: 2842.89 - Avg Max Tile: 120.32 - Epsilon: 0.100 - Beta: 0.429
2025-03-04 22:06:28,678 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_5000.pt
2025-03-04 22:06:28,679 - INFO - Episode 5000/50000 - Avg Reward: 2633.29 - Avg Max Tile: 111.68 - Epsilon: 0.100 - Beta: 0.430
2025-03-04 22:09:09,883 - INFO - Episode 5100/50000 - Avg Reward: 2647.92 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.431
2025-03-04 22:11:53,387 - INFO - Episode 5200/50000 - Avg Reward: 2668.75 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.431
2025-03-04 22:14:47,675 - INFO - Episode 5300/50000 - Avg Reward: 2843.51 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.432
2025-03-04 22:17:45,859 - INFO - Episode 5400/50000 - Avg Reward: 2979.24 - Avg Max Tile: 132.16 - Epsilon: 0.100 - Beta: 0.432
2025-03-04 22:20:32,667 - INFO - Episode 5500/50000 - Avg Reward: 2795.07 - Avg Max Tile: 120.00 - Epsilon: 0.100 - Beta: 0.433
2025-03-04 22:23:29,077 - INFO - Episode 5600/50000 - Avg Reward: 2913.10 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.434
2025-03-04 22:26:18,603 - INFO - Episode 5700/50000 - Avg Reward: 2807.05 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.434
2025-03-04 22:26:41,234 - INFO - New best score: 8833.593736749888 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-04 22:29:13,108 - INFO - Episode 5800/50000 - Avg Reward: 2846.94 - Avg Max Tile: 122.56 - Epsilon: 0.100 - Beta: 0.435
2025-03-04 22:32:07,666 - INFO - Episode 5900/50000 - Avg Reward: 2881.43 - Avg Max Tile: 126.08 - Epsilon: 0.100 - Beta: 0.435
2025-03-04 22:35:05,070 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-04 22:35:05,071 - INFO - Episode 6000/50000 - Avg Reward: 2956.17 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.436
2025-03-04 22:37:42,324 - INFO - Episode 6100/50000 - Avg Reward: 2534.33 - Avg Max Tile: 105.44 - Epsilon: 0.100 - Beta: 0.437
2025-03-04 22:40:21,126 - INFO - Episode 6200/50000 - Avg Reward: 2568.95 - Avg Max Tile: 107.68 - Epsilon: 0.100 - Beta: 0.437
2025-03-04 22:43:09,166 - INFO - Episode 6300/50000 - Avg Reward: 2734.43 - Avg Max Tile: 117.12 - Epsilon: 0.100 - Beta: 0.438
2025-03-04 22:46:06,296 - INFO - Episode 6400/50000 - Avg Reward: 2916.11 - Avg Max Tile: 125.76 - Epsilon: 0.100 - Beta: 0.438
2025-03-04 22:48:48,382 - INFO - Episode 6500/50000 - Avg Reward: 2644.57 - Avg Max Tile: 112.32 - Epsilon: 0.100 - Beta: 0.439
2025-03-04 22:51:36,558 - INFO - Episode 6600/50000 - Avg Reward: 2765.87 - Avg Max Tile: 117.12 - Epsilon: 0.100 - Beta: 0.440
2025-03-04 22:54:25,755 - INFO - Episode 6700/50000 - Avg Reward: 2778.09 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.440
2025-03-04 22:57:10,955 - INFO - Episode 6800/50000 - Avg Reward: 2740.60 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.441
2025-03-04 23:00:09,527 - INFO - Episode 6900/50000 - Avg Reward: 3025.95 - Avg Max Tile: 135.36 - Epsilon: 0.100 - Beta: 0.441
2025-03-04 23:02:51,455 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_7000.pt
2025-03-04 23:02:51,456 - INFO - Episode 7000/50000 - Avg Reward: 2613.40 - Avg Max Tile: 109.28 - Epsilon: 0.100 - Beta: 0.442
2025-03-04 23:05:37,924 - INFO - Episode 7100/50000 - Avg Reward: 2787.24 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.443
2025-03-04 23:08:32,833 - INFO - Episode 7200/50000 - Avg Reward: 2867.24 - Avg Max Tile: 124.64 - Epsilon: 0.100 - Beta: 0.443
2025-03-04 23:11:09,237 - INFO - Episode 7300/50000 - Avg Reward: 2513.98 - Avg Max Tile: 103.52 - Epsilon: 0.100 - Beta: 0.444
2025-03-04 23:14:05,588 - INFO - Episode 7400/50000 - Avg Reward: 2916.99 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.444
2025-03-04 23:16:55,046 - INFO - Episode 7500/50000 - Avg Reward: 2788.96 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.445
2025-03-04 23:19:56,811 - INFO - Episode 7600/50000 - Avg Reward: 2984.30 - Avg Max Tile: 128.96 - Epsilon: 0.100 - Beta: 0.446
2025-03-04 23:23:00,596 - INFO - Episode 7700/50000 - Avg Reward: 2993.92 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.446
2025-03-04 23:25:55,670 - INFO - Episode 7800/50000 - Avg Reward: 2922.06 - Avg Max Tile: 129.92 - Epsilon: 0.100 - Beta: 0.447
2025-03-04 23:28:50,180 - INFO - Episode 7900/50000 - Avg Reward: 2918.93 - Avg Max Tile: 127.36 - Epsilon: 0.100 - Beta: 0.447
2025-03-04 23:29:05,212 - INFO - New best score: 8990.724985745552 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:18:49,477 - INFO - Starting training with device: cuda
2025-03-05 00:18:49,477 - INFO - Model parameters: 3394954
2025-03-05 00:18:49,477 - INFO - New highest tile achieved: 2 (Episode 1)
2025-03-05 00:18:49,477 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-05 00:18:49,493 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-05 00:18:49,520 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-05 00:18:49,588 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-05 00:18:49,632 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-05 00:18:49,800 - INFO - New highest tile achieved: 128 (Episode 1)
2025-03-05 00:18:50,180 - INFO - New best score: 2970.731244033574 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:18:51,720 - INFO - New best score: 3509.028116792443 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:19:20,607 - INFO - New highest tile achieved: 256 (Episode 26)
2025-03-05 00:19:21,250 - INFO - New best score: 4835.187491637467 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:19:57,917 - INFO - New best score: 4909.731243944167 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:20:48,504 - INFO - New best score: 6226.09373958707 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:21:20,688 - INFO - Episode 100/50000 - Avg Reward: 2694.14 - Avg Max Tile: 112.32 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 00:24:01,312 - INFO - Episode 200/50000 - Avg Reward: 2791.80 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 00:25:15,467 - INFO - New highest tile achieved: 512 (Episode 244)
2025-03-05 00:25:15,658 - INFO - New best score: 8041.97499014735 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 00:26:42,379 - INFO - Episode 300/50000 - Avg Reward: 2811.57 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 00:29:22,965 - INFO - Episode 400/50000 - Avg Reward: 2770.25 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 00:31:54,252 - INFO - Episode 500/50000 - Avg Reward: 2528.76 - Avg Max Tile: 107.52 - Epsilon: 0.100 - Beta: 0.403
2025-03-05 00:34:39,740 - INFO - Episode 600/50000 - Avg Reward: 2785.58 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.404
2025-03-05 00:37:31,800 - INFO - Episode 700/50000 - Avg Reward: 2884.78 - Avg Max Tile: 124.96 - Epsilon: 0.100 - Beta: 0.404
2025-03-05 00:40:11,495 - INFO - Episode 800/50000 - Avg Reward: 2628.61 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.405
2025-03-05 00:42:46,281 - INFO - Episode 900/50000 - Avg Reward: 2579.21 - Avg Max Tile: 111.20 - Epsilon: 0.100 - Beta: 0.405
2025-03-05 00:45:33,215 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-05 00:45:33,215 - INFO - Episode 1000/50000 - Avg Reward: 2820.63 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.406
2025-03-05 00:48:22,111 - INFO - Episode 1100/50000 - Avg Reward: 2807.89 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.407
2025-03-05 00:51:21,079 - INFO - Episode 1200/50000 - Avg Reward: 3040.88 - Avg Max Tile: 132.48 - Epsilon: 0.100 - Beta: 0.407
2025-03-05 00:53:59,489 - INFO - Episode 1300/50000 - Avg Reward: 2720.38 - Avg Max Tile: 121.44 - Epsilon: 0.100 - Beta: 0.408
2025-03-05 00:56:51,290 - INFO - Episode 1400/50000 - Avg Reward: 2886.43 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.408
2025-03-05 00:59:26,256 - INFO - Episode 1500/50000 - Avg Reward: 2556.60 - Avg Max Tile: 109.12 - Epsilon: 0.100 - Beta: 0.409
2025-03-05 01:02:18,966 - INFO - Episode 1600/50000 - Avg Reward: 2886.16 - Avg Max Tile: 123.68 - Epsilon: 0.100 - Beta: 0.410
2025-03-05 01:05:05,176 - INFO - Episode 1700/50000 - Avg Reward: 2778.67 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.410
2025-03-05 01:07:53,628 - INFO - Episode 1800/50000 - Avg Reward: 2891.89 - Avg Max Tile: 130.40 - Epsilon: 0.100 - Beta: 0.411
2025-03-05 01:10:35,706 - INFO - Episode 1900/50000 - Avg Reward: 2693.82 - Avg Max Tile: 113.28 - Epsilon: 0.100 - Beta: 0.411
2025-03-05 01:13:27,629 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_2000.pt
2025-03-05 01:13:27,629 - INFO - Episode 2000/50000 - Avg Reward: 2908.77 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.412
2025-03-05 01:14:17,299 - INFO - New best score: 8202.134363359217 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 01:15:02,780 - INFO - New best score: 8497.553115448356 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 01:16:24,650 - INFO - Episode 2100/50000 - Avg Reward: 2997.32 - Avg Max Tile: 131.20 - Epsilon: 0.100 - Beta: 0.413
2025-03-05 01:19:11,290 - INFO - Episode 2200/50000 - Avg Reward: 2804.07 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.413
2025-03-05 01:21:57,581 - INFO - Episode 2300/50000 - Avg Reward: 2769.87 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.414
2025-03-05 01:24:34,479 - INFO - New best score: 8534.337485402822 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 01:24:47,661 - INFO - Episode 2400/50000 - Avg Reward: 2870.45 - Avg Max Tile: 125.76 - Epsilon: 0.100 - Beta: 0.414
2025-03-05 01:26:44,076 - INFO - New best score: 8590.412485092878 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 01:27:42,694 - INFO - Episode 2500/50000 - Avg Reward: 2949.45 - Avg Max Tile: 131.04 - Epsilon: 0.100 - Beta: 0.415
2025-03-05 01:30:30,558 - INFO - Episode 2600/50000 - Avg Reward: 2847.42 - Avg Max Tile: 124.80 - Epsilon: 0.100 - Beta: 0.416
2025-03-05 01:33:21,251 - INFO - Episode 2700/50000 - Avg Reward: 2869.33 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.416
2025-03-05 01:36:00,491 - INFO - Episode 2800/50000 - Avg Reward: 2617.92 - Avg Max Tile: 112.00 - Epsilon: 0.100 - Beta: 0.417
2025-03-05 01:38:45,462 - INFO - Episode 2900/50000 - Avg Reward: 2804.35 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.417
2025-03-05 01:41:34,949 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_3000.pt
2025-03-05 01:41:34,949 - INFO - Episode 3000/50000 - Avg Reward: 2881.27 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.418
2025-03-05 01:44:18,263 - INFO - Episode 3100/50000 - Avg Reward: 2700.39 - Avg Max Tile: 113.60 - Epsilon: 0.100 - Beta: 0.419
2025-03-05 01:47:12,502 - INFO - Episode 3200/50000 - Avg Reward: 2930.96 - Avg Max Tile: 126.56 - Epsilon: 0.100 - Beta: 0.419
2025-03-05 01:49:52,614 - INFO - Episode 3300/50000 - Avg Reward: 2700.32 - Avg Max Tile: 116.48 - Epsilon: 0.100 - Beta: 0.420
2025-03-05 01:52:50,554 - INFO - Episode 3400/50000 - Avg Reward: 3014.82 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.420
2025-03-05 01:55:35,855 - INFO - Episode 3500/50000 - Avg Reward: 2791.39 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.421
2025-03-05 01:58:27,943 - INFO - Episode 3600/50000 - Avg Reward: 2906.27 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.422
2025-03-05 02:01:09,948 - INFO - Episode 3700/50000 - Avg Reward: 2715.67 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.422
2025-03-05 02:03:54,731 - INFO - Episode 3800/50000 - Avg Reward: 2744.17 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.423
2025-03-05 02:06:50,319 - INFO - Episode 3900/50000 - Avg Reward: 2947.04 - Avg Max Tile: 128.64 - Epsilon: 0.100 - Beta: 0.423
2025-03-05 02:09:33,999 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_4000.pt
2025-03-05 02:09:33,999 - INFO - Episode 4000/50000 - Avg Reward: 2712.43 - Avg Max Tile: 113.60 - Epsilon: 0.100 - Beta: 0.424
2025-03-05 02:12:18,406 - INFO - Episode 4100/50000 - Avg Reward: 2737.95 - Avg Max Tile: 116.16 - Epsilon: 0.100 - Beta: 0.425
2025-03-05 02:15:05,918 - INFO - Episode 4200/50000 - Avg Reward: 2833.75 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.425
2025-03-05 02:17:56,094 - INFO - Episode 4300/50000 - Avg Reward: 2824.37 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.426
2025-03-05 02:20:45,580 - INFO - Episode 4400/50000 - Avg Reward: 2847.78 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.426
2025-03-05 02:23:25,194 - INFO - Episode 4500/50000 - Avg Reward: 2615.45 - Avg Max Tile: 106.56 - Epsilon: 0.100 - Beta: 0.427
2025-03-05 02:26:22,026 - INFO - Episode 4600/50000 - Avg Reward: 3027.17 - Avg Max Tile: 136.00 - Epsilon: 0.100 - Beta: 0.428
2025-03-05 02:29:07,881 - INFO - Episode 4700/50000 - Avg Reward: 2803.33 - Avg Max Tile: 120.32 - Epsilon: 0.100 - Beta: 0.428
2025-03-05 02:32:00,908 - INFO - Episode 4800/50000 - Avg Reward: 2897.29 - Avg Max Tile: 124.16 - Epsilon: 0.100 - Beta: 0.429
2025-03-05 02:34:51,390 - INFO - Episode 4900/50000 - Avg Reward: 2842.89 - Avg Max Tile: 120.32 - Epsilon: 0.100 - Beta: 0.429
2025-03-05 02:37:28,543 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_5000.pt
2025-03-05 02:37:28,543 - INFO - Episode 5000/50000 - Avg Reward: 2633.29 - Avg Max Tile: 111.68 - Epsilon: 0.100 - Beta: 0.430
2025-03-05 02:40:07,109 - INFO - Episode 5100/50000 - Avg Reward: 2647.92 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.431
2025-03-05 02:42:47,850 - INFO - Episode 5200/50000 - Avg Reward: 2668.75 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.431
2025-03-05 02:45:39,011 - INFO - Episode 5300/50000 - Avg Reward: 2843.51 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.432
2025-03-05 02:48:33,403 - INFO - Episode 5400/50000 - Avg Reward: 2979.24 - Avg Max Tile: 132.16 - Epsilon: 0.100 - Beta: 0.432
2025-03-05 02:51:17,799 - INFO - Episode 5500/50000 - Avg Reward: 2795.07 - Avg Max Tile: 120.00 - Epsilon: 0.100 - Beta: 0.433
2025-03-05 02:54:10,630 - INFO - Episode 5600/50000 - Avg Reward: 2913.10 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.434
2025-03-05 02:56:57,102 - INFO - Episode 5700/50000 - Avg Reward: 2807.05 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.434
2025-03-05 02:57:18,835 - INFO - New best score: 8833.593736749888 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 02:59:47,980 - INFO - Episode 5800/50000 - Avg Reward: 2846.94 - Avg Max Tile: 122.56 - Epsilon: 0.100 - Beta: 0.435
2025-03-05 03:02:39,704 - INFO - Episode 5900/50000 - Avg Reward: 2881.43 - Avg Max Tile: 126.08 - Epsilon: 0.100 - Beta: 0.435
2025-03-05 03:05:34,025 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-05 03:05:34,025 - INFO - Episode 6000/50000 - Avg Reward: 2956.17 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.436
2025-03-05 03:08:08,042 - INFO - Episode 6100/50000 - Avg Reward: 2534.33 - Avg Max Tile: 105.44 - Epsilon: 0.100 - Beta: 0.437
2025-03-05 03:10:44,354 - INFO - Episode 6200/50000 - Avg Reward: 2568.95 - Avg Max Tile: 107.68 - Epsilon: 0.100 - Beta: 0.437
2025-03-05 03:13:29,134 - INFO - Episode 6300/50000 - Avg Reward: 2734.43 - Avg Max Tile: 117.12 - Epsilon: 0.100 - Beta: 0.438
2025-03-05 03:16:21,562 - INFO - Episode 6400/50000 - Avg Reward: 2916.11 - Avg Max Tile: 125.76 - Epsilon: 0.100 - Beta: 0.438
2025-03-05 03:19:01,448 - INFO - Episode 6500/50000 - Avg Reward: 2644.57 - Avg Max Tile: 112.32 - Epsilon: 0.100 - Beta: 0.439
2025-03-05 03:21:47,192 - INFO - Episode 6600/50000 - Avg Reward: 2765.87 - Avg Max Tile: 117.12 - Epsilon: 0.100 - Beta: 0.440
2025-03-05 03:24:33,293 - INFO - Episode 6700/50000 - Avg Reward: 2778.09 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.440
2025-03-05 03:27:15,927 - INFO - Episode 6800/50000 - Avg Reward: 2740.60 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.441
2025-03-05 03:30:11,543 - INFO - Episode 6900/50000 - Avg Reward: 3025.95 - Avg Max Tile: 135.36 - Epsilon: 0.100 - Beta: 0.441
2025-03-05 03:32:50,509 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_7000.pt
2025-03-05 03:32:50,509 - INFO - Episode 7000/50000 - Avg Reward: 2613.40 - Avg Max Tile: 109.28 - Epsilon: 0.100 - Beta: 0.442
2025-03-05 03:35:34,648 - INFO - Episode 7100/50000 - Avg Reward: 2787.24 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.443
2025-03-05 03:38:25,106 - INFO - Episode 7200/50000 - Avg Reward: 2867.24 - Avg Max Tile: 124.64 - Epsilon: 0.100 - Beta: 0.443
2025-03-05 03:40:58,713 - INFO - Episode 7300/50000 - Avg Reward: 2513.98 - Avg Max Tile: 103.52 - Epsilon: 0.100 - Beta: 0.444
2025-03-05 03:43:51,475 - INFO - Episode 7400/50000 - Avg Reward: 2916.99 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.444
2025-03-05 03:46:37,005 - INFO - Episode 7500/50000 - Avg Reward: 2788.96 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.445
2025-03-05 03:49:34,164 - INFO - Episode 7600/50000 - Avg Reward: 2984.30 - Avg Max Tile: 128.96 - Epsilon: 0.100 - Beta: 0.446
2025-03-05 03:52:33,458 - INFO - Episode 7700/50000 - Avg Reward: 2993.92 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.446
2025-03-05 03:55:25,885 - INFO - Episode 7800/50000 - Avg Reward: 2922.06 - Avg Max Tile: 129.92 - Epsilon: 0.100 - Beta: 0.447
2025-03-05 03:58:17,592 - INFO - Episode 7900/50000 - Avg Reward: 2918.93 - Avg Max Tile: 127.36 - Epsilon: 0.100 - Beta: 0.447
2025-03-05 03:58:32,088 - INFO - New best score: 8990.724985745552 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 04:01:06,630 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_8000.pt
2025-03-05 04:01:06,630 - INFO - Episode 8000/50000 - Avg Reward: 2826.55 - Avg Max Tile: 120.80 - Epsilon: 0.100 - Beta: 0.448
2025-03-05 04:01:12,324 - INFO - New best score: 10505.66873091459 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 04:03:52,145 - INFO - Episode 8100/50000 - Avg Reward: 2806.99 - Avg Max Tile: 124.16 - Epsilon: 0.100 - Beta: 0.449
2025-03-05 04:06:39,645 - INFO - Episode 8200/50000 - Avg Reward: 2855.11 - Avg Max Tile: 126.08 - Epsilon: 0.100 - Beta: 0.449
2025-03-05 04:09:23,454 - INFO - Episode 8300/50000 - Avg Reward: 2717.66 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.450
2025-03-05 04:12:15,686 - INFO - Episode 8400/50000 - Avg Reward: 2860.25 - Avg Max Tile: 123.20 - Epsilon: 0.100 - Beta: 0.450
2025-03-05 04:15:02,512 - INFO - Episode 8500/50000 - Avg Reward: 2769.40 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.451
2025-03-05 04:17:49,604 - INFO - Episode 8600/50000 - Avg Reward: 2765.75 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.452
2025-03-05 04:20:37,654 - INFO - Episode 8700/50000 - Avg Reward: 2762.64 - Avg Max Tile: 115.84 - Epsilon: 0.100 - Beta: 0.452
2025-03-05 04:23:23,436 - INFO - Episode 8800/50000 - Avg Reward: 2734.97 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.453
2025-03-05 04:26:09,053 - INFO - Episode 8900/50000 - Avg Reward: 2746.20 - Avg Max Tile: 117.92 - Epsilon: 0.100 - Beta: 0.453
2025-03-05 04:29:05,276 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_9000.pt
2025-03-05 04:29:05,276 - INFO - Episode 9000/50000 - Avg Reward: 2931.41 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.454
2025-03-05 04:31:56,326 - INFO - Episode 9100/50000 - Avg Reward: 2816.08 - Avg Max Tile: 120.64 - Epsilon: 0.100 - Beta: 0.455
2025-03-05 04:34:49,741 - INFO - Episode 9200/50000 - Avg Reward: 2920.16 - Avg Max Tile: 128.00 - Epsilon: 0.100 - Beta: 0.455
2025-03-05 04:37:36,886 - INFO - Episode 9300/50000 - Avg Reward: 2808.29 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.456
2025-03-05 04:40:21,781 - INFO - Episode 9400/50000 - Avg Reward: 2750.82 - Avg Max Tile: 118.24 - Epsilon: 0.100 - Beta: 0.456
2025-03-05 04:43:20,080 - INFO - Episode 9500/50000 - Avg Reward: 3020.62 - Avg Max Tile: 131.52 - Epsilon: 0.100 - Beta: 0.457
2025-03-05 04:46:06,575 - INFO - Episode 9600/50000 - Avg Reward: 2792.66 - Avg Max Tile: 121.60 - Epsilon: 0.100 - Beta: 0.458
2025-03-05 04:48:57,722 - INFO - Episode 9700/50000 - Avg Reward: 2847.84 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.458
2025-03-05 04:51:55,666 - INFO - Episode 9800/50000 - Avg Reward: 3046.37 - Avg Max Tile: 139.20 - Epsilon: 0.100 - Beta: 0.459
2025-03-05 04:54:39,050 - INFO - Episode 9900/50000 - Avg Reward: 2709.13 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.459
2025-03-05 04:57:29,625 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_10000.pt
2025-03-05 04:57:29,625 - INFO - Episode 10000/50000 - Avg Reward: 2860.39 - Avg Max Tile: 123.20 - Epsilon: 0.100 - Beta: 0.460
2025-03-05 05:00:15,417 - INFO - Episode 10100/50000 - Avg Reward: 2774.44 - Avg Max Tile: 119.04 - Epsilon: 0.100 - Beta: 0.461
2025-03-05 05:03:02,851 - INFO - Episode 10200/50000 - Avg Reward: 2822.47 - Avg Max Tile: 124.80 - Epsilon: 0.100 - Beta: 0.461
2025-03-05 05:05:40,233 - INFO - Episode 10300/50000 - Avg Reward: 2594.70 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.462
2025-03-05 05:08:46,125 - INFO - Episode 10400/50000 - Avg Reward: 3192.06 - Avg Max Tile: 143.36 - Epsilon: 0.100 - Beta: 0.462
2025-03-05 05:11:31,767 - INFO - Episode 10500/50000 - Avg Reward: 2782.68 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.463
2025-03-05 05:14:21,535 - INFO - Episode 10600/50000 - Avg Reward: 2809.58 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.464
2025-03-05 05:17:10,792 - INFO - Episode 10700/50000 - Avg Reward: 2866.81 - Avg Max Tile: 125.12 - Epsilon: 0.100 - Beta: 0.464
2025-03-05 05:19:58,296 - INFO - Episode 10800/50000 - Avg Reward: 2822.19 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.465
2025-03-05 05:22:46,228 - INFO - Episode 10900/50000 - Avg Reward: 2840.89 - Avg Max Tile: 125.28 - Epsilon: 0.100 - Beta: 0.465
2025-03-05 05:25:36,224 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_11000.pt
2025-03-05 05:25:36,224 - INFO - Episode 11000/50000 - Avg Reward: 2855.93 - Avg Max Tile: 121.76 - Epsilon: 0.100 - Beta: 0.466
2025-03-05 05:28:18,402 - INFO - Episode 11100/50000 - Avg Reward: 2729.79 - Avg Max Tile: 119.36 - Epsilon: 0.100 - Beta: 0.467
2025-03-05 05:31:00,030 - INFO - Episode 11200/50000 - Avg Reward: 2727.92 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.467
2025-03-05 05:33:41,323 - INFO - Episode 11300/50000 - Avg Reward: 2687.13 - Avg Max Tile: 111.84 - Epsilon: 0.100 - Beta: 0.468
2025-03-05 05:36:37,141 - INFO - Episode 11400/50000 - Avg Reward: 2979.46 - Avg Max Tile: 128.32 - Epsilon: 0.100 - Beta: 0.468
2025-03-05 05:39:29,477 - INFO - Episode 11500/50000 - Avg Reward: 2889.47 - Avg Max Tile: 125.12 - Epsilon: 0.100 - Beta: 0.469
2025-03-05 05:42:05,537 - INFO - Episode 11600/50000 - Avg Reward: 2576.51 - Avg Max Tile: 109.44 - Epsilon: 0.100 - Beta: 0.470
2025-03-05 05:44:56,639 - INFO - Episode 11700/50000 - Avg Reward: 2945.22 - Avg Max Tile: 133.28 - Epsilon: 0.100 - Beta: 0.470
2025-03-05 05:47:39,860 - INFO - Episode 11800/50000 - Avg Reward: 2732.82 - Avg Max Tile: 116.80 - Epsilon: 0.100 - Beta: 0.471
2025-03-05 05:50:24,109 - INFO - Episode 11900/50000 - Avg Reward: 2751.64 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.471
2025-03-05 05:53:08,893 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_12000.pt
2025-03-05 05:53:08,893 - INFO - Episode 12000/50000 - Avg Reward: 2715.93 - Avg Max Tile: 114.72 - Epsilon: 0.100 - Beta: 0.472
2025-03-05 05:55:46,921 - INFO - Episode 12100/50000 - Avg Reward: 2582.30 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.473
2025-03-05 05:58:34,374 - INFO - Episode 12200/50000 - Avg Reward: 2792.18 - Avg Max Tile: 121.60 - Epsilon: 0.100 - Beta: 0.473
2025-03-05 06:01:20,543 - INFO - Episode 12300/50000 - Avg Reward: 2745.01 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.474
2025-03-05 06:04:01,092 - INFO - Episode 12400/50000 - Avg Reward: 2701.71 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.474
2025-03-05 06:06:56,208 - INFO - Episode 12500/50000 - Avg Reward: 2965.77 - Avg Max Tile: 128.96 - Epsilon: 0.100 - Beta: 0.475
2025-03-05 06:09:39,996 - INFO - Episode 12600/50000 - Avg Reward: 2768.40 - Avg Max Tile: 121.52 - Epsilon: 0.100 - Beta: 0.476
2025-03-05 06:12:25,447 - INFO - Episode 12700/50000 - Avg Reward: 2744.96 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.476
2025-03-05 06:15:17,108 - INFO - Episode 12800/50000 - Avg Reward: 2872.99 - Avg Max Tile: 122.40 - Epsilon: 0.100 - Beta: 0.477
2025-03-05 06:18:09,325 - INFO - Episode 12900/50000 - Avg Reward: 2932.45 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.477
2025-03-05 06:20:53,418 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 06:20:53,418 - INFO - Episode 13000/50000 - Avg Reward: 2738.15 - Avg Max Tile: 116.00 - Epsilon: 0.100 - Beta: 0.478
2025-03-05 06:23:34,752 - INFO - Episode 13100/50000 - Avg Reward: 2674.18 - Avg Max Tile: 113.92 - Epsilon: 0.100 - Beta: 0.479
2025-03-05 06:26:26,154 - INFO - Episode 13200/50000 - Avg Reward: 2909.05 - Avg Max Tile: 129.28 - Epsilon: 0.100 - Beta: 0.479
2025-03-05 06:29:05,986 - INFO - Episode 13300/50000 - Avg Reward: 2662.09 - Avg Max Tile: 115.04 - Epsilon: 0.100 - Beta: 0.480
2025-03-05 06:31:52,021 - INFO - Episode 13400/50000 - Avg Reward: 2799.43 - Avg Max Tile: 120.64 - Epsilon: 0.100 - Beta: 0.480
2025-03-05 06:34:40,931 - INFO - Episode 13500/50000 - Avg Reward: 2837.31 - Avg Max Tile: 122.56 - Epsilon: 0.100 - Beta: 0.481
2025-03-05 06:37:25,123 - INFO - Episode 13600/50000 - Avg Reward: 2777.54 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.482
2025-03-05 06:40:22,750 - INFO - Episode 13700/50000 - Avg Reward: 2968.18 - Avg Max Tile: 129.28 - Epsilon: 0.100 - Beta: 0.482
2025-03-05 07:52:15,569 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 07:52:15,648 - ERROR - Error loading checkpoint: 'optimizer_state_dict'
2025-03-05 07:52:32,611 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 07:52:32,679 - ERROR - Error loading checkpoint: 'optimizer_state_dict'
2025-03-05 07:53:33,735 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 07:53:33,811 - INFO - Resuming from episode 13001
2025-03-05 07:53:33,811 - INFO - Starting training with device: cuda
2025-03-05 07:53:33,811 - INFO - Model parameters: 3394954
2025-03-05 07:53:34,004 - INFO - New highest tile achieved: 2 (Episode 13002)
2025-03-05 07:53:34,004 - INFO - New highest tile achieved: 4 (Episode 13002)
2025-03-05 07:53:34,026 - INFO - New highest tile achieved: 8 (Episode 13002)
2025-03-05 07:53:34,095 - INFO - New highest tile achieved: 16 (Episode 13002)
2025-03-05 07:53:34,158 - INFO - New highest tile achieved: 32 (Episode 13002)
2025-03-05 07:53:34,255 - INFO - New highest tile achieved: 64 (Episode 13002)
2025-03-05 07:53:34,587 - INFO - New best score: 1781.7749973118307 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:53:35,134 - INFO - New highest tile achieved: 128 (Episode 13003)
2025-03-05 07:53:35,486 - INFO - New best score: 3087.887496685981 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:53:36,535 - INFO - New best score: 3689.687493884564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:53:55,258 - INFO - New highest tile achieved: 256 (Episode 13016)
2025-03-05 07:53:55,945 - INFO - New best score: 5571.193738847972 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:54:02,710 - INFO - New best score: 5673.165615934133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:55:42,757 - INFO - New best score: 6226.09373958707 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:55:58,024 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 07:55:58,171 - INFO - Resuming from episode 1
2025-03-05 07:55:58,171 - INFO - Previous best score: 0
2025-03-05 07:55:58,171 - INFO - Previous highest tile: 0
2025-03-05 07:55:58,171 - INFO - Starting training with device: cuda
2025-03-05 07:55:58,172 - INFO - Model parameters: 3394954
2025-03-05 07:55:58,371 - INFO - New highest tile achieved: 2 (Episode 2)
2025-03-05 07:55:58,371 - INFO - New highest tile achieved: 4 (Episode 2)
2025-03-05 07:55:58,392 - INFO - New highest tile achieved: 8 (Episode 2)
2025-03-05 07:55:58,463 - INFO - New highest tile achieved: 16 (Episode 2)
2025-03-05 07:55:58,525 - INFO - New highest tile achieved: 32 (Episode 2)
2025-03-05 07:55:58,625 - INFO - New highest tile achieved: 64 (Episode 2)
2025-03-05 07:55:58,941 - INFO - New best score: 1781.7749973118307 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:55:59,504 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-05 07:55:59,847 - INFO - New best score: 3087.887496685981 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:56:00,939 - INFO - New best score: 3689.687493884564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:56:20,680 - INFO - New highest tile achieved: 256 (Episode 16)
2025-03-05 07:56:21,355 - INFO - New best score: 5571.193738847972 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:56:28,576 - INFO - New best score: 5673.165615934133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 07:56:55,826 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 07:56:55,900 - ERROR - Error loading checkpoint: 'optimizer_state_dict'
2025-03-05 07:59:50,232 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 07:59:50,287 - ERROR - Error loading checkpoint: 'optimizer_state_dict'
2025-03-05 08:01:12,180 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 08:01:12,238 - WARNING - Replay buffer state not found in checkpoint, starting with empty buffer
2025-03-05 08:01:12,238 - WARNING - GradScaler state not found in checkpoint, using default initialization
2025-03-05 08:01:12,238 - INFO - Resuming from episode 1
2025-03-05 08:01:12,238 - INFO - Current epsilon: 0.100
2025-03-05 08:01:12,238 - INFO - Starting training with device: cuda
2025-03-05 08:01:12,238 - INFO - Model parameters: 3394954
2025-03-05 08:01:12,437 - INFO - New highest tile achieved: 2 (Episode 2)
2025-03-05 08:01:12,437 - INFO - New highest tile achieved: 4 (Episode 2)
2025-03-05 08:01:12,458 - INFO - New highest tile achieved: 8 (Episode 2)
2025-03-05 08:01:12,528 - INFO - New highest tile achieved: 16 (Episode 2)
2025-03-05 08:01:12,592 - INFO - New highest tile achieved: 32 (Episode 2)
2025-03-05 08:01:12,690 - INFO - New highest tile achieved: 64 (Episode 2)
2025-03-05 08:01:12,992 - INFO - New best score: 1781.7749973118307 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:01:13,532 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-05 08:01:13,877 - INFO - New best score: 3087.887496685981 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:01:14,913 - INFO - New best score: 3689.687493884564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:01:33,219 - INFO - New highest tile achieved: 256 (Episode 16)
2025-03-05 08:01:33,919 - INFO - New best score: 5571.193738847972 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:01:40,997 - INFO - New best score: 5673.165615934133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:05:54,174 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 08:05:54,289 - WARNING - Replay buffer state not found in checkpoint, starting with empty buffer
2025-03-05 08:05:54,289 - WARNING - GradScaler state not found in checkpoint, using default initialization
2025-03-05 08:05:54,289 - INFO - Resuming from episode 1
2025-03-05 08:05:54,289 - INFO - Current epsilon: 0.100
2025-03-05 08:05:54,295 - INFO - Starting training with device: cuda
2025-03-05 08:05:54,295 - INFO - Model parameters: 3394954
2025-03-05 08:05:55,189 - INFO - New highest tile achieved: 2 (Episode 2)
2025-03-05 08:05:55,193 - INFO - New highest tile achieved: 4 (Episode 2)
2025-03-05 08:05:55,213 - INFO - New highest tile achieved: 8 (Episode 2)
2025-03-05 08:05:55,305 - INFO - New highest tile achieved: 16 (Episode 2)
2025-03-05 08:05:55,401 - INFO - New highest tile achieved: 32 (Episode 2)
2025-03-05 08:05:55,532 - INFO - New highest tile achieved: 64 (Episode 2)
2025-03-05 08:05:56,064 - INFO - New best score: 1781.7749973118307 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:05:56,735 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-05 08:05:57,136 - INFO - New best score: 3087.887496685981 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:05:58,334 - INFO - New best score: 3689.687493884564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:06:18,183 - INFO - New highest tile achieved: 256 (Episode 16)
2025-03-05 08:06:18,836 - INFO - New best score: 5571.193738847972 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:06:25,557 - INFO - New best score: 5673.165615934133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:07:58,726 - INFO - New best score: 6226.09373958707 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:08:30,474 - INFO - Episode 100/50000 - Avg Reward: 2768.14 - Avg Max Tile: 113.45 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 08:11:10,825 - INFO - Episode 200/50000 - Avg Reward: 2791.80 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 08:12:24,263 - INFO - New highest tile achieved: 512 (Episode 244)
2025-03-05 08:12:25,325 - INFO - New best score: 8041.97499014735 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 08:13:51,970 - INFO - Episode 300/50000 - Avg Reward: 2811.57 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 08:16:32,847 - INFO - Episode 400/50000 - Avg Reward: 2770.25 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 08:19:02,058 - INFO - Episode 500/50000 - Avg Reward: 2528.76 - Avg Max Tile: 107.52 - Epsilon: 0.100 - Beta: 0.403
2025-03-05 08:21:49,345 - INFO - Episode 600/50000 - Avg Reward: 2785.58 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.404
2025-03-05 08:24:39,651 - INFO - Episode 700/50000 - Avg Reward: 2884.78 - Avg Max Tile: 124.96 - Epsilon: 0.100 - Beta: 0.404
2025-03-05 10:55:04,913 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 10:55:04,988 - WARNING - Replay buffer state not found in checkpoint, starting with empty buffer
2025-03-05 10:55:04,988 - WARNING - GradScaler state not found in checkpoint, using default initialization
2025-03-05 10:55:04,989 - INFO - Resuming from episode 1
2025-03-05 10:55:04,989 - INFO - Current epsilon: 0.100
2025-03-05 10:55:04,989 - INFO - Starting training with device: cuda
2025-03-05 10:55:04,990 - INFO - Model parameters: 3394954
2025-03-05 10:55:05,206 - INFO - New highest tile achieved: 2 (Episode 2)
2025-03-05 10:55:05,209 - INFO - New highest tile achieved: 4 (Episode 2)
2025-03-05 10:55:05,225 - INFO - New highest tile achieved: 8 (Episode 2)
2025-03-05 10:55:05,300 - INFO - New highest tile achieved: 16 (Episode 2)
2025-03-05 10:55:05,366 - INFO - New highest tile achieved: 32 (Episode 2)
2025-03-05 10:55:05,498 - INFO - New highest tile achieved: 64 (Episode 2)
2025-03-05 10:55:05,819 - INFO - New best score: 1781.7749973118307 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 10:55:06,407 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-05 10:55:06,808 - INFO - New best score: 3087.887496685981 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 10:55:08,035 - INFO - New best score: 3689.687493884564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 10:55:27,143 - INFO - New highest tile achieved: 256 (Episode 16)
2025-03-05 10:55:27,932 - INFO - New best score: 5571.193738847972 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 10:55:35,045 - INFO - New best score: 5673.165615934133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 10:57:17,927 - INFO - New best score: 6226.09373958707 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 10:57:55,349 - INFO - Episode 100/50000 - Avg Reward: 2768.14 - Avg Max Tile: 113.45 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 11:01:01,780 - INFO - Episode 200/50000 - Avg Reward: 2791.80 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 11:02:25,185 - INFO - New highest tile achieved: 512 (Episode 244)
2025-03-05 11:02:26,408 - INFO - New best score: 8041.97499014735 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:04:04,393 - INFO - Episode 300/50000 - Avg Reward: 2811.57 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 11:07:05,987 - INFO - Episode 400/50000 - Avg Reward: 2770.25 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 11:15:40,508 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 11:15:40,562 - WARNING - Replay buffer state not found in checkpoint, starting with empty buffer
2025-03-05 11:15:40,562 - WARNING - GradScaler state not found in checkpoint, using default initialization
2025-03-05 11:15:40,562 - INFO - Resuming from episode 1
2025-03-05 11:15:40,562 - INFO - Current epsilon: 0.100
2025-03-05 11:15:40,562 - INFO - Starting training with device: cuda
2025-03-05 11:15:40,562 - INFO - Model parameters: 3394954
2025-03-05 11:15:40,766 - INFO - New highest tile achieved: 2 (Episode 2)
2025-03-05 11:15:40,766 - INFO - New highest tile achieved: 4 (Episode 2)
2025-03-05 11:15:40,786 - INFO - New highest tile achieved: 8 (Episode 2)
2025-03-05 11:15:40,858 - INFO - New highest tile achieved: 16 (Episode 2)
2025-03-05 11:15:40,931 - INFO - New highest tile achieved: 32 (Episode 2)
2025-03-05 11:15:41,046 - INFO - New highest tile achieved: 64 (Episode 2)
2025-03-05 11:15:41,371 - INFO - New best score: 1781.7749973118307 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:15:41,934 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-05 11:15:42,286 - INFO - New best score: 3087.887496685981 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:15:43,369 - INFO - New best score: 3689.687493884564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:16:01,321 - INFO - New highest tile achieved: 256 (Episode 16)
2025-03-05 11:16:01,955 - INFO - New best score: 5571.193738847972 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:16:08,725 - INFO - New best score: 5673.165615934133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:17:45,107 - INFO - New best score: 6226.09373958707 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:18:20,489 - INFO - Episode 100/50000 - Avg Reward: 2768.14 - Avg Max Tile: 113.45 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 11:21:01,296 - INFO - Episode 200/50000 - Avg Reward: 2791.80 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.401
2025-03-05 11:22:14,863 - INFO - New highest tile achieved: 512 (Episode 244)
2025-03-05 11:22:16,061 - INFO - New best score: 8041.97499014735 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 11:23:42,500 - INFO - Episode 300/50000 - Avg Reward: 2811.57 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 11:26:22,305 - INFO - Episode 400/50000 - Avg Reward: 2770.25 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.402
2025-03-05 11:28:51,815 - INFO - Episode 500/50000 - Avg Reward: 2528.76 - Avg Max Tile: 107.52 - Epsilon: 0.100 - Beta: 0.403
2025-03-05 11:31:35,278 - INFO - Episode 600/50000 - Avg Reward: 2785.58 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.404
2025-03-05 11:34:24,272 - INFO - Episode 700/50000 - Avg Reward: 2884.78 - Avg Max Tile: 124.96 - Epsilon: 0.100 - Beta: 0.404
2025-03-05 11:37:03,319 - INFO - Episode 800/50000 - Avg Reward: 2628.61 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.405
2025-03-05 11:39:37,300 - INFO - Episode 900/50000 - Avg Reward: 2579.21 - Avg Max Tile: 111.20 - Epsilon: 0.100 - Beta: 0.405
2025-03-05 11:42:25,186 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-05 11:42:25,186 - INFO - Episode 1000/50000 - Avg Reward: 2820.63 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.406
2025-03-05 11:45:05,868 - INFO - Episode 1100/50000 - Avg Reward: 2807.89 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.407
2025-03-05 11:48:01,486 - INFO - Episode 1200/50000 - Avg Reward: 3040.88 - Avg Max Tile: 132.48 - Epsilon: 0.100 - Beta: 0.407
2025-03-05 11:50:38,839 - INFO - Episode 1300/50000 - Avg Reward: 2720.38 - Avg Max Tile: 121.44 - Epsilon: 0.100 - Beta: 0.408
2025-03-05 11:53:29,685 - INFO - Episode 1400/50000 - Avg Reward: 2886.43 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.408
2025-03-05 11:56:03,424 - INFO - Episode 1500/50000 - Avg Reward: 2556.60 - Avg Max Tile: 109.12 - Epsilon: 0.100 - Beta: 0.409
2025-03-05 11:58:54,123 - INFO - Episode 1600/50000 - Avg Reward: 2886.16 - Avg Max Tile: 123.68 - Epsilon: 0.100 - Beta: 0.410
2025-03-05 12:01:39,289 - INFO - Episode 1700/50000 - Avg Reward: 2778.67 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.410
2025-03-05 12:04:26,656 - INFO - Episode 1800/50000 - Avg Reward: 2891.89 - Avg Max Tile: 130.40 - Epsilon: 0.100 - Beta: 0.411
2025-03-05 12:07:08,616 - INFO - Episode 1900/50000 - Avg Reward: 2693.82 - Avg Max Tile: 113.28 - Epsilon: 0.100 - Beta: 0.411
2025-03-05 12:10:02,932 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_2000.pt
2025-03-05 12:10:02,932 - INFO - Episode 2000/50000 - Avg Reward: 2908.77 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.412
2025-03-05 12:10:53,734 - INFO - New best score: 8202.134363359217 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 12:11:39,839 - INFO - New best score: 8497.553115448356 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 12:12:58,148 - INFO - Episode 2100/50000 - Avg Reward: 2997.32 - Avg Max Tile: 131.20 - Epsilon: 0.100 - Beta: 0.413
2025-03-05 12:15:42,172 - INFO - Episode 2200/50000 - Avg Reward: 2804.07 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.413
2025-03-05 12:18:27,573 - INFO - Episode 2300/50000 - Avg Reward: 2769.87 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.414
2025-03-05 12:21:07,195 - INFO - New best score: 8534.337485402822 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 12:21:20,042 - INFO - Episode 2400/50000 - Avg Reward: 2870.45 - Avg Max Tile: 125.76 - Epsilon: 0.100 - Beta: 0.414
2025-03-05 12:23:14,792 - INFO - New best score: 8590.412485092878 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 12:24:12,581 - INFO - Episode 2500/50000 - Avg Reward: 2949.45 - Avg Max Tile: 131.04 - Epsilon: 0.100 - Beta: 0.415
2025-03-05 12:27:00,371 - INFO - Episode 2600/50000 - Avg Reward: 2847.42 - Avg Max Tile: 124.80 - Epsilon: 0.100 - Beta: 0.416
2025-03-05 12:29:49,960 - INFO - Episode 2700/50000 - Avg Reward: 2869.33 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.416
2025-03-05 12:32:28,795 - INFO - Episode 2800/50000 - Avg Reward: 2617.92 - Avg Max Tile: 112.00 - Epsilon: 0.100 - Beta: 0.417
2025-03-05 12:35:13,454 - INFO - Episode 2900/50000 - Avg Reward: 2804.35 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.417
2025-03-05 12:38:05,467 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_3000.pt
2025-03-05 12:38:05,467 - INFO - Episode 3000/50000 - Avg Reward: 2881.27 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.418
2025-03-05 12:40:42,843 - INFO - Episode 3100/50000 - Avg Reward: 2700.39 - Avg Max Tile: 113.60 - Epsilon: 0.100 - Beta: 0.419
2025-03-05 12:43:34,478 - INFO - Episode 3200/50000 - Avg Reward: 2930.96 - Avg Max Tile: 126.56 - Epsilon: 0.100 - Beta: 0.419
2025-03-05 12:46:14,757 - INFO - Episode 3300/50000 - Avg Reward: 2700.32 - Avg Max Tile: 116.48 - Epsilon: 0.100 - Beta: 0.420
2025-03-05 12:49:11,966 - INFO - Episode 3400/50000 - Avg Reward: 3014.82 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.420
2025-03-05 12:51:57,451 - INFO - Episode 3500/50000 - Avg Reward: 2791.39 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.421
2025-03-05 12:54:49,475 - INFO - Episode 3600/50000 - Avg Reward: 2906.27 - Avg Max Tile: 126.72 - Epsilon: 0.100 - Beta: 0.422
2025-03-05 12:57:31,745 - INFO - Episode 3700/50000 - Avg Reward: 2715.67 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.422
2025-03-05 13:00:16,116 - INFO - Episode 3800/50000 - Avg Reward: 2744.17 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.423
2025-03-05 13:03:11,184 - INFO - Episode 3900/50000 - Avg Reward: 2947.04 - Avg Max Tile: 128.64 - Epsilon: 0.100 - Beta: 0.423
2025-03-05 13:05:57,738 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_4000.pt
2025-03-05 13:05:57,754 - INFO - Episode 4000/50000 - Avg Reward: 2712.43 - Avg Max Tile: 113.60 - Epsilon: 0.100 - Beta: 0.424
2025-03-05 13:08:35,954 - INFO - Episode 4100/50000 - Avg Reward: 2737.95 - Avg Max Tile: 116.16 - Epsilon: 0.100 - Beta: 0.425
2025-03-05 13:11:20,710 - INFO - Episode 4200/50000 - Avg Reward: 2833.75 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.425
2025-03-05 13:14:10,089 - INFO - Episode 4300/50000 - Avg Reward: 2824.37 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.426
2025-03-05 13:16:58,365 - INFO - Episode 4400/50000 - Avg Reward: 2847.78 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.426
2025-03-05 13:19:37,424 - INFO - Episode 4500/50000 - Avg Reward: 2615.45 - Avg Max Tile: 106.56 - Epsilon: 0.100 - Beta: 0.427
2025-03-05 13:22:34,248 - INFO - Episode 4600/50000 - Avg Reward: 3027.17 - Avg Max Tile: 136.00 - Epsilon: 0.100 - Beta: 0.428
2025-03-05 13:25:20,114 - INFO - Episode 4700/50000 - Avg Reward: 2803.33 - Avg Max Tile: 120.32 - Epsilon: 0.100 - Beta: 0.428
2025-03-05 13:28:12,964 - INFO - Episode 4800/50000 - Avg Reward: 2897.29 - Avg Max Tile: 124.16 - Epsilon: 0.100 - Beta: 0.429
2025-03-05 13:31:02,795 - INFO - Episode 4900/50000 - Avg Reward: 2842.89 - Avg Max Tile: 120.32 - Epsilon: 0.100 - Beta: 0.429
2025-03-05 13:33:42,693 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_5000.pt
2025-03-05 13:33:42,693 - INFO - Episode 5000/50000 - Avg Reward: 2633.29 - Avg Max Tile: 111.68 - Epsilon: 0.100 - Beta: 0.430
2025-03-05 13:36:16,032 - INFO - Episode 5100/50000 - Avg Reward: 2647.92 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.431
2025-03-05 13:38:56,433 - INFO - Episode 5200/50000 - Avg Reward: 2668.75 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.431
2025-03-05 13:41:47,171 - INFO - Episode 5300/50000 - Avg Reward: 2843.51 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.432
2025-03-05 13:44:41,534 - INFO - Episode 5400/50000 - Avg Reward: 2979.24 - Avg Max Tile: 132.16 - Epsilon: 0.100 - Beta: 0.432
2025-03-05 13:47:26,599 - INFO - Episode 5500/50000 - Avg Reward: 2795.07 - Avg Max Tile: 120.00 - Epsilon: 0.100 - Beta: 0.433
2025-03-05 13:50:19,428 - INFO - Episode 5600/50000 - Avg Reward: 2913.10 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.434
2025-03-05 13:53:05,950 - INFO - Episode 5700/50000 - Avg Reward: 2807.05 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.434
2025-03-05 13:53:30,701 - INFO - New best score: 8833.593736749888 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 13:55:53,727 - INFO - Episode 5800/50000 - Avg Reward: 2846.94 - Avg Max Tile: 122.56 - Epsilon: 0.100 - Beta: 0.435
2025-03-05 13:58:43,618 - INFO - Episode 5900/50000 - Avg Reward: 2881.43 - Avg Max Tile: 126.08 - Epsilon: 0.100 - Beta: 0.435
2025-03-05 14:01:40,055 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-05 14:01:40,055 - INFO - Episode 6000/50000 - Avg Reward: 2956.17 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.436
2025-03-05 14:04:08,709 - INFO - Episode 6100/50000 - Avg Reward: 2534.33 - Avg Max Tile: 105.44 - Epsilon: 0.100 - Beta: 0.437
2025-03-05 14:06:45,485 - INFO - Episode 6200/50000 - Avg Reward: 2568.95 - Avg Max Tile: 107.68 - Epsilon: 0.100 - Beta: 0.437
2025-03-05 14:09:29,214 - INFO - Episode 6300/50000 - Avg Reward: 2734.43 - Avg Max Tile: 117.12 - Epsilon: 0.100 - Beta: 0.438
2025-03-05 14:12:21,603 - INFO - Episode 6400/50000 - Avg Reward: 2916.11 - Avg Max Tile: 125.76 - Epsilon: 0.100 - Beta: 0.438
2025-03-05 14:15:01,338 - INFO - Episode 6500/50000 - Avg Reward: 2644.57 - Avg Max Tile: 112.32 - Epsilon: 0.100 - Beta: 0.439
2025-03-05 14:17:47,418 - INFO - Episode 6600/50000 - Avg Reward: 2765.87 - Avg Max Tile: 117.12 - Epsilon: 0.100 - Beta: 0.440
2025-03-05 14:20:33,762 - INFO - Episode 6700/50000 - Avg Reward: 2778.09 - Avg Max Tile: 118.88 - Epsilon: 0.100 - Beta: 0.440
2025-03-05 14:23:16,121 - INFO - Episode 6800/50000 - Avg Reward: 2740.60 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.441
2025-03-05 14:26:11,677 - INFO - Episode 6900/50000 - Avg Reward: 3025.95 - Avg Max Tile: 135.36 - Epsilon: 0.100 - Beta: 0.441
2025-03-05 14:28:52,876 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_7000.pt
2025-03-05 14:28:52,876 - INFO - Episode 7000/50000 - Avg Reward: 2613.40 - Avg Max Tile: 109.28 - Epsilon: 0.100 - Beta: 0.442
2025-03-05 14:31:30,884 - INFO - Episode 7100/50000 - Avg Reward: 2787.24 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.443
2025-03-05 14:34:20,959 - INFO - Episode 7200/50000 - Avg Reward: 2867.24 - Avg Max Tile: 124.64 - Epsilon: 0.100 - Beta: 0.443
2025-03-05 14:36:54,429 - INFO - Episode 7300/50000 - Avg Reward: 2513.98 - Avg Max Tile: 103.52 - Epsilon: 0.100 - Beta: 0.444
2025-03-05 14:39:47,612 - INFO - Episode 7400/50000 - Avg Reward: 2916.99 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.444
2025-03-05 14:42:32,973 - INFO - Episode 7500/50000 - Avg Reward: 2788.96 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.445
2025-03-05 14:45:30,534 - INFO - Episode 7600/50000 - Avg Reward: 2984.30 - Avg Max Tile: 128.96 - Epsilon: 0.100 - Beta: 0.446
2025-03-05 14:48:29,380 - INFO - Episode 7700/50000 - Avg Reward: 2993.92 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.446
2025-03-05 14:51:21,668 - INFO - Episode 7800/50000 - Avg Reward: 2922.06 - Avg Max Tile: 129.92 - Epsilon: 0.100 - Beta: 0.447
2025-03-05 14:54:13,252 - INFO - Episode 7900/50000 - Avg Reward: 2918.93 - Avg Max Tile: 127.36 - Epsilon: 0.100 - Beta: 0.447
2025-03-05 14:54:30,719 - INFO - New best score: 8990.724985745552 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 14:57:02,121 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_8000.pt
2025-03-05 14:57:02,121 - INFO - Episode 8000/50000 - Avg Reward: 2826.55 - Avg Max Tile: 120.80 - Epsilon: 0.100 - Beta: 0.448
2025-03-05 14:57:10,344 - INFO - New best score: 10505.66873091459 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-05 14:59:48,693 - INFO - Episode 8100/50000 - Avg Reward: 2806.99 - Avg Max Tile: 124.16 - Epsilon: 0.100 - Beta: 0.449
2025-03-05 15:02:35,546 - INFO - Episode 8200/50000 - Avg Reward: 2855.11 - Avg Max Tile: 126.08 - Epsilon: 0.100 - Beta: 0.449
2025-03-05 15:05:19,722 - INFO - Episode 8300/50000 - Avg Reward: 2717.66 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.450
2025-03-05 15:08:11,272 - INFO - Episode 8400/50000 - Avg Reward: 2860.25 - Avg Max Tile: 123.20 - Epsilon: 0.100 - Beta: 0.450
2025-03-05 15:10:56,824 - INFO - Episode 8500/50000 - Avg Reward: 2769.40 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.451
2025-03-05 15:13:42,281 - INFO - Episode 8600/50000 - Avg Reward: 2765.75 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.452
2025-03-05 15:16:29,568 - INFO - Episode 8700/50000 - Avg Reward: 2762.64 - Avg Max Tile: 115.84 - Epsilon: 0.100 - Beta: 0.452
2025-03-05 15:19:14,754 - INFO - Episode 8800/50000 - Avg Reward: 2734.97 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.453
2025-03-05 15:21:59,163 - INFO - Episode 8900/50000 - Avg Reward: 2746.20 - Avg Max Tile: 117.92 - Epsilon: 0.100 - Beta: 0.453
2025-03-05 15:24:56,450 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_9000.pt
2025-03-05 15:24:56,450 - INFO - Episode 9000/50000 - Avg Reward: 2931.41 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.454
2025-03-05 15:27:39,158 - INFO - Episode 9100/50000 - Avg Reward: 2816.08 - Avg Max Tile: 120.64 - Epsilon: 0.100 - Beta: 0.455
2025-03-05 15:30:31,085 - INFO - Episode 9200/50000 - Avg Reward: 2920.16 - Avg Max Tile: 128.00 - Epsilon: 0.100 - Beta: 0.455
2025-03-05 15:33:17,818 - INFO - Episode 9300/50000 - Avg Reward: 2808.29 - Avg Max Tile: 124.00 - Epsilon: 0.100 - Beta: 0.456
2025-03-05 15:36:02,342 - INFO - Episode 9400/50000 - Avg Reward: 2750.82 - Avg Max Tile: 118.24 - Epsilon: 0.100 - Beta: 0.456
2025-03-05 15:39:00,341 - INFO - Episode 9500/50000 - Avg Reward: 3020.62 - Avg Max Tile: 131.52 - Epsilon: 0.100 - Beta: 0.457
2025-03-05 15:41:46,238 - INFO - Episode 9600/50000 - Avg Reward: 2792.66 - Avg Max Tile: 121.60 - Epsilon: 0.100 - Beta: 0.458
2025-03-05 15:44:36,308 - INFO - Episode 9700/50000 - Avg Reward: 2847.84 - Avg Max Tile: 121.92 - Epsilon: 0.100 - Beta: 0.458
2025-03-05 15:47:33,572 - INFO - Episode 9800/50000 - Avg Reward: 3046.37 - Avg Max Tile: 139.20 - Epsilon: 0.100 - Beta: 0.459
2025-03-05 15:50:16,763 - INFO - Episode 9900/50000 - Avg Reward: 2709.13 - Avg Max Tile: 114.56 - Epsilon: 0.100 - Beta: 0.459
2025-03-05 15:53:09,252 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_10000.pt
2025-03-05 15:53:09,252 - INFO - Episode 10000/50000 - Avg Reward: 2860.39 - Avg Max Tile: 123.20 - Epsilon: 0.100 - Beta: 0.460
2025-03-05 15:55:47,844 - INFO - Episode 10100/50000 - Avg Reward: 2774.44 - Avg Max Tile: 119.04 - Epsilon: 0.100 - Beta: 0.461
2025-03-05 15:58:34,413 - INFO - Episode 10200/50000 - Avg Reward: 2822.47 - Avg Max Tile: 124.80 - Epsilon: 0.100 - Beta: 0.461
2025-03-05 16:01:11,134 - INFO - Episode 10300/50000 - Avg Reward: 2594.70 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.462
2025-03-05 16:04:16,399 - INFO - Episode 10400/50000 - Avg Reward: 3192.06 - Avg Max Tile: 143.36 - Epsilon: 0.100 - Beta: 0.462
2025-03-05 16:07:01,952 - INFO - Episode 10500/50000 - Avg Reward: 2782.68 - Avg Max Tile: 119.68 - Epsilon: 0.100 - Beta: 0.463
2025-03-05 16:09:50,817 - INFO - Episode 10600/50000 - Avg Reward: 2809.58 - Avg Max Tile: 117.76 - Epsilon: 0.100 - Beta: 0.464
2025-03-05 16:12:40,072 - INFO - Episode 10700/50000 - Avg Reward: 2866.81 - Avg Max Tile: 125.12 - Epsilon: 0.100 - Beta: 0.464
2025-03-05 16:15:27,624 - INFO - Episode 10800/50000 - Avg Reward: 2822.19 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.465
2025-03-05 16:18:15,069 - INFO - Episode 10900/50000 - Avg Reward: 2840.89 - Avg Max Tile: 125.28 - Epsilon: 0.100 - Beta: 0.465
2025-03-05 16:21:07,260 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_11000.pt
2025-03-05 16:21:07,276 - INFO - Episode 11000/50000 - Avg Reward: 2855.93 - Avg Max Tile: 121.76 - Epsilon: 0.100 - Beta: 0.466
2025-03-05 16:23:43,215 - INFO - Episode 11100/50000 - Avg Reward: 2729.79 - Avg Max Tile: 119.36 - Epsilon: 0.100 - Beta: 0.467
2025-03-05 16:26:24,835 - INFO - Episode 11200/50000 - Avg Reward: 2727.92 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.467
2025-03-05 16:29:05,657 - INFO - Episode 11300/50000 - Avg Reward: 2687.13 - Avg Max Tile: 111.84 - Epsilon: 0.100 - Beta: 0.468
2025-03-05 16:32:02,437 - INFO - Episode 11400/50000 - Avg Reward: 2979.46 - Avg Max Tile: 128.32 - Epsilon: 0.100 - Beta: 0.468
2025-03-05 16:34:54,190 - INFO - Episode 11500/50000 - Avg Reward: 2889.47 - Avg Max Tile: 125.12 - Epsilon: 0.100 - Beta: 0.469
2025-03-05 16:37:30,132 - INFO - Episode 11600/50000 - Avg Reward: 2576.51 - Avg Max Tile: 109.44 - Epsilon: 0.100 - Beta: 0.470
2025-03-05 16:40:20,781 - INFO - Episode 11700/50000 - Avg Reward: 2945.22 - Avg Max Tile: 133.28 - Epsilon: 0.100 - Beta: 0.470
2025-03-05 16:43:03,779 - INFO - Episode 11800/50000 - Avg Reward: 2732.82 - Avg Max Tile: 116.80 - Epsilon: 0.100 - Beta: 0.471
2025-03-05 16:45:47,862 - INFO - Episode 11900/50000 - Avg Reward: 2751.64 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.471
2025-03-05 16:48:34,351 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_12000.pt
2025-03-05 16:48:34,351 - INFO - Episode 12000/50000 - Avg Reward: 2715.93 - Avg Max Tile: 114.72 - Epsilon: 0.100 - Beta: 0.472
2025-03-05 16:51:05,274 - INFO - Episode 12100/50000 - Avg Reward: 2582.30 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.473
2025-03-05 16:53:50,433 - INFO - Episode 12200/50000 - Avg Reward: 2792.18 - Avg Max Tile: 121.60 - Epsilon: 0.100 - Beta: 0.473
2025-03-05 16:56:35,763 - INFO - Episode 12300/50000 - Avg Reward: 2745.01 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.474
2025-03-05 16:59:15,760 - INFO - Episode 12400/50000 - Avg Reward: 2701.71 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.474
2025-03-05 17:02:10,886 - INFO - Episode 12500/50000 - Avg Reward: 2965.77 - Avg Max Tile: 128.96 - Epsilon: 0.100 - Beta: 0.475
2025-03-05 17:04:54,506 - INFO - Episode 12600/50000 - Avg Reward: 2768.40 - Avg Max Tile: 121.52 - Epsilon: 0.100 - Beta: 0.476
2025-03-05 17:07:39,169 - INFO - Episode 12700/50000 - Avg Reward: 2744.96 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.476
2025-03-05 17:10:30,631 - INFO - Episode 12800/50000 - Avg Reward: 2872.99 - Avg Max Tile: 122.40 - Epsilon: 0.100 - Beta: 0.477
2025-03-05 17:13:22,301 - INFO - Episode 12900/50000 - Avg Reward: 2932.45 - Avg Max Tile: 129.60 - Epsilon: 0.100 - Beta: 0.477
2025-03-05 17:16:09,110 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-05 17:16:09,110 - INFO - Episode 13000/50000 - Avg Reward: 2738.15 - Avg Max Tile: 116.00 - Epsilon: 0.100 - Beta: 0.478
2025-03-05 17:18:43,634 - INFO - Episode 13100/50000 - Avg Reward: 2674.18 - Avg Max Tile: 113.92 - Epsilon: 0.100 - Beta: 0.479
2025-03-05 17:21:32,513 - INFO - Episode 13200/50000 - Avg Reward: 2909.05 - Avg Max Tile: 129.28 - Epsilon: 0.100 - Beta: 0.479
2025-03-05 17:24:12,018 - INFO - Episode 13300/50000 - Avg Reward: 2662.09 - Avg Max Tile: 115.04 - Epsilon: 0.100 - Beta: 0.480
2025-03-05 17:26:57,576 - INFO - Episode 13400/50000 - Avg Reward: 2799.43 - Avg Max Tile: 120.64 - Epsilon: 0.100 - Beta: 0.480
2025-03-05 17:29:45,742 - INFO - Episode 13500/50000 - Avg Reward: 2837.31 - Avg Max Tile: 122.56 - Epsilon: 0.100 - Beta: 0.481
2025-03-05 17:32:29,531 - INFO - Episode 13600/50000 - Avg Reward: 2777.54 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.482
2025-03-05 17:35:26,445 - INFO - Episode 13700/50000 - Avg Reward: 2968.18 - Avg Max Tile: 129.28 - Epsilon: 0.100 - Beta: 0.482
2025-03-05 17:38:17,141 - INFO - Episode 13800/50000 - Avg Reward: 2852.89 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.483
2025-03-05 17:41:07,735 - INFO - Episode 13900/50000 - Avg Reward: 2830.91 - Avg Max Tile: 119.52 - Epsilon: 0.100 - Beta: 0.483
2025-03-05 17:44:05,932 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_14000.pt
2025-03-05 17:44:05,932 - INFO - Episode 14000/50000 - Avg Reward: 2936.36 - Avg Max Tile: 127.04 - Epsilon: 0.100 - Beta: 0.484
2025-03-05 17:46:54,148 - INFO - Episode 14100/50000 - Avg Reward: 2956.00 - Avg Max Tile: 130.24 - Epsilon: 0.100 - Beta: 0.485
2025-03-05 17:49:36,848 - INFO - Episode 14200/50000 - Avg Reward: 2784.53 - Avg Max Tile: 122.88 - Epsilon: 0.100 - Beta: 0.485
2025-03-05 17:52:34,815 - INFO - Episode 14300/50000 - Avg Reward: 2998.09 - Avg Max Tile: 129.28 - Epsilon: 0.100 - Beta: 0.486
2025-03-05 17:55:28,107 - INFO - Episode 14400/50000 - Avg Reward: 2912.81 - Avg Max Tile: 125.92 - Epsilon: 0.100 - Beta: 0.486
2025-03-05 17:58:18,522 - INFO - Episode 14500/50000 - Avg Reward: 2914.59 - Avg Max Tile: 128.96 - Epsilon: 0.100 - Beta: 0.487
2025-03-05 18:01:03,850 - INFO - Episode 14600/50000 - Avg Reward: 2748.42 - Avg Max Tile: 117.92 - Epsilon: 0.100 - Beta: 0.488
2025-03-05 18:03:44,418 - INFO - Episode 14700/50000 - Avg Reward: 2702.36 - Avg Max Tile: 118.72 - Epsilon: 0.100 - Beta: 0.488
2025-03-05 18:06:30,632 - INFO - Episode 14800/50000 - Avg Reward: 2790.20 - Avg Max Tile: 120.64 - Epsilon: 0.100 - Beta: 0.489
2025-03-05 18:09:28,731 - INFO - Episode 14900/50000 - Avg Reward: 3075.04 - Avg Max Tile: 136.64 - Epsilon: 0.100 - Beta: 0.489
2025-03-05 18:12:15,723 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_15000.pt
2025-03-05 18:12:15,723 - INFO - Episode 15000/50000 - Avg Reward: 2719.83 - Avg Max Tile: 116.16 - Epsilon: 0.100 - Beta: 0.490
2025-03-05 18:14:50,612 - INFO - Episode 15100/50000 - Avg Reward: 2699.38 - Avg Max Tile: 118.08 - Epsilon: 0.100 - Beta: 0.491
2025-03-05 18:17:28,753 - INFO - Episode 15200/50000 - Avg Reward: 2701.95 - Avg Max Tile: 117.92 - Epsilon: 0.100 - Beta: 0.491
2025-03-05 18:20:09,791 - INFO - Episode 15300/50000 - Avg Reward: 2802.53 - Avg Max Tile: 124.80 - Epsilon: 0.100 - Beta: 0.492
2025-03-05 18:22:44,170 - INFO - Episode 15400/50000 - Avg Reward: 2670.41 - Avg Max Tile: 115.36 - Epsilon: 0.100 - Beta: 0.492
2025-03-05 18:25:24,830 - INFO - Episode 15500/50000 - Avg Reward: 2683.08 - Avg Max Tile: 111.36 - Epsilon: 0.100 - Beta: 0.493
2025-03-05 18:28:11,294 - INFO - Episode 15600/50000 - Avg Reward: 2933.03 - Avg Max Tile: 132.48 - Epsilon: 0.100 - Beta: 0.494
2025-03-05 18:30:48,919 - INFO - Episode 15700/50000 - Avg Reward: 2679.06 - Avg Max Tile: 114.72 - Epsilon: 0.100 - Beta: 0.494
2025-03-05 18:33:31,854 - INFO - Episode 15800/50000 - Avg Reward: 2758.04 - Avg Max Tile: 115.20 - Epsilon: 0.100 - Beta: 0.495
2025-03-05 18:36:06,711 - INFO - Episode 15900/50000 - Avg Reward: 2603.30 - Avg Max Tile: 109.44 - Epsilon: 0.100 - Beta: 0.495
2025-03-05 18:38:48,126 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_16000.pt
2025-03-05 18:38:48,126 - INFO - Episode 16000/50000 - Avg Reward: 2736.49 - Avg Max Tile: 122.08 - Epsilon: 0.100 - Beta: 0.496
2025-03-05 18:41:26,750 - INFO - Episode 16100/50000 - Avg Reward: 2728.98 - Avg Max Tile: 119.36 - Epsilon: 0.100 - Beta: 0.497
2025-03-05 18:44:21,585 - INFO - Episode 16200/50000 - Avg Reward: 3037.65 - Avg Max Tile: 135.04 - Epsilon: 0.100 - Beta: 0.497
2025-03-05 18:46:59,895 - INFO - Episode 16300/50000 - Avg Reward: 2658.91 - Avg Max Tile: 110.56 - Epsilon: 0.100 - Beta: 0.498
2025-03-05 18:49:54,579 - INFO - Episode 16400/50000 - Avg Reward: 3043.22 - Avg Max Tile: 133.76 - Epsilon: 0.100 - Beta: 0.498
2025-03-05 18:52:32,209 - INFO - Episode 16500/50000 - Avg Reward: 2645.22 - Avg Max Tile: 110.72 - Epsilon: 0.100 - Beta: 0.499
2025-03-05 18:55:14,336 - INFO - Episode 16600/50000 - Avg Reward: 2802.61 - Avg Max Tile: 121.28 - Epsilon: 0.100 - Beta: 0.500
2025-03-05 18:57:54,013 - INFO - Episode 16700/50000 - Avg Reward: 2747.79 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.500
2025-03-05 19:00:23,969 - INFO - Episode 16800/50000 - Avg Reward: 2540.20 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.501
2025-03-05 19:03:08,446 - INFO - Episode 16900/50000 - Avg Reward: 2767.41 - Avg Max Tile: 115.84 - Epsilon: 0.100 - Beta: 0.501
2025-03-05 19:05:49,250 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_17000.pt
2025-03-05 19:05:49,252 - INFO - Episode 17000/50000 - Avg Reward: 2674.37 - Avg Max Tile: 112.64 - Epsilon: 0.100 - Beta: 0.502
2025-03-05 19:08:29,202 - INFO - Episode 17100/50000 - Avg Reward: 2881.43 - Avg Max Tile: 124.16 - Epsilon: 0.100 - Beta: 0.503
2025-03-05 19:11:05,837 - INFO - Episode 17200/50000 - Avg Reward: 2621.13 - Avg Max Tile: 111.68 - Epsilon: 0.100 - Beta: 0.503
2025-03-05 19:13:55,205 - INFO - Episode 17300/50000 - Avg Reward: 2862.49 - Avg Max Tile: 121.60 - Epsilon: 0.100 - Beta: 0.504
2025-03-05 19:16:43,754 - INFO - Episode 17400/50000 - Avg Reward: 2761.82 - Avg Max Tile: 116.80 - Epsilon: 0.100 - Beta: 0.504
2025-03-05 19:20:23,137 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 19:21:12,741 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 19:22:00,520 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 19:22:03,584 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-05 19:22:03,584 - INFO - 
Evaluating regular agent...
2025-03-05 19:22:04,640 - INFO - Game 1/10 completed: Max Tile = 128
2025-03-05 19:22:05,171 - INFO - Game 2/10 completed: Max Tile = 32
2025-03-05 19:22:05,735 - INFO - Game 3/10 completed: Max Tile = 64
2025-03-05 19:22:06,484 - INFO - Game 4/10 completed: Max Tile = 64
2025-03-05 19:22:15,026 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 19:22:17,990 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-05 19:22:17,990 - INFO - 
Evaluating regular agent...
2025-03-05 19:22:19,028 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-05 19:22:19,573 - INFO - Game 2/5 completed: Max Tile = 32
2025-03-05 19:22:20,075 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-05 19:22:20,687 - INFO - Game 4/5 completed: Max Tile = 64
2025-03-05 19:22:21,555 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-05 19:22:21,555 - INFO - ========================================
2025-03-05 19:22:21,555 - INFO - Evaluation over 5 games:
2025-03-05 19:22:21,555 - INFO - Average Max Tile: 83.2
2025-03-05 19:22:21,555 - INFO - Average Score: 943.2
2025-03-05 19:22:21,555 - INFO - Average Steps: 105.8
2025-03-05 19:22:21,555 - INFO - Best Max Tile: 128
2025-03-05 19:22:21,555 - INFO - Tile distribution:
2025-03-05 19:22:21,555 - INFO -   32: 1 games (20.0%)
2025-03-05 19:22:21,555 - INFO -   64: 2 games (40.0%)
2025-03-05 19:22:21,555 - INFO -   128: 2 games (40.0%)
2025-03-05 19:22:21,555 - INFO - Average steps to achieve tile:
2025-03-05 19:22:21,555 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-05 19:32:15,256 - INFO - Game 1/5 completed: Max Tile = 64
2025-03-05 20:08:00,529 - INFO - Game 2/5 completed: Max Tile = 128
2025-03-05 20:15:03,908 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-05 21:42:37,971 - INFO - Game 4/5 completed: Max Tile = 512
2025-03-05 22:00:20,816 - INFO - Game 5/5 completed: Max Tile = 64
2025-03-05 22:00:20,816 - INFO - ========================================
2025-03-05 22:00:20,816 - INFO - Evaluation over 5 games:
2025-03-05 22:00:20,816 - INFO - Average Max Tile: 166.4
2025-03-05 22:00:20,816 - INFO - Average Score: 1881.6
2025-03-05 22:00:20,816 - INFO - Average Steps: 159.6
2025-03-05 22:00:20,816 - INFO - Best Max Tile: 512
2025-03-05 22:00:20,816 - INFO - Tile distribution:
2025-03-05 22:00:20,816 - INFO -   64: 3 games (60.0%)
2025-03-05 22:00:20,816 - INFO -   128: 1 games (20.0%)
2025-03-05 22:00:20,816 - INFO -   512: 1 games (20.0%)
2025-03-05 22:00:20,816 - INFO - Average steps to achieve tile:
2025-03-05 22:00:20,816 - INFO - 
==================================================
2025-03-05 22:00:20,816 - INFO - COMPARISON RESULTS:
2025-03-05 22:00:20,816 - INFO - Average Max Tile: Regular = 83.2, Enhanced MCTS = 166.4
2025-03-05 22:00:20,816 - INFO - Average Score: Regular = 943.2, Enhanced MCTS = 1881.6
2025-03-05 22:00:20,816 - INFO - Best Max Tile: Regular = 128, Enhanced MCTS = 512
2025-03-05 22:00:20,816 - INFO - 
Regular Agent Tile Distribution:
2025-03-05 22:00:20,816 - INFO -   32: 1 games (20.0%)
2025-03-05 22:00:20,816 - INFO -   64: 2 games (40.0%)
2025-03-05 22:00:20,816 - INFO -   128: 2 games (40.0%)
2025-03-05 22:00:20,816 - INFO - 
Enhanced MCTS Agent Tile Distribution:
2025-03-05 22:00:20,825 - INFO -   64: 3 games (60.0%)
2025-03-05 22:00:20,825 - INFO -   128: 1 games (20.0%)
2025-03-05 22:00:20,825 - INFO -   512: 1 games (20.0%)
2025-03-05 22:00:20,825 - INFO - 
==================================================
2025-03-05 22:00:20,826 - INFO - RUNNING SIMULATION COUNT COMPARISON
2025-03-05 22:00:20,826 - INFO - 
Evaluating with 50 simulations...
2025-03-05 22:11:26,427 - INFO - Game 1/2 completed: Max Tile = 256
2025-03-05 22:19:22,828 - INFO - Game 2/2 completed: Max Tile = 128
2025-03-05 22:19:22,828 - INFO - ========================================
2025-03-05 22:19:22,828 - INFO - Evaluation over 2 games:
2025-03-05 22:19:22,828 - INFO - Average Max Tile: 192.0
2025-03-05 22:19:22,828 - INFO - Average Score: 2098.0
2025-03-05 22:19:22,828 - INFO - Average Steps: 184.5
2025-03-05 22:19:22,828 - INFO - Best Max Tile: 256
2025-03-05 22:19:22,828 - INFO - Tile distribution:
2025-03-05 22:19:22,828 - INFO -   128: 1 games (50.0%)
2025-03-05 22:19:22,828 - INFO -   256: 1 games (50.0%)
2025-03-05 22:19:22,828 - INFO - Average steps to achieve tile:
2025-03-05 22:19:22,828 - INFO - 
Evaluating with 100 simulations...
2025-03-05 22:26:52,093 - INFO - Game 1/2 completed: Max Tile = 64
2025-03-05 22:37:34,048 - INFO - Game 2/2 completed: Max Tile = 128
2025-03-05 22:37:34,048 - INFO - ========================================
2025-03-05 22:37:34,049 - INFO - Evaluation over 2 games:
2025-03-05 22:37:34,050 - INFO - Average Max Tile: 96.0
2025-03-05 22:37:34,050 - INFO - Average Score: 1208.0
2025-03-05 22:37:34,050 - INFO - Average Steps: 126.5
2025-03-05 22:37:34,050 - INFO - Best Max Tile: 128
2025-03-05 22:37:34,051 - INFO - Tile distribution:
2025-03-05 22:37:34,051 - INFO -   64: 1 games (50.0%)
2025-03-05 22:37:34,051 - INFO -   128: 1 games (50.0%)
2025-03-05 22:37:34,051 - INFO - Average steps to achieve tile:
2025-03-05 22:37:34,052 - INFO - 
Evaluating with 200 simulations...
2025-03-05 23:09:17,031 - INFO - Game 1/2 completed: Max Tile = 128
2025-03-05 23:15:46,411 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 23:15:49,377 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-05 23:15:49,377 - INFO - 
Evaluating regular agent...
2025-03-05 23:15:50,398 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-05 23:15:50,906 - INFO - Game 2/5 completed: Max Tile = 32
2025-03-05 23:15:51,395 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-05 23:15:51,997 - INFO - Game 4/5 completed: Max Tile = 64
2025-03-05 23:15:52,855 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-05 23:15:52,855 - INFO - ========================================
2025-03-05 23:15:52,855 - INFO - Evaluation over 5 games:
2025-03-05 23:15:52,855 - INFO - Average Max Tile: 83.2
2025-03-05 23:15:52,855 - INFO - Average Score: 943.2
2025-03-05 23:15:52,855 - INFO - Average Steps: 105.8
2025-03-05 23:15:52,855 - INFO - Best Max Tile: 128
2025-03-05 23:15:52,855 - INFO - Tile distribution:
2025-03-05 23:15:52,855 - INFO -   32: 1 games (20.0%)
2025-03-05 23:15:52,855 - INFO -   64: 2 games (40.0%)
2025-03-05 23:15:52,855 - INFO -   128: 2 games (40.0%)
2025-03-05 23:15:52,855 - INFO - Average steps to achieve tile:
2025-03-05 23:15:52,855 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-05 23:16:34,651 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 23:16:37,393 - INFO - Creating enhanced MCTS agent with 20 simulations
2025-03-05 23:16:37,393 - INFO - 
Evaluating regular agent...
2025-03-05 23:16:38,413 - INFO - Game 1/5 completed: Max Tile = 128
2025-03-05 23:16:38,933 - INFO - Game 2/5 completed: Max Tile = 32
2025-03-05 23:16:39,422 - INFO - Game 3/5 completed: Max Tile = 64
2025-03-05 23:16:40,032 - INFO - Game 4/5 completed: Max Tile = 64
2025-03-05 23:16:40,880 - INFO - Game 5/5 completed: Max Tile = 128
2025-03-05 23:16:40,880 - INFO - ========================================
2025-03-05 23:16:40,880 - INFO - Evaluation over 5 games:
2025-03-05 23:16:40,880 - INFO - Average Max Tile: 83.2
2025-03-05 23:16:40,880 - INFO - Average Score: 943.2
2025-03-05 23:16:40,880 - INFO - Average Steps: 105.8
2025-03-05 23:16:40,880 - INFO - Best Max Tile: 128
2025-03-05 23:16:40,880 - INFO - Tile distribution:
2025-03-05 23:16:40,880 - INFO -   32: 1 games (20.0%)
2025-03-05 23:16:40,880 - INFO -   64: 2 games (40.0%)
2025-03-05 23:16:40,880 - INFO -   128: 2 games (40.0%)
2025-03-05 23:16:40,880 - INFO - Average steps to achieve tile:
2025-03-05 23:16:40,880 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-05 23:26:57,465 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 23:27:00,440 - INFO - Creating enhanced MCTS agent with 20 simulations
2025-03-05 23:27:00,441 - INFO - 
Evaluating regular agent...
2025-03-05 23:27:01,487 - INFO - Game 1/1 completed: Max Tile = 128
2025-03-05 23:27:01,488 - INFO - ========================================
2025-03-05 23:27:01,488 - INFO - Evaluation over 1 games:
2025-03-05 23:27:01,489 - INFO - Average Max Tile: 128.0
2025-03-05 23:27:01,489 - INFO - Average Score: 1208.0
2025-03-05 23:27:01,489 - INFO - Average Steps: 126.0
2025-03-05 23:27:01,489 - INFO - Best Max Tile: 128
2025-03-05 23:27:01,490 - INFO - Tile distribution:
2025-03-05 23:27:01,490 - INFO -   128: 1 games (100.0%)
2025-03-05 23:27:01,490 - INFO - Average steps to achieve tile:
2025-03-05 23:27:01,491 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-05 23:28:35,779 - INFO - Loading model from models/dueling_dqn/dueling_dqn_per_best.pt
2025-03-05 23:28:38,759 - INFO - Creating enhanced MCTS agent with 20 simulations
2025-03-05 23:28:38,760 - INFO - 
Evaluating regular agent...
2025-03-05 23:28:39,890 - INFO - Game 1/1 completed: Max Tile = 128
2025-03-05 23:28:39,891 - INFO - ========================================
2025-03-05 23:28:39,891 - INFO - Evaluation over 1 games:
2025-03-05 23:28:39,892 - INFO - Average Max Tile: 128.0
2025-03-05 23:28:39,892 - INFO - Average Score: 1208.0
2025-03-05 23:28:39,892 - INFO - Average Steps: 126.0
2025-03-05 23:28:39,892 - INFO - Best Max Tile: 128
2025-03-05 23:28:39,892 - INFO - Tile distribution:
2025-03-05 23:28:39,892 - INFO -   128: 1 games (100.0%)
2025-03-05 23:28:39,892 - INFO - Average steps to achieve tile:
2025-03-05 23:28:39,893 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-06 10:37:49,125 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:37:49,125 - ERROR - Error loading checkpoint: [Errno 2] No such file or directory: 'models\\dueling_dqn\\dueling_dqn_per_best.pt'
2025-03-06 10:38:20,739 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:38:20,739 - ERROR - Error loading checkpoint: [Errno 2] No such file or directory: 'models\\dueling_dqn\\dueling_dqn_per_best.pt'
2025-03-06 10:38:45,066 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:38:45,067 - ERROR - Error loading checkpoint: [Errno 2] No such file or directory: 'models\\dueling_dqn\\dueling_dqn_per_best.pt'
2025-03-06 10:43:52,540 - INFO - Starting training with device: cuda
2025-03-06 10:43:52,541 - INFO - Model parameters: 3394954
2025-03-06 10:43:52,543 - INFO - New highest tile achieved: 2 (Episode 1)
2025-03-06 10:43:52,546 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-06 10:43:52,558 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-06 10:43:52,583 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-06 10:43:52,602 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-06 10:43:52,616 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-06 10:43:52,770 - INFO - New best score: 279.19999051094055 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:43:53,002 - INFO - New highest tile achieved: 128 (Episode 2)
2025-03-06 10:43:53,078 - INFO - New best score: 674.5999828577042 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:43:53,622 - INFO - New best score: 727.1999813318253 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:44:01,532 - INFO - New highest tile achieved: 256 (Episode 11)
2025-03-06 10:44:02,513 - INFO - New best score: 1684.9999692440033 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:44:19,842 - INFO - New best score: 2086.7999690771103 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:44:37,164 - INFO - New best score: 2246.799961090088 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:46:41,112 - INFO - Episode 100/50000 - Avg Reward: 709.25 - Avg Max Tile: 116.48 - Epsilon: 0.100 - Beta: 0.401
2025-03-06 10:47:18,788 - INFO - New best score: 2435.3999497890472 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:49:35,968 - INFO - Episode 200/50000 - Avg Reward: 803.65 - Avg Max Tile: 125.12 - Epsilon: 0.100 - Beta: 0.401
2025-03-06 10:51:49,967 - INFO - New highest tile achieved: 512 (Episode 281)
2025-03-06 10:51:51,933 - INFO - New best score: 4321.599953055382 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 10:52:32,053 - INFO - Episode 300/50000 - Avg Reward: 847.58 - Avg Max Tile: 128.16 - Epsilon: 0.100 - Beta: 0.402
2025-03-06 10:55:26,794 - INFO - Episode 400/50000 - Avg Reward: 814.95 - Avg Max Tile: 126.08 - Epsilon: 0.100 - Beta: 0.402
2025-03-06 10:58:21,246 - INFO - Episode 500/50000 - Avg Reward: 758.54 - Avg Max Tile: 118.24 - Epsilon: 0.100 - Beta: 0.403
2025-03-06 11:01:10,283 - INFO - Episode 600/50000 - Avg Reward: 776.81 - Avg Max Tile: 122.24 - Epsilon: 0.100 - Beta: 0.404
2025-03-06 11:03:55,274 - INFO - Episode 700/50000 - Avg Reward: 673.67 - Avg Max Tile: 108.48 - Epsilon: 0.100 - Beta: 0.404
2025-03-06 11:07:03,614 - INFO - Episode 800/50000 - Avg Reward: 895.70 - Avg Max Tile: 134.40 - Epsilon: 0.100 - Beta: 0.405
2025-03-06 11:09:53,625 - INFO - Episode 900/50000 - Avg Reward: 717.66 - Avg Max Tile: 116.48 - Epsilon: 0.100 - Beta: 0.405
2025-03-06 11:12:53,173 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-06 11:12:53,173 - INFO - Episode 1000/50000 - Avg Reward: 860.01 - Avg Max Tile: 129.92 - Epsilon: 0.100 - Beta: 0.406
2025-03-06 11:15:35,564 - INFO - Episode 1100/50000 - Avg Reward: 753.44 - Avg Max Tile: 117.44 - Epsilon: 0.100 - Beta: 0.407
2025-03-06 11:18:55,432 - INFO - Starting training with device: cuda
2025-03-06 11:18:55,432 - INFO - Model parameters: 3394954
2025-03-06 11:18:55,432 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-06 11:18:55,455 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-06 11:18:55,466 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-06 11:18:55,498 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-06 11:18:55,565 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-06 11:18:55,689 - INFO - New best score: 262.599990606308 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:18:56,048 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-06 11:18:56,132 - INFO - New best score: 3083.9999871253967 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:18:57,452 - INFO - New best score: 3214.1999864578247 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:18:59,789 - INFO - New best score: 3222.799979686737 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:19:05,707 - INFO - New highest tile achieved: 256 (Episode 14)
2025-03-06 11:19:06,050 - INFO - New best score: 9738.399970650673 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:19:22,850 - INFO - New best score: 9793.999964952469 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:19:41,408 - INFO - New best score: 9812.999963521957 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:19:52,361 - INFO - New best score: 9897.399974107742 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:20:35,392 - INFO - New best score: 10221.999966263771 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:20:40,680 - INFO - New best score: 10321.399976491928 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:21:04,987 - INFO - Episode 100/10000 - Avg Reward: 2646.40 - Avg Max Tile: 112.16 - Epsilon: 0.260 - Beta: 0.401
2025-03-06 11:21:58,609 - INFO - New highest tile achieved: 512 (Episode 135)
2025-03-06 11:21:59,490 - INFO - New best score: 24929.99996083975 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:23:48,437 - INFO - Episode 200/10000 - Avg Reward: 2945.35 - Avg Max Tile: 115.84 - Epsilon: 0.056 - Beta: 0.401
2025-03-06 11:25:02,044 - INFO - Starting training with device: cuda
2025-03-06 11:25:02,045 - INFO - Model parameters: 3394954
2025-03-06 11:25:02,048 - INFO - New highest tile achieved: 2 (Episode 1)
2025-03-06 11:25:02,048 - INFO - Board state with new highest tile 2:
[[2, 2, 0, 0],
 [0, 0, 0, 0],
 [2, 0, 0, 0],
 [0, 0, 0, 0]]
2025-03-06 11:25:02,051 - INFO - New highest tile achieved: 4 (Episode 1)
2025-03-06 11:25:02,052 - INFO - Board state with new highest tile 4:
[[4, 2, 0, 0],
 [0, 0, 0, 0],
 [0, 0, 2, 0],
 [0, 0, 0, 0]]
2025-03-06 11:25:02,061 - INFO - New highest tile achieved: 8 (Episode 1)
2025-03-06 11:25:02,062 - INFO - Board state with new highest tile 8:
[[8, 2, 4, 0],
 [4, 0, 0, 0],
 [0, 0, 0, 0],
 [0, 0, 2, 0]]
2025-03-06 11:25:02,089 - INFO - New highest tile achieved: 16 (Episode 1)
2025-03-06 11:25:02,089 - INFO - Board state with new highest tile 16:
[[ 8, 16,  0,  0],
 [ 2,  4,  2,  0],
 [ 4,  8,  0,  4],
 [ 0,  0,  0,  0]]
2025-03-06 11:25:02,125 - INFO - New highest tile achieved: 32 (Episode 1)
2025-03-06 11:25:02,126 - INFO - Board state with new highest tile 32:
[[ 0,  0,  2,  0],
 [ 0,  0,  0,  8],
 [ 0,  4,  8, 16],
 [ 2,  2, 32,  8]]
2025-03-06 11:25:02,149 - INFO - New highest tile achieved: 64 (Episode 1)
2025-03-06 11:25:02,151 - INFO - Board state with new highest tile 64:
[[ 8,  2,  8,  4],
 [ 2,  4, 64,  8],
 [ 0,  2,  0,  0],
 [ 0,  0,  0,  0]]
2025-03-06 11:25:02,271 - INFO - New best score: 232.3999959230423 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:25:02,272 - INFO - Board state with new best score 232.3999959230423:
[[ 2,  4,  2,  4],
 [ 4, 64, 32,  2],
 [ 8, 16,  4, 16],
 [ 2,  4,  8,  2]]
2025-03-06 11:25:02,576 - INFO - New best score: 291.3999857902527 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:25:02,576 - INFO - Board state with new best score 291.3999857902527:
[[ 2, 16,  4,  2],
 [64, 32, 16,  4],
 [ 8,  4, 64,  2],
 [ 4, 32,  4,  8]]
2025-03-06 11:25:02,780 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-06 11:25:02,781 - INFO - Board state with new highest tile 128:
[[  0,   2,   0,   2],
 [  0,   8,  16,   4],
 [ 16,   4, 128,   2],
 [  4,   8,   2,   4]]
2025-03-06 11:25:02,959 - INFO - New best score: 3196.7999733686447 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:25:02,960 - INFO - Board state with new best score 3196.7999733686447:
[[  2,   4,   2,   4],
 [  8,  64,  32,   2],
 [ 16,   8, 128,   4],
 [  4,  16,  32,   2]]
2025-03-06 11:25:04,377 - INFO - New highest tile achieved: 256 (Episode 5)
2025-03-06 11:25:04,377 - INFO - Board state with new highest tile 256:
[[  0,   0,   4,  16],
 [  0,   2,   8,   8],
 [  0,  32, 256,  16],
 [  2,   8,   4,   8]]
2025-03-06 11:25:04,979 - INFO - New best score: 9831.199974775314 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:25:04,979 - INFO - Board state with new best score 9831.199974775314:
[[  4,  16,   4,   2],
 [  8,  32,  16,   4],
 [  2,  64, 256,  16],
 [  4,  16,  64,   2]]
2025-03-06 11:25:15,303 - INFO - New best score: 9833.999972343445 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:25:15,303 - INFO - Board state with new best score 9833.999972343445:
[[  2,   8,  16,   4],
 [ 64, 256,   4,   8],
 [  4,   2,   8,   2],
 [ 16,   4,   2,  16]]
2025-03-06 11:25:45,358 - INFO - New best score: 9891.799971938133 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:25:45,359 - INFO - Board state with new best score 9891.799971938133:
[[  4,   8,   2,   4],
 [ 32,  64,   4,   8],
 [  8,  32, 256,  16],
 [  2,  16,   2,   4]]
2025-03-06 11:26:50,339 - INFO - New best score: 9958.199979066849 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:26:50,340 - INFO - Board state with new best score 9958.199979066849:
[[  4,  16,   4,   2],
 [  2, 256,  32,   4],
 [ 32,   2,   8,   2],
 [ 16,   4,   2,   4]]
2025-03-06 11:27:03,745 - INFO - New best score: 10165.399958848953 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:27:03,746 - INFO - Board state with new best score 10165.399958848953:
[[ 16,   8,   4,  16],
 [  2, 128,  16,   8],
 [  8, 256,  32,   4],
 [  4,  32,   8,   2]]
2025-03-06 11:27:11,053 - INFO - Episode 100/10000 - Avg Reward: 2437.96 - Avg Max Tile: 109.12 - Epsilon: 0.262 - Beta: 0.401
2025-03-06 11:27:39,762 - INFO - Starting training with device: cuda
2025-03-06 11:27:39,763 - INFO - Model parameters: 3394954
2025-03-06 11:27:39,962 - INFO - New best score: 233.9999918937683 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:27:39,962 - INFO - Final board state for new best score 233.9999918937683:
[[ 8,  2,  4,  2],
 [ 2,  8, 32, 16],
 [ 4, 64,  8,  2],
 [ 2,  8,  2,  8]]
2025-03-06 11:27:40,259 - INFO - New highest tile achieved: 128 (Episode 2)
2025-03-06 11:27:40,260 - INFO - Final board state for new max tile 128:
[[  2,  32,   2,   8],
 [  8,   4,  32,   4],
 [ 32,  64, 128,   2],
 [  2,   4,  16,   4]]
2025-03-06 11:27:40,307 - INFO - New best score: 3190.3999794721603 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:27:40,308 - INFO - Final board state for new best score 3190.3999794721603:
[[  2,  32,   2,   8],
 [  8,   4,  32,   4],
 [ 32,  64, 128,   2],
 [  2,   4,  16,   4]]
2025-03-06 11:27:40,793 - INFO - New best score: 3373.39997112751 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:27:40,794 - INFO - Final board state for new best score 3373.39997112751:
[[  8,   4, 128,   4],
 [ 32,   8,   4,   2],
 [128,  32,   8,  64],
 [  2,   4,   2,   8]]
2025-03-06 11:28:37,936 - INFO - New highest tile achieved: 256 (Episode 57)
2025-03-06 11:28:37,937 - INFO - Final board state for new max tile 256:
[[ 16,   2,   8,   2],
 [  4,  32,  16,   8],
 [  2,  16, 256,  64],
 [  4,   2,   4,   2]]
2025-03-06 11:28:38,155 - INFO - New best score: 9776.999976873398 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:28:38,155 - INFO - Final board state for new best score 9776.999976873398:
[[ 16,   2,   8,   2],
 [  4,  32,  16,   8],
 [  2,  16, 256,  64],
 [  4,   2,   4,   2]]
2025-03-06 11:28:53,343 - INFO - New best score: 9791.799978733063 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:28:53,344 - INFO - Final board state for new best score 9791.799978733063:
[[ 16,   2,  16,   2],
 [  8,   4,   2,  16],
 [ 32, 256,   8,   4],
 [  8,  16,   4,   2]]
2025-03-06 11:29:23,326 - INFO - New best score: 9848.999970555305 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:29:23,326 - INFO - Final board state for new best score 9848.999970555305:
[[  4,   2,  64,   4],
 [ 16,   4, 256,   2],
 [  2,  16,  32,   8],
 [  4,   8,   4,   2]]
2025-03-06 11:29:35,483 - INFO - New best score: 10042.799972653389 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:29:35,484 - INFO - Final board state for new best score 10042.799972653389:
[[ 64,   4,   2,   8],
 [  8,  64,  16,   4],
 [  4, 256,   4,   2],
 [  2,   4,   2,   8]]
2025-03-06 11:29:38,494 - INFO - Episode 100/10000 - Avg Reward: 2196.81 - Avg Max Tile: 100.64 - Epsilon: 0.287 - Beta: 0.401
2025-03-06 11:30:34,409 - INFO - New best score: 10151.599956274033 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:30:34,409 - INFO - Final board state for new best score 10151.599956274033:
[[  2,  32,   2,   4],
 [256, 128,  32,   8],
 [  4,  32,   8,   4],
 [  2,   8,   4,   2]]
2025-03-06 11:31:02,808 - INFO - New best score: 10313.59996831417 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:31:02,809 - INFO - Final board state for new best score 10313.59996831417:
[[  4,  32,   4,   2],
 [256, 128,  16,   4],
 [  2,  16,  32,   2],
 [  8,   4,   8,   4]]
2025-03-06 11:32:10,501 - INFO - Episode 200/10000 - Avg Reward: 2700.01 - Avg Max Tile: 112.32 - Epsilon: 0.062 - Beta: 0.401
2025-03-06 11:32:25,281 - INFO - New best score: 10503.199974298477 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:32:25,282 - INFO - Final board state for new best score 10503.199974298477:
[[256,  64,  32,   8],
 [  8,  32,  16,   4],
 [ 64,  16,   4,   2],
 [  4,   8,   2,   4]]
2025-03-06 11:32:48,365 - INFO - New best score: 10727.19997870922 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:32:48,365 - INFO - Final board state for new best score 10727.19997870922:
[[  4,   2,  64,  16],
 [256, 128,  16,   4],
 [ 32,   8,   4,   2],
 [ 16,   4,   2,   4]]
2025-03-06 11:33:20,624 - INFO - New best score: 10852.399970293045 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:33:20,624 - INFO - Final board state for new best score 10852.399970293045:
[[256, 128,   4,   8],
 [128,  64,   8,   4],
 [ 32,  16,   4,   2],
 [  2,   4,  16,   4]]
2025-03-06 11:35:03,902 - INFO - Episode 300/10000 - Avg Reward: 3350.27 - Avg Max Tile: 122.56 - Epsilon: 0.050 - Beta: 0.402
2025-03-06 11:36:22,638 - INFO - New best score: 11012.999962210655 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:36:22,639 - INFO - Final board state for new best score 11012.999962210655:
[[256, 128,   4,   2],
 [128,  64,  32,   8],
 [ 32,  16,   8,   4],
 [ 16,   4,   2,   8]]
2025-03-06 11:38:28,405 - INFO - Episode 400/10000 - Avg Reward: 4807.44 - Avg Max Tile: 151.04 - Epsilon: 0.050 - Beta: 0.402
2025-03-06 11:39:01,989 - INFO - New highest tile achieved: 512 (Episode 416)
2025-03-06 11:39:01,990 - INFO - Final board state for new max tile 512:
[[512,   2,  16,   2],
 [  2,  64,  32,   4],
 [ 32,  16,   4,   8],
 [  8,   4,   2,   4]]
2025-03-06 11:39:03,663 - INFO - New best score: 25884.799971342087 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:39:03,663 - INFO - Final board state for new best score 25884.799971342087:
[[512,   2,  16,   2],
 [  2,  64,  32,   4],
 [ 32,  16,   4,   8],
 [  8,   4,   2,   4]]
2025-03-06 11:41:29,807 - INFO - Episode 500/10000 - Avg Reward: 4068.40 - Avg Max Tile: 137.60 - Epsilon: 0.050 - Beta: 0.403
2025-03-06 11:44:55,051 - INFO - Episode 600/10000 - Avg Reward: 4217.58 - Avg Max Tile: 138.88 - Epsilon: 0.050 - Beta: 0.404
2025-03-06 11:48:20,953 - INFO - New best score: 25945.399961829185 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:48:20,953 - INFO - Final board state for new best score 25945.399961829185:
[[  2, 128,  32,   8],
 [512,  32,   4,   2],
 [ 16,   8,   2,   4],
 [  2,  32,   8,   2]]
2025-03-06 11:48:20,954 - INFO - Episode 700/10000 - Avg Reward: 4253.71 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.404
2025-03-06 11:51:53,046 - INFO - Episode 800/10000 - Avg Reward: 3982.96 - Avg Max Tile: 136.32 - Epsilon: 0.050 - Beta: 0.405
2025-03-06 11:55:24,289 - INFO - Episode 900/10000 - Avg Reward: 3734.67 - Avg Max Tile: 131.52 - Epsilon: 0.050 - Beta: 0.405
2025-03-06 11:58:26,932 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-06 11:58:26,933 - INFO - Episode 1000/10000 - Avg Reward: 3403.03 - Avg Max Tile: 125.12 - Epsilon: 0.050 - Beta: 0.406
2025-03-06 11:58:47,828 - INFO - New best score: 26110.79995417595 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 11:58:47,828 - INFO - Final board state for new best score 26110.79995417595:
[[512, 128,   8,   4],
 [128,  16,  32,   8],
 [  4,   2,  16,   4],
 [  8,   4,   8,   2]]
2025-03-06 12:03:24,316 - INFO - Starting training with device: cuda
2025-03-06 12:03:24,317 - INFO - Model parameters: 3394954
2025-03-06 12:03:24,588 - INFO - New highest tile achieved: 128 (Episode 1)
2025-03-06 12:03:24,588 - INFO - Final board state for new max tile 128:
[[  4,   2,   4,   2],
 [ 64,   4,   8,   4],
 [128,  16,   2,   8],
 [  4,   8,   4,   2]]
2025-03-06 12:03:24,639 - INFO - New best score: 1270.79998421669 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:03:24,639 - INFO - Final board state for new best score 1270.79998421669:
[[  4,   2,   4,   2],
 [ 64,   4,   8,   4],
 [128,  16,   2,   8],
 [  4,   8,   4,   2]]
2025-03-06 12:03:28,032 - INFO - New best score: 1387.3999814391136 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:03:28,033 - INFO - Final board state for new best score 1387.3999814391136:
[[  2,   8, 128,   4],
 [ 16,  32,   2,  16],
 [  8,  16,  64,   4],
 [  2,   8,   4,   2]]
2025-03-06 12:03:32,832 - INFO - New best score: 1389.9999850988388 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:03:32,832 - INFO - Final board state for new best score 1389.9999850988388:
[[  2,   4,  16,   2],
 [  4,   2,  32,  16],
 [  8,  16, 128,   8],
 [  4,   2,   4,   2]]
2025-03-06 12:03:34,427 - INFO - New highest tile achieved: 256 (Episode 13)
2025-03-06 12:03:34,428 - INFO - Final board state for new max tile 256:
[[  2,  16,   2,   4],
 [ 16, 256,   4,   2],
 [  4,  32,   2,  64],
 [  2,   8,   4,   2]]
2025-03-06 12:03:34,534 - INFO - New best score: 1899.599972486496 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:03:34,534 - INFO - Final board state for new best score 1899.599972486496:
[[  2,  16,   2,   4],
 [ 16, 256,   4,   2],
 [  4,  32,   2,  64],
 [  2,   8,   4,   2]]
2025-03-06 12:03:47,482 - INFO - New best score: 2125.1999764442444 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:03:47,483 - INFO - Final board state for new best score 2125.1999764442444:
[[  2,   8,  16,   4],
 [  8, 256,   8,   2],
 [  4,   2,  16,   4],
 [  2,  16,   8,   2]]
2025-03-06 12:04:12,863 - INFO - New best score: 2206.999960899353 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:04:12,863 - INFO - Final board state for new best score 2206.999960899353:
[[  4,   2,   4, 128],
 [  2,  16,  64,   4],
 [  8, 256,  32,   2],
 [  4,   2,  16,   4]]
2025-03-06 12:05:15,493 - INFO - New best score: 2370.199966430664 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:05:15,494 - INFO - Final board state for new best score 2370.199966430664:
[[  8,  64,   4,   2],
 [  4, 128,  16,   8],
 [  2, 256,   8,   4],
 [  4,  16,   4,   2]]
2025-03-06 12:05:24,116 - INFO - Episode 100/10000 - Avg Reward: 1210.76 - Avg Max Tile: 105.28 - Epsilon: 0.267 - Beta: 0.401
2025-03-06 12:05:36,302 - INFO - New best score: 2631.3999503850937 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:05:36,302 - INFO - Final board state for new best score 2631.3999503850937:
[[256,   8,   2,   4],
 [  8, 256,  32,   8],
 [  4,  64,   8,  16],
 [ 16,   8,   4,   2]]
2025-03-06 12:07:22,502 - INFO - New best score: 2942.599976539612 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:07:22,503 - INFO - Final board state for new best score 2942.599976539612:
[[256,   8,   4,   2],
 [  4,   2, 128,   8],
 [ 64,  32,   8,   4],
 [  4,  16,   4,   2]]
2025-03-06 12:07:56,432 - INFO - New highest tile achieved: 512 (Episode 191)
2025-03-06 12:07:56,433 - INFO - Final board state for new max tile 512:
[[  8,   4,  64,   4],
 [512,  16,   8,   2],
 [  8,  32,   4,   8],
 [  4,  16,   2,   4]]
2025-03-06 12:07:57,171 - INFO - New best score: 3719.1999609470367 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:07:57,172 - INFO - Final board state for new best score 3719.1999609470367:
[[  8,   4,  64,   4],
 [512,  16,   8,   2],
 [  8,  32,   4,   8],
 [  4,  16,   2,   4]]
2025-03-06 12:08:13,096 - INFO - Episode 200/10000 - Avg Reward: 1468.50 - Avg Max Tile: 126.40 - Epsilon: 0.051 - Beta: 0.401
2025-03-06 12:11:27,634 - INFO - Episode 300/10000 - Avg Reward: 1663.86 - Avg Max Tile: 145.28 - Epsilon: 0.050 - Beta: 0.402
2025-03-06 12:14:34,698 - INFO - Episode 400/10000 - Avg Reward: 1593.93 - Avg Max Tile: 136.96 - Epsilon: 0.050 - Beta: 0.402
2025-03-06 12:17:38,683 - INFO - Episode 500/10000 - Avg Reward: 1552.92 - Avg Max Tile: 129.28 - Epsilon: 0.050 - Beta: 0.403
2025-03-06 12:18:51,939 - INFO - New best score: 3757.999966979027 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:18:51,939 - INFO - Final board state for new best score 3757.999966979027:
[[512,  16,   8,   2],
 [  8,  32,  16,   8],
 [  2,   4,   8,   4],
 [ 16,   8,   4,   2]]
2025-03-06 12:19:28,190 - INFO - New best score: 5022.399933934212 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:19:28,191 - INFO - Final board state for new best score 5022.399933934212:
[[512,  64,   4,  16],
 [  8, 256,  32,   8],
 [ 32,  64,   8,   4],
 [  2,  32,  16,   2]]
2025-03-06 12:20:57,396 - INFO - Episode 600/10000 - Avg Reward: 1654.22 - Avg Max Tile: 142.08 - Epsilon: 0.050 - Beta: 0.404
2025-03-06 12:24:03,452 - INFO - Episode 700/10000 - Avg Reward: 1551.12 - Avg Max Tile: 126.72 - Epsilon: 0.050 - Beta: 0.404
2025-03-06 12:26:59,522 - INFO - Episode 800/10000 - Avg Reward: 1433.28 - Avg Max Tile: 115.52 - Epsilon: 0.050 - Beta: 0.405
2025-03-06 12:30:09,131 - INFO - Episode 900/10000 - Avg Reward: 1559.18 - Avg Max Tile: 131.84 - Epsilon: 0.050 - Beta: 0.405
2025-03-06 12:33:40,290 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-06 12:33:40,291 - INFO - Episode 1000/10000 - Avg Reward: 1638.99 - Avg Max Tile: 133.60 - Epsilon: 0.050 - Beta: 0.406
2025-03-06 12:36:44,536 - INFO - Episode 1100/10000 - Avg Reward: 1519.86 - Avg Max Tile: 125.76 - Epsilon: 0.050 - Beta: 0.407
2025-03-06 12:40:40,374 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-06 12:40:41,570 - INFO - Resuming from episode 1000
2025-03-06 12:40:41,571 - INFO - Previous best score: 5022.399933934212
2025-03-06 12:40:41,571 - INFO - Previous highest tile: 512
2025-03-06 12:40:41,571 - INFO - Current epsilon: 0.050
2025-03-06 12:40:41,571 - INFO - Starting training with device: cuda
2025-03-06 12:40:41,572 - INFO - Model parameters: 3394954
2025-03-06 12:40:41,572 - INFO - Episode 1000: Reset epsilon to 0.3 to encourage exploration
2025-03-06 12:44:10,136 - INFO - Episode 1100/10000 - Avg Reward: 1433.26 - Avg Max Tile: 126.72 - Epsilon: 0.058 - Beta: 0.407
2025-03-06 12:44:29,859 - INFO - New best score: 5120.799956679344 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 12:44:29,860 - INFO - Final board state for new best score 5120.799956679344:
[[512,   8,   2,   4],
 [  4, 256,  16,   2],
 [  8,   4,   2,   4],
 [  2,  32,   4,   2]]
2025-03-06 12:48:07,149 - INFO - Episode 1200/10000 - Avg Reward: 1614.55 - Avg Max Tile: 136.80 - Epsilon: 0.050 - Beta: 0.407
2025-03-06 12:52:03,183 - INFO - Episode 1300/10000 - Avg Reward: 1625.05 - Avg Max Tile: 141.60 - Epsilon: 0.050 - Beta: 0.408
2025-03-06 12:56:03,258 - INFO - Episode 1400/10000 - Avg Reward: 1588.53 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.408
2025-03-06 13:00:05,088 - INFO - Episode 1500/10000 - Avg Reward: 1622.83 - Avg Max Tile: 140.00 - Epsilon: 0.050 - Beta: 0.409
2025-03-06 13:01:27,191 - INFO - New best score: 5234.399943590164 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 13:01:27,192 - INFO - Final board state for new best score 5234.399943590164:
[[512, 256,  64,  16],
 [ 16,  32,  16,   2],
 [  4,  16,   8,   4],
 [  2,   8,   4,   2]]
2025-03-06 13:04:20,501 - INFO - Episode 1600/10000 - Avg Reward: 1670.20 - Avg Max Tile: 141.92 - Epsilon: 0.050 - Beta: 0.410
2025-03-06 13:08:06,204 - INFO - Episode 1700/10000 - Avg Reward: 1512.44 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.410
2025-03-06 13:11:54,615 - INFO - Episode 1800/10000 - Avg Reward: 1530.46 - Avg Max Tile: 125.28 - Epsilon: 0.050 - Beta: 0.411
2025-03-06 13:15:50,006 - INFO - Episode 1900/10000 - Avg Reward: 1552.38 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.411
2025-03-06 13:19:51,373 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_2000.pt
2025-03-06 13:19:51,374 - INFO - Episode 2000/10000 - Avg Reward: 1576.35 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.412
2025-03-06 13:19:51,374 - INFO - Episode 2000: Reset epsilon to 0.3 to encourage exploration
2025-03-06 13:23:01,065 - INFO - Episode 2100/10000 - Avg Reward: 1291.25 - Avg Max Tile: 108.80 - Epsilon: 0.067 - Beta: 0.413
2025-03-06 13:26:54,185 - INFO - Episode 2200/10000 - Avg Reward: 1571.55 - Avg Max Tile: 134.88 - Epsilon: 0.050 - Beta: 0.413
2025-03-06 13:30:34,609 - INFO - Episode 2300/10000 - Avg Reward: 1464.07 - Avg Max Tile: 121.12 - Epsilon: 0.050 - Beta: 0.414
2025-03-06 13:34:35,566 - INFO - Episode 2400/10000 - Avg Reward: 1591.73 - Avg Max Tile: 135.36 - Epsilon: 0.050 - Beta: 0.414
2025-03-06 13:38:39,118 - INFO - Episode 2500/10000 - Avg Reward: 1659.80 - Avg Max Tile: 142.72 - Epsilon: 0.050 - Beta: 0.415
2025-03-06 13:42:35,943 - INFO - Episode 2600/10000 - Avg Reward: 1543.40 - Avg Max Tile: 132.48 - Epsilon: 0.050 - Beta: 0.416
2025-03-06 13:46:42,268 - INFO - Episode 2700/10000 - Avg Reward: 1627.79 - Avg Max Tile: 138.24 - Epsilon: 0.050 - Beta: 0.416
2025-03-06 13:50:32,616 - INFO - Episode 2800/10000 - Avg Reward: 1544.86 - Avg Max Tile: 127.04 - Epsilon: 0.050 - Beta: 0.417
2025-03-06 13:54:17,704 - INFO - Episode 2900/10000 - Avg Reward: 1496.68 - Avg Max Tile: 122.40 - Epsilon: 0.050 - Beta: 0.417
2025-03-06 13:58:19,680 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_3000.pt
2025-03-06 13:58:19,680 - INFO - Episode 3000/10000 - Avg Reward: 1557.23 - Avg Max Tile: 129.60 - Epsilon: 0.050 - Beta: 0.418
2025-03-06 13:58:19,681 - INFO - Episode 3000: Reset epsilon to 0.3 to encourage exploration
2025-03-06 14:01:32,743 - INFO - Episode 3100/10000 - Avg Reward: 1337.76 - Avg Max Tile: 112.96 - Epsilon: 0.066 - Beta: 0.419
2025-03-06 14:05:37,412 - INFO - Episode 3200/10000 - Avg Reward: 1628.62 - Avg Max Tile: 137.92 - Epsilon: 0.050 - Beta: 0.419
2025-03-06 14:09:28,800 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_3000.pt
2025-03-06 14:09:30,678 - INFO - Resuming from episode 3000
2025-03-06 14:09:30,678 - INFO - Previous best score: 5234.399943590164
2025-03-06 14:09:30,679 - INFO - Previous highest tile: 512
2025-03-06 14:09:30,679 - INFO - Current epsilon: 0.050
2025-03-06 14:09:30,679 - INFO - Starting training with device: cuda
2025-03-06 14:09:30,680 - INFO - Model parameters: 3394954
2025-03-06 14:09:30,680 - INFO - Episode 3000: Reset epsilon to 0.5 to encourage exploration (using slower decay rate: 0.9998)
2025-03-06 14:12:24,152 - INFO - Episode 3100/10000 - Avg Reward: 1189.30 - Avg Max Tile: 97.92 - Epsilon: 0.124 - Beta: 0.419
2025-03-06 14:16:10,847 - INFO - Episode 3199: Returning to normal epsilon decay rate after 200 episodes of exploration
2025-03-06 14:16:14,337 - INFO - Episode 3200/10000 - Avg Reward: 1557.00 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.419
2025-03-06 14:20:31,527 - INFO - Episode 3300/10000 - Avg Reward: 1704.40 - Avg Max Tile: 143.36 - Epsilon: 0.050 - Beta: 0.420
2025-03-06 14:24:39,446 - INFO - Episode 3400/10000 - Avg Reward: 1647.28 - Avg Max Tile: 137.92 - Epsilon: 0.050 - Beta: 0.420
2025-03-06 14:28:42,912 - INFO - Episode 3500/10000 - Avg Reward: 1607.64 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.421
2025-03-06 14:32:34,338 - INFO - Episode 3600/10000 - Avg Reward: 1563.22 - Avg Max Tile: 132.48 - Epsilon: 0.050 - Beta: 0.422
2025-03-06 14:36:23,341 - INFO - Episode 3700/10000 - Avg Reward: 1508.52 - Avg Max Tile: 126.08 - Epsilon: 0.050 - Beta: 0.422
2025-03-06 14:40:14,305 - INFO - Episode 3800/10000 - Avg Reward: 1549.81 - Avg Max Tile: 129.44 - Epsilon: 0.050 - Beta: 0.423
2025-03-06 14:44:08,168 - INFO - Episode 3900/10000 - Avg Reward: 1536.88 - Avg Max Tile: 128.32 - Epsilon: 0.050 - Beta: 0.423
2025-03-06 14:48:13,606 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_4000.pt
2025-03-06 14:48:13,606 - INFO - Episode 4000/10000 - Avg Reward: 1654.86 - Avg Max Tile: 146.88 - Epsilon: 0.050 - Beta: 0.424
2025-03-06 14:48:13,606 - INFO - Episode 4000: Reset epsilon to 0.5 to encourage exploration (using slower decay rate: 0.9998)
2025-03-06 14:51:16,019 - INFO - Episode 4100/10000 - Avg Reward: 1298.91 - Avg Max Tile: 112.80 - Epsilon: 0.113 - Beta: 0.425
2025-03-06 14:54:56,804 - INFO - Episode 4199: Returning to normal epsilon decay rate after 200 episodes of exploration
2025-03-06 14:54:59,239 - INFO - Episode 4200/10000 - Avg Reward: 1485.64 - Avg Max Tile: 124.16 - Epsilon: 0.050 - Beta: 0.425
2025-03-06 14:59:01,714 - INFO - Episode 4300/10000 - Avg Reward: 1617.72 - Avg Max Tile: 138.88 - Epsilon: 0.050 - Beta: 0.426
2025-03-06 15:03:03,922 - INFO - Episode 4400/10000 - Avg Reward: 1619.44 - Avg Max Tile: 138.40 - Epsilon: 0.050 - Beta: 0.426
2025-03-06 15:06:51,202 - INFO - Episode 4500/10000 - Avg Reward: 1555.14 - Avg Max Tile: 131.84 - Epsilon: 0.050 - Beta: 0.427
2025-03-06 15:09:50,098 - INFO - New best score: 5505.599947452545 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 15:09:50,098 - INFO - Final board state for new best score 5505.599947452545:
[[512,   4,  64,  16],
 [256, 128,  16,   4],
 [  8,  64,   8,   2],
 [  2,  16,   2,   4]]
2025-03-06 15:11:08,304 - INFO - Episode 4600/10000 - Avg Reward: 1708.74 - Avg Max Tile: 149.12 - Epsilon: 0.050 - Beta: 0.428
2025-03-06 15:14:55,820 - INFO - Episode 4700/10000 - Avg Reward: 1525.56 - Avg Max Tile: 130.08 - Epsilon: 0.050 - Beta: 0.428
2025-03-06 15:18:58,880 - INFO - Episode 4800/10000 - Avg Reward: 1627.87 - Avg Max Tile: 138.88 - Epsilon: 0.050 - Beta: 0.429
2025-03-06 15:22:53,258 - INFO - Episode 4900/10000 - Avg Reward: 1603.43 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.429
2025-03-06 15:26:49,161 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_5000.pt
2025-03-06 15:26:49,161 - INFO - Episode 5000/10000 - Avg Reward: 1545.99 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.430
2025-03-06 15:26:49,162 - INFO - Episode 5000: Reset epsilon to 0.5 to encourage exploration (using slower decay rate: 0.9998)
2025-03-06 15:29:50,906 - INFO - Episode 5100/10000 - Avg Reward: 1266.47 - Avg Max Tile: 108.16 - Epsilon: 0.114 - Beta: 0.431
2025-03-06 15:33:36,012 - INFO - Episode 5199: Returning to normal epsilon decay rate after 200 episodes of exploration
2025-03-06 15:33:38,070 - INFO - Episode 5200/10000 - Avg Reward: 1513.51 - Avg Max Tile: 128.32 - Epsilon: 0.050 - Beta: 0.431
2025-03-06 15:37:40,507 - INFO - Episode 5300/10000 - Avg Reward: 1556.76 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.432
2025-03-06 15:41:29,384 - INFO - Episode 5400/10000 - Avg Reward: 1579.64 - Avg Max Tile: 131.52 - Epsilon: 0.050 - Beta: 0.432
2025-03-06 15:45:11,284 - INFO - Episode 5500/10000 - Avg Reward: 1593.51 - Avg Max Tile: 133.12 - Epsilon: 0.050 - Beta: 0.433
2025-03-06 15:48:34,901 - INFO - Episode 5600/10000 - Avg Reward: 1492.39 - Avg Max Tile: 126.40 - Epsilon: 0.050 - Beta: 0.434
2025-03-06 15:52:03,237 - INFO - Episode 5700/10000 - Avg Reward: 1562.68 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.434
2025-03-06 15:55:41,977 - INFO - Episode 5800/10000 - Avg Reward: 1594.37 - Avg Max Tile: 136.64 - Epsilon: 0.050 - Beta: 0.435
2025-03-06 15:59:05,009 - INFO - Episode 5900/10000 - Avg Reward: 1542.08 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.435
2025-03-06 16:03:13,987 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:03:13,987 - INFO - Episode 6000/10000 - Avg Reward: 1709.13 - Avg Max Tile: 150.08 - Epsilon: 0.050 - Beta: 0.436
2025-03-06 16:03:13,988 - INFO - Episode 6000: Reset epsilon to 0.5 to encourage exploration (using slower decay rate: 0.9998)
2025-03-06 16:07:35,991 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:07:37,883 - INFO - Resuming from episode 6000
2025-03-06 16:07:37,884 - INFO - Previous best score: 5505.599947452545
2025-03-06 16:07:37,884 - INFO - Previous highest tile: 512
2025-03-06 16:07:37,884 - INFO - Current epsilon: 0.050
2025-03-06 16:07:37,885 - INFO - Starting training with device: cuda
2025-03-06 16:07:37,885 - INFO - Model parameters: 3394954
2025-03-06 16:07:37,886 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 16:08:23,711 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:08:25,572 - INFO - Resuming from episode 6000
2025-03-06 16:08:25,572 - INFO - Previous best score: 5505.599947452545
2025-03-06 16:08:25,572 - INFO - Previous highest tile: 512
2025-03-06 16:08:25,573 - INFO - Current epsilon: 0.050
2025-03-06 16:08:25,573 - INFO - Starting training with device: cuda
2025-03-06 16:08:25,573 - INFO - Model parameters: 3394954
2025-03-06 16:08:25,574 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 16:09:29,861 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:09:31,736 - INFO - Resuming from episode 6000
2025-03-06 16:09:31,737 - INFO - Previous best score: 5505.599947452545
2025-03-06 16:09:31,737 - INFO - Previous highest tile: 512
2025-03-06 16:09:31,737 - INFO - Current epsilon: 0.050
2025-03-06 16:09:31,738 - INFO - Starting training with device: cuda
2025-03-06 16:09:31,738 - INFO - Model parameters: 3394954
2025-03-06 16:09:31,738 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 16:09:47,077 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:09:48,929 - INFO - Resuming from episode 6000
2025-03-06 16:09:48,929 - INFO - Previous best score: 5505.599947452545
2025-03-06 16:09:48,930 - INFO - Previous highest tile: 512
2025-03-06 16:09:48,930 - INFO - Current epsilon: 0.050
2025-03-06 16:09:48,930 - INFO - Starting training with device: cuda
2025-03-06 16:09:48,930 - INFO - Model parameters: 3394954
2025-03-06 16:09:48,932 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 16:10:49,742 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:10:51,615 - INFO - Resuming from episode 6000
2025-03-06 16:10:51,615 - INFO - Previous best score: 5505.599947452545
2025-03-06 16:10:51,616 - INFO - Previous highest tile: 512
2025-03-06 16:10:51,616 - INFO - Current epsilon: 0.050
2025-03-06 16:10:51,616 - INFO - Starting training with device: cuda
2025-03-06 16:10:51,617 - INFO - Model parameters: 3394954
2025-03-06 16:10:51,617 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 16:11:51,742 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-06 16:11:53,612 - INFO - Resuming from episode 6000
2025-03-06 16:11:53,612 - INFO - Previous best score: 5505.599947452545
2025-03-06 16:11:53,612 - INFO - Previous highest tile: 512
2025-03-06 16:11:53,612 - INFO - Current epsilon: 0.050
2025-03-06 16:11:53,612 - INFO - Starting training with device: cuda
2025-03-06 16:11:53,613 - INFO - Model parameters: 3394954
2025-03-06 16:11:53,614 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 16:14:39,714 - INFO - Episode 6100/10000 - Avg Reward: 1240.91 - Avg Max Tile: 107.04 - Epsilon: 0.122 - Beta: 0.437
2025-03-06 16:18:05,783 - INFO - Episode 6199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-06 16:18:07,832 - INFO - Episode 6200/10000 - Avg Reward: 1517.29 - Avg Max Tile: 125.76 - Epsilon: 0.050 - Beta: 0.437
2025-03-06 16:21:58,080 - INFO - Episode 6300/10000 - Avg Reward: 1585.66 - Avg Max Tile: 132.80 - Epsilon: 0.050 - Beta: 0.438
2025-03-06 16:25:54,281 - INFO - Episode 6400/10000 - Avg Reward: 1579.24 - Avg Max Tile: 135.36 - Epsilon: 0.050 - Beta: 0.438
2025-03-06 16:29:48,784 - INFO - Episode 6500/10000 - Avg Reward: 1565.77 - Avg Max Tile: 129.44 - Epsilon: 0.050 - Beta: 0.439
2025-03-06 16:33:43,018 - INFO - Episode 6600/10000 - Avg Reward: 1520.70 - Avg Max Tile: 130.24 - Epsilon: 0.050 - Beta: 0.440
2025-03-06 16:37:47,674 - INFO - Episode 6700/10000 - Avg Reward: 1639.67 - Avg Max Tile: 140.80 - Epsilon: 0.050 - Beta: 0.440
2025-03-06 16:41:37,285 - INFO - Episode 6800/10000 - Avg Reward: 1580.66 - Avg Max Tile: 134.08 - Epsilon: 0.050 - Beta: 0.441
2025-03-06 16:45:58,354 - INFO - Episode 6900/10000 - Avg Reward: 1681.03 - Avg Max Tile: 142.24 - Epsilon: 0.050 - Beta: 0.441
2025-03-06 16:50:19,526 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_7000.pt
2025-03-06 16:50:19,526 - INFO - Episode 7000/10000 - Avg Reward: 1591.99 - Avg Max Tile: 136.32 - Epsilon: 0.050 - Beta: 0.442
2025-03-06 16:54:00,953 - INFO - Episode 7100/10000 - Avg Reward: 1482.47 - Avg Max Tile: 123.84 - Epsilon: 0.050 - Beta: 0.443
2025-03-06 16:57:50,379 - INFO - Episode 7200/10000 - Avg Reward: 1559.68 - Avg Max Tile: 134.08 - Epsilon: 0.050 - Beta: 0.443
2025-03-06 17:02:05,929 - INFO - Episode 7300/10000 - Avg Reward: 1720.90 - Avg Max Tile: 151.84 - Epsilon: 0.050 - Beta: 0.444
2025-03-06 17:06:17,547 - INFO - Episode 7400/10000 - Avg Reward: 1718.44 - Avg Max Tile: 149.28 - Epsilon: 0.050 - Beta: 0.444
2025-03-06 17:10:07,724 - INFO - Episode 7500/10000 - Avg Reward: 1555.75 - Avg Max Tile: 131.52 - Epsilon: 0.050 - Beta: 0.445
2025-03-06 17:13:52,147 - INFO - Episode 7600/10000 - Avg Reward: 1517.64 - Avg Max Tile: 124.16 - Epsilon: 0.050 - Beta: 0.446
2025-03-06 17:17:51,247 - INFO - Episode 7700/10000 - Avg Reward: 1620.23 - Avg Max Tile: 138.40 - Epsilon: 0.050 - Beta: 0.446
2025-03-06 17:21:32,918 - INFO - Episode 7800/10000 - Avg Reward: 1487.36 - Avg Max Tile: 120.64 - Epsilon: 0.050 - Beta: 0.447
2025-03-06 17:25:34,122 - INFO - Episode 7900/10000 - Avg Reward: 1634.19 - Avg Max Tile: 141.60 - Epsilon: 0.050 - Beta: 0.447
2025-03-06 17:29:45,700 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_8000.pt
2025-03-06 17:29:45,700 - INFO - Episode 8000/10000 - Avg Reward: 1659.10 - Avg Max Tile: 142.40 - Epsilon: 0.050 - Beta: 0.448
2025-03-06 17:29:45,701 - INFO - Episode 8000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-06 17:32:39,243 - INFO - Episode 8100/10000 - Avg Reward: 1311.94 - Avg Max Tile: 115.84 - Epsilon: 0.114 - Beta: 0.449
2025-03-06 17:36:27,564 - INFO - Episode 8199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-06 17:36:29,349 - INFO - Episode 8200/10000 - Avg Reward: 1624.64 - Avg Max Tile: 141.60 - Epsilon: 0.050 - Beta: 0.449
2025-03-06 17:40:26,136 - INFO - Episode 8300/10000 - Avg Reward: 1601.18 - Avg Max Tile: 136.96 - Epsilon: 0.050 - Beta: 0.450
2025-03-06 17:44:16,192 - INFO - Episode 8400/10000 - Avg Reward: 1647.62 - Avg Max Tile: 143.68 - Epsilon: 0.050 - Beta: 0.450
2025-03-06 17:47:59,864 - INFO - Episode 8500/10000 - Avg Reward: 1510.20 - Avg Max Tile: 126.72 - Epsilon: 0.050 - Beta: 0.451
2025-03-06 17:51:53,169 - INFO - Episode 8600/10000 - Avg Reward: 1579.37 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.452
2025-03-06 17:55:57,180 - INFO - Episode 8700/10000 - Avg Reward: 1623.38 - Avg Max Tile: 141.12 - Epsilon: 0.050 - Beta: 0.452
2025-03-06 17:59:47,395 - INFO - Episode 8800/10000 - Avg Reward: 1512.87 - Avg Max Tile: 125.12 - Epsilon: 0.050 - Beta: 0.453
2025-03-06 18:03:48,357 - INFO - Episode 8900/10000 - Avg Reward: 1583.91 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.453
2025-03-06 18:08:07,253 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_9000.pt
2025-03-06 18:08:07,255 - INFO - Episode 9000/10000 - Avg Reward: 1700.35 - Avg Max Tile: 146.24 - Epsilon: 0.050 - Beta: 0.454
2025-03-06 18:12:03,884 - INFO - Episode 9100/10000 - Avg Reward: 1616.69 - Avg Max Tile: 136.32 - Epsilon: 0.050 - Beta: 0.455
2025-03-06 18:16:09,678 - INFO - Episode 9200/10000 - Avg Reward: 1619.87 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.455
2025-03-06 18:20:02,780 - INFO - Episode 9300/10000 - Avg Reward: 1556.30 - Avg Max Tile: 131.84 - Epsilon: 0.050 - Beta: 0.456
2025-03-06 18:23:44,061 - INFO - Episode 9400/10000 - Avg Reward: 1461.27 - Avg Max Tile: 117.76 - Epsilon: 0.050 - Beta: 0.456
2025-03-06 18:27:42,722 - INFO - Episode 9500/10000 - Avg Reward: 1566.93 - Avg Max Tile: 134.72 - Epsilon: 0.050 - Beta: 0.457
2025-03-06 18:31:47,362 - INFO - Episode 9600/10000 - Avg Reward: 1649.43 - Avg Max Tile: 136.00 - Epsilon: 0.050 - Beta: 0.458
2025-03-06 18:35:46,632 - INFO - Episode 9700/10000 - Avg Reward: 1613.35 - Avg Max Tile: 137.28 - Epsilon: 0.050 - Beta: 0.458
2025-03-06 18:36:27,782 - INFO - New best score: 5545.599947214127 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 18:36:27,783 - INFO - Final board state for new best score 5545.599947214127:
[[512,   8,   4,   2],
 [256,   4,  32,   8],
 [128,  64,   8,   4],
 [ 16,   8,   4,   2]]
2025-03-06 18:39:49,857 - INFO - Episode 9800/10000 - Avg Reward: 1628.25 - Avg Max Tile: 141.76 - Epsilon: 0.050 - Beta: 0.459
2025-03-06 18:43:33,269 - INFO - Episode 9900/10000 - Avg Reward: 1587.31 - Avg Max Tile: 135.04 - Epsilon: 0.050 - Beta: 0.459
2025-03-06 18:47:42,222 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_10000.pt
2025-03-06 18:47:42,222 - INFO - Episode 10000/10000 - Avg Reward: 1641.21 - Avg Max Tile: 140.16 - Epsilon: 0.050 - Beta: 0.460
2025-03-06 18:47:49,066 - INFO - Training completed - Final model saved to models\dueling_dqn\dueling_dqn_per_final.pt
2025-03-06 18:47:49,067 - INFO - Highest tile achieved during training: 512
2025-03-06 18:48:44,740 - INFO - Loading model from models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-06 18:48:48,843 - INFO - Creating enhanced MCTS agent with 200 simulations
2025-03-06 18:48:48,843 - INFO - 
Evaluating regular agent...
2025-03-06 18:48:50,357 - INFO - Game 1/20 completed: Max Tile = 256
2025-03-06 18:48:51,892 - INFO - Game 2/20 completed: Max Tile = 256
2025-03-06 18:48:53,827 - INFO - Game 3/20 completed: Max Tile = 256
2025-03-06 18:48:54,548 - INFO - Game 4/20 completed: Max Tile = 64
2025-03-06 18:48:54,946 - INFO - Game 5/20 completed: Max Tile = 32
2025-03-06 18:48:55,501 - INFO - Game 6/20 completed: Max Tile = 32
2025-03-06 18:48:57,052 - INFO - Game 7/20 completed: Max Tile = 256
2025-03-06 18:48:57,927 - INFO - Game 8/20 completed: Max Tile = 128
2025-03-06 18:48:59,178 - INFO - Game 9/20 completed: Max Tile = 128
2025-03-06 18:49:00,308 - INFO - Game 10/20 completed: Max Tile = 256
2025-03-06 18:49:01,126 - INFO - Game 11/20 completed: Max Tile = 128
2025-03-06 18:49:02,328 - INFO - Game 12/20 completed: Max Tile = 128
2025-03-06 18:49:02,980 - INFO - Game 13/20 completed: Max Tile = 64
2025-03-06 18:49:03,690 - INFO - Game 14/20 completed: Max Tile = 64
2025-03-06 18:49:04,865 - INFO - Game 15/20 completed: Max Tile = 256
2025-03-06 18:49:05,612 - INFO - Game 16/20 completed: Max Tile = 64
2025-03-06 18:49:06,467 - INFO - Game 17/20 completed: Max Tile = 128
2025-03-06 18:49:08,368 - INFO - Game 18/20 completed: Max Tile = 256
2025-03-06 18:49:09,740 - INFO - Game 19/20 completed: Max Tile = 256
2025-03-06 18:49:10,776 - INFO - Game 20/20 completed: Max Tile = 128
2025-03-06 18:49:10,777 - INFO - ========================================
2025-03-06 18:49:10,777 - INFO - Evaluation over 20 games:
2025-03-06 18:49:10,777 - INFO - Average Max Tile: 156.8
2025-03-06 18:49:10,778 - INFO - Average Score: 1774.2
2025-03-06 18:49:10,778 - INFO - Average Steps: 158.3
2025-03-06 18:49:10,778 - INFO - Best Max Tile: 256
2025-03-06 18:49:10,779 - INFO - Tile distribution:
2025-03-06 18:49:10,779 - INFO -   32: 2 games (10.0%)
2025-03-06 18:49:10,779 - INFO -   64: 4 games (20.0%)
2025-03-06 18:49:10,780 - INFO -   128: 6 games (30.0%)
2025-03-06 18:49:10,780 - INFO -   256: 8 games (40.0%)
2025-03-06 18:49:10,781 - INFO - Average steps to achieve tile:
2025-03-06 18:49:10,781 - INFO - 
Evaluating enhanced MCTS agent...
2025-03-06 19:02:00,288 - INFO - Game 1/20 completed: Max Tile = 64
2025-03-06 20:10:07,195 - INFO - Game 2/20 completed: Max Tile = 256
2025-03-06 20:27:58,787 - INFO - Game 3/20 completed: Max Tile = 128
2025-03-06 20:34:32,129 - INFO - Game 4/20 completed: Max Tile = 64
2025-03-06 21:05:18,327 - INFO - Game 5/20 completed: Max Tile = 128
2025-03-06 21:46:45,036 - INFO - Game 6/20 completed: Max Tile = 256
2025-03-06 22:10:20,460 - INFO - Game 7/20 completed: Max Tile = 128
2025-03-07 12:12:28,964 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_10000.pt
2025-03-07 12:12:30,829 - INFO - Resuming from episode 10000
2025-03-07 12:12:30,829 - INFO - Previous best score: 5545.599947214127
2025-03-07 12:12:30,829 - INFO - Previous highest tile: 512
2025-03-07 12:12:30,829 - INFO - Current epsilon: 0.050
2025-03-07 12:12:30,830 - INFO - Starting training with device: cuda
2025-03-07 12:12:30,830 - INFO - Model parameters: 3394954
2025-03-07 12:12:36,967 - INFO - Training completed - Final model saved to models\dueling_dqn\dueling_dqn_per_final.pt
2025-03-07 12:12:36,967 - INFO - Highest tile achieved during training: 512
2025-03-07 12:12:58,259 - INFO - Loading checkpoint from models\dueling_dqn\dueling_dqn_per_10000.pt
2025-03-07 12:13:00,053 - INFO - Resuming from episode 10000
2025-03-07 12:13:00,054 - INFO - Previous best score: 5545.599947214127
2025-03-07 12:13:00,054 - INFO - Previous highest tile: 512
2025-03-07 12:13:00,054 - INFO - Current epsilon: 0.050
2025-03-07 12:13:00,054 - INFO - Starting training with device: cuda
2025-03-07 12:13:00,055 - INFO - Model parameters: 3394954
2025-03-07 12:13:00,055 - INFO - Episode 10000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 12:15:49,175 - INFO - Episode 10100/25000 - Avg Reward: 1259.08 - Avg Max Tile: 106.24 - Epsilon: 0.115 - Beta: 0.461
2025-03-07 12:19:13,456 - INFO - Episode 10199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 12:19:15,415 - INFO - Episode 10200/25000 - Avg Reward: 1468.69 - Avg Max Tile: 123.04 - Epsilon: 0.050 - Beta: 0.461
2025-03-07 12:23:10,306 - INFO - Episode 10300/25000 - Avg Reward: 1616.82 - Avg Max Tile: 140.16 - Epsilon: 0.050 - Beta: 0.462
2025-03-07 12:26:55,793 - INFO - Episode 10400/25000 - Avg Reward: 1569.70 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.462
2025-03-07 12:30:44,204 - INFO - Episode 10500/25000 - Avg Reward: 1641.32 - Avg Max Tile: 140.00 - Epsilon: 0.050 - Beta: 0.463
2025-03-07 12:34:25,795 - INFO - Episode 10600/25000 - Avg Reward: 1522.80 - Avg Max Tile: 129.28 - Epsilon: 0.050 - Beta: 0.464
2025-03-07 12:38:17,250 - INFO - Episode 10700/25000 - Avg Reward: 1620.55 - Avg Max Tile: 137.28 - Epsilon: 0.050 - Beta: 0.464
2025-03-07 12:42:05,901 - INFO - Episode 10800/25000 - Avg Reward: 1576.68 - Avg Max Tile: 131.84 - Epsilon: 0.050 - Beta: 0.465
2025-03-07 12:45:46,978 - INFO - Episode 10900/25000 - Avg Reward: 1517.89 - Avg Max Tile: 126.88 - Epsilon: 0.050 - Beta: 0.465
2025-03-07 12:49:38,452 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_11000.pt
2025-03-07 12:49:38,453 - INFO - Episode 11000/25000 - Avg Reward: 1567.57 - Avg Max Tile: 129.28 - Epsilon: 0.050 - Beta: 0.466
2025-03-07 12:53:17,127 - INFO - Episode 11100/25000 - Avg Reward: 1514.39 - Avg Max Tile: 129.60 - Epsilon: 0.050 - Beta: 0.467
2025-03-07 12:56:56,900 - INFO - Episode 11200/25000 - Avg Reward: 1510.03 - Avg Max Tile: 129.92 - Epsilon: 0.050 - Beta: 0.467
2025-03-07 13:00:30,298 - INFO - Episode 11300/25000 - Avg Reward: 1535.35 - Avg Max Tile: 131.68 - Epsilon: 0.050 - Beta: 0.468
2025-03-07 13:04:21,882 - INFO - Episode 11400/25000 - Avg Reward: 1641.02 - Avg Max Tile: 145.76 - Epsilon: 0.050 - Beta: 0.468
2025-03-07 13:08:07,645 - INFO - Episode 11500/25000 - Avg Reward: 1577.99 - Avg Max Tile: 136.64 - Epsilon: 0.050 - Beta: 0.469
2025-03-07 13:11:42,915 - INFO - Episode 11600/25000 - Avg Reward: 1494.60 - Avg Max Tile: 118.08 - Epsilon: 0.050 - Beta: 0.470
2025-03-07 13:15:21,591 - INFO - Episode 11700/25000 - Avg Reward: 1565.12 - Avg Max Tile: 128.80 - Epsilon: 0.050 - Beta: 0.470
2025-03-07 13:19:16,252 - INFO - Episode 11800/25000 - Avg Reward: 1632.73 - Avg Max Tile: 140.00 - Epsilon: 0.050 - Beta: 0.471
2025-03-07 13:23:04,225 - INFO - Episode 11900/25000 - Avg Reward: 1525.00 - Avg Max Tile: 129.76 - Epsilon: 0.050 - Beta: 0.471
2025-03-07 13:27:03,658 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_12000.pt
2025-03-07 13:27:03,659 - INFO - Episode 12000/25000 - Avg Reward: 1605.17 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.472
2025-03-07 13:27:03,659 - INFO - Episode 12000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 13:30:03,786 - INFO - Episode 12100/25000 - Avg Reward: 1388.86 - Avg Max Tile: 123.84 - Epsilon: 0.100 - Beta: 0.473
2025-03-07 13:33:36,120 - INFO - Episode 12199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 13:33:38,881 - INFO - Episode 12200/25000 - Avg Reward: 1547.80 - Avg Max Tile: 127.68 - Epsilon: 0.050 - Beta: 0.473
2025-03-07 13:37:32,042 - INFO - Episode 12300/25000 - Avg Reward: 1586.63 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.474
2025-03-07 13:41:05,585 - INFO - Episode 12400/25000 - Avg Reward: 1487.49 - Avg Max Tile: 122.40 - Epsilon: 0.050 - Beta: 0.474
2025-03-07 13:44:52,266 - INFO - Episode 12500/25000 - Avg Reward: 1616.59 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.475
2025-03-07 13:48:30,492 - INFO - Episode 12600/25000 - Avg Reward: 1486.68 - Avg Max Tile: 121.60 - Epsilon: 0.050 - Beta: 0.476
2025-03-07 13:52:23,910 - INFO - Episode 12700/25000 - Avg Reward: 1595.62 - Avg Max Tile: 137.92 - Epsilon: 0.050 - Beta: 0.476
2025-03-07 13:56:26,742 - INFO - Episode 12800/25000 - Avg Reward: 1692.43 - Avg Max Tile: 141.76 - Epsilon: 0.050 - Beta: 0.477
2025-03-07 13:59:59,804 - INFO - Episode 12900/25000 - Avg Reward: 1538.50 - Avg Max Tile: 128.00 - Epsilon: 0.050 - Beta: 0.477
2025-03-07 14:04:00,337 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_13000.pt
2025-03-07 14:04:00,337 - INFO - Episode 13000/25000 - Avg Reward: 1580.73 - Avg Max Tile: 134.40 - Epsilon: 0.050 - Beta: 0.478
2025-03-07 14:07:32,265 - INFO - Episode 13100/25000 - Avg Reward: 1499.75 - Avg Max Tile: 125.12 - Epsilon: 0.050 - Beta: 0.479
2025-03-07 14:11:22,470 - INFO - Episode 13200/25000 - Avg Reward: 1607.29 - Avg Max Tile: 137.12 - Epsilon: 0.050 - Beta: 0.479
2025-03-07 14:14:55,664 - INFO - Episode 13300/25000 - Avg Reward: 1510.39 - Avg Max Tile: 125.60 - Epsilon: 0.050 - Beta: 0.480
2025-03-07 14:18:35,922 - INFO - Episode 13400/25000 - Avg Reward: 1552.26 - Avg Max Tile: 136.64 - Epsilon: 0.050 - Beta: 0.480
2025-03-07 14:22:32,241 - INFO - Episode 13500/25000 - Avg Reward: 1642.82 - Avg Max Tile: 140.16 - Epsilon: 0.050 - Beta: 0.481
2025-03-07 14:26:06,237 - INFO - Episode 13600/25000 - Avg Reward: 1491.36 - Avg Max Tile: 125.92 - Epsilon: 0.050 - Beta: 0.482
2025-03-07 14:30:18,413 - INFO - Episode 13700/25000 - Avg Reward: 1717.60 - Avg Max Tile: 150.72 - Epsilon: 0.050 - Beta: 0.482
2025-03-07 14:34:17,662 - INFO - Episode 13800/25000 - Avg Reward: 1606.93 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.483
2025-03-07 14:38:17,217 - INFO - Episode 13900/25000 - Avg Reward: 1632.40 - Avg Max Tile: 143.04 - Epsilon: 0.050 - Beta: 0.483
2025-03-07 14:42:26,897 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_14000.pt
2025-03-07 14:42:26,897 - INFO - Episode 14000/25000 - Avg Reward: 1661.69 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.484
2025-03-07 14:42:26,898 - INFO - Episode 14000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 14:45:17,490 - INFO - Episode 14100/25000 - Avg Reward: 1298.54 - Avg Max Tile: 111.04 - Epsilon: 0.113 - Beta: 0.485
2025-03-07 14:48:58,879 - INFO - Episode 14199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 14:49:00,172 - INFO - Episode 14200/25000 - Avg Reward: 1496.97 - Avg Max Tile: 126.40 - Epsilon: 0.050 - Beta: 0.485
2025-03-07 14:52:38,075 - INFO - Episode 14300/25000 - Avg Reward: 1472.85 - Avg Max Tile: 123.84 - Epsilon: 0.050 - Beta: 0.486
2025-03-07 14:56:31,773 - INFO - Episode 14400/25000 - Avg Reward: 1563.07 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.486
2025-03-07 15:00:24,594 - INFO - Episode 14500/25000 - Avg Reward: 1620.97 - Avg Max Tile: 136.48 - Epsilon: 0.050 - Beta: 0.487
2025-03-07 15:04:18,440 - INFO - Episode 14600/25000 - Avg Reward: 1627.00 - Avg Max Tile: 135.36 - Epsilon: 0.050 - Beta: 0.488
2025-03-07 15:08:22,723 - INFO - Episode 14700/25000 - Avg Reward: 1624.92 - Avg Max Tile: 138.72 - Epsilon: 0.050 - Beta: 0.488
2025-03-07 15:12:32,773 - INFO - Episode 14800/25000 - Avg Reward: 1683.97 - Avg Max Tile: 143.36 - Epsilon: 0.050 - Beta: 0.489
2025-03-07 15:16:16,472 - INFO - Episode 14900/25000 - Avg Reward: 1467.71 - Avg Max Tile: 119.36 - Epsilon: 0.050 - Beta: 0.489
2025-03-07 15:20:18,489 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_15000.pt
2025-03-07 15:20:18,489 - INFO - Episode 15000/25000 - Avg Reward: 1604.75 - Avg Max Tile: 137.28 - Epsilon: 0.050 - Beta: 0.490
2025-03-07 15:24:04,381 - INFO - Episode 15100/25000 - Avg Reward: 1574.23 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.491
2025-03-07 15:27:58,270 - INFO - Episode 15200/25000 - Avg Reward: 1594.25 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.491
2025-03-07 15:31:26,462 - INFO - Episode 15300/25000 - Avg Reward: 1434.01 - Avg Max Tile: 117.12 - Epsilon: 0.050 - Beta: 0.492
2025-03-07 15:35:11,270 - INFO - Episode 15400/25000 - Avg Reward: 1559.84 - Avg Max Tile: 131.68 - Epsilon: 0.050 - Beta: 0.492
2025-03-07 15:39:11,000 - INFO - Episode 15500/25000 - Avg Reward: 1575.20 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.493
2025-03-07 15:42:58,670 - INFO - Episode 15600/25000 - Avg Reward: 1529.22 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.494
2025-03-07 15:46:57,420 - INFO - Episode 15700/25000 - Avg Reward: 1632.25 - Avg Max Tile: 143.04 - Epsilon: 0.050 - Beta: 0.494
2025-03-07 15:50:51,153 - INFO - Episode 15800/25000 - Avg Reward: 1567.82 - Avg Max Tile: 134.40 - Epsilon: 0.050 - Beta: 0.495
2025-03-07 15:55:04,303 - INFO - Episode 15900/25000 - Avg Reward: 1653.14 - Avg Max Tile: 142.08 - Epsilon: 0.050 - Beta: 0.495
2025-03-07 15:58:51,451 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_16000.pt
2025-03-07 15:58:51,452 - INFO - Episode 16000/25000 - Avg Reward: 1516.40 - Avg Max Tile: 125.76 - Epsilon: 0.050 - Beta: 0.496
2025-03-07 15:58:51,452 - INFO - Episode 16000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 16:01:48,366 - INFO - Episode 16100/25000 - Avg Reward: 1333.17 - Avg Max Tile: 115.36 - Epsilon: 0.107 - Beta: 0.497
2025-03-07 16:05:42,290 - INFO - Episode 16199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 16:05:43,783 - INFO - Episode 16200/25000 - Avg Reward: 1630.95 - Avg Max Tile: 144.96 - Epsilon: 0.050 - Beta: 0.497
2025-03-07 16:09:38,855 - INFO - Episode 16300/25000 - Avg Reward: 1639.83 - Avg Max Tile: 140.48 - Epsilon: 0.050 - Beta: 0.498
2025-03-07 16:13:26,548 - INFO - Episode 16400/25000 - Avg Reward: 1639.13 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.498
2025-03-07 16:17:16,863 - INFO - Episode 16500/25000 - Avg Reward: 1581.18 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.499
2025-03-07 16:20:58,955 - INFO - Episode 16600/25000 - Avg Reward: 1517.42 - Avg Max Tile: 128.80 - Epsilon: 0.050 - Beta: 0.500
2025-03-07 16:25:04,975 - INFO - Episode 16700/25000 - Avg Reward: 1691.68 - Avg Max Tile: 150.40 - Epsilon: 0.050 - Beta: 0.500
2025-03-07 16:28:55,167 - INFO - Episode 16800/25000 - Avg Reward: 1529.64 - Avg Max Tile: 127.36 - Epsilon: 0.050 - Beta: 0.501
2025-03-07 16:32:53,734 - INFO - Episode 16900/25000 - Avg Reward: 1660.25 - Avg Max Tile: 142.56 - Epsilon: 0.050 - Beta: 0.501
2025-03-07 16:36:40,632 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_17000.pt
2025-03-07 16:36:40,632 - INFO - Episode 17000/25000 - Avg Reward: 1520.98 - Avg Max Tile: 125.76 - Epsilon: 0.050 - Beta: 0.502
2025-03-07 16:40:27,556 - INFO - Episode 17100/25000 - Avg Reward: 1588.21 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.503
2025-03-07 16:44:13,846 - INFO - Episode 17200/25000 - Avg Reward: 1522.57 - Avg Max Tile: 129.28 - Epsilon: 0.050 - Beta: 0.503
2025-03-07 16:48:08,944 - INFO - Episode 17300/25000 - Avg Reward: 1619.86 - Avg Max Tile: 137.92 - Epsilon: 0.050 - Beta: 0.504
2025-03-07 16:52:06,186 - INFO - Episode 17400/25000 - Avg Reward: 1633.65 - Avg Max Tile: 136.64 - Epsilon: 0.050 - Beta: 0.504
2025-03-07 16:55:59,280 - INFO - Episode 17500/25000 - Avg Reward: 1590.05 - Avg Max Tile: 137.44 - Epsilon: 0.050 - Beta: 0.505
2025-03-07 16:59:47,873 - INFO - Episode 17600/25000 - Avg Reward: 1523.20 - Avg Max Tile: 128.00 - Epsilon: 0.050 - Beta: 0.506
2025-03-07 17:03:40,947 - INFO - Episode 17700/25000 - Avg Reward: 1564.62 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.506
2025-03-07 17:07:48,511 - INFO - Episode 17800/25000 - Avg Reward: 1662.62 - Avg Max Tile: 144.00 - Epsilon: 0.050 - Beta: 0.507
2025-03-07 17:11:19,962 - INFO - Episode 17900/25000 - Avg Reward: 1409.79 - Avg Max Tile: 113.60 - Epsilon: 0.050 - Beta: 0.507
2025-03-07 17:15:36,897 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_18000.pt
2025-03-07 17:15:36,897 - INFO - Episode 18000/25000 - Avg Reward: 1709.41 - Avg Max Tile: 147.84 - Epsilon: 0.050 - Beta: 0.508
2025-03-07 17:15:36,898 - INFO - Episode 18000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 17:18:29,822 - INFO - Episode 18100/25000 - Avg Reward: 1288.74 - Avg Max Tile: 112.32 - Epsilon: 0.112 - Beta: 0.509
2025-03-07 17:22:18,883 - INFO - Episode 18199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 17:22:21,589 - INFO - Episode 18200/25000 - Avg Reward: 1563.17 - Avg Max Tile: 134.72 - Epsilon: 0.050 - Beta: 0.509
2025-03-07 17:26:14,558 - INFO - Episode 18300/25000 - Avg Reward: 1587.10 - Avg Max Tile: 136.32 - Epsilon: 0.050 - Beta: 0.510
2025-03-07 17:30:08,849 - INFO - Episode 18400/25000 - Avg Reward: 1580.22 - Avg Max Tile: 135.04 - Epsilon: 0.050 - Beta: 0.510
2025-03-07 17:33:48,041 - INFO - Episode 18500/25000 - Avg Reward: 1472.86 - Avg Max Tile: 120.16 - Epsilon: 0.050 - Beta: 0.511
2025-03-07 17:37:45,248 - INFO - Episode 18600/25000 - Avg Reward: 1571.56 - Avg Max Tile: 133.12 - Epsilon: 0.050 - Beta: 0.512
2025-03-07 17:41:28,498 - INFO - Episode 18700/25000 - Avg Reward: 1508.19 - Avg Max Tile: 127.84 - Epsilon: 0.050 - Beta: 0.512
2025-03-07 17:45:31,000 - INFO - Episode 18800/25000 - Avg Reward: 1586.34 - Avg Max Tile: 127.68 - Epsilon: 0.050 - Beta: 0.513
2025-03-07 17:49:30,773 - INFO - Episode 18900/25000 - Avg Reward: 1573.50 - Avg Max Tile: 136.32 - Epsilon: 0.050 - Beta: 0.513
2025-03-07 17:53:30,290 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_19000.pt
2025-03-07 17:53:30,290 - INFO - Episode 19000/25000 - Avg Reward: 1567.11 - Avg Max Tile: 132.80 - Epsilon: 0.050 - Beta: 0.514
2025-03-07 17:57:26,251 - INFO - Episode 19100/25000 - Avg Reward: 1616.65 - Avg Max Tile: 137.76 - Epsilon: 0.050 - Beta: 0.515
2025-03-07 18:01:18,306 - INFO - Episode 19200/25000 - Avg Reward: 1611.19 - Avg Max Tile: 142.40 - Epsilon: 0.050 - Beta: 0.515
2025-03-07 18:05:05,296 - INFO - Episode 19300/25000 - Avg Reward: 1550.82 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.516
2025-03-07 18:08:55,748 - INFO - Episode 19400/25000 - Avg Reward: 1617.55 - Avg Max Tile: 140.32 - Epsilon: 0.050 - Beta: 0.516
2025-03-07 18:12:47,970 - INFO - Episode 19500/25000 - Avg Reward: 1540.96 - Avg Max Tile: 128.00 - Epsilon: 0.050 - Beta: 0.517
2025-03-07 18:16:40,960 - INFO - Episode 19600/25000 - Avg Reward: 1558.83 - Avg Max Tile: 131.68 - Epsilon: 0.050 - Beta: 0.518
2025-03-07 18:20:43,900 - INFO - Episode 19700/25000 - Avg Reward: 1665.46 - Avg Max Tile: 137.60 - Epsilon: 0.050 - Beta: 0.518
2025-03-07 18:24:29,242 - INFO - Episode 19800/25000 - Avg Reward: 1514.99 - Avg Max Tile: 121.60 - Epsilon: 0.050 - Beta: 0.519
2025-03-07 18:28:30,645 - INFO - Episode 19900/25000 - Avg Reward: 1654.78 - Avg Max Tile: 146.24 - Epsilon: 0.050 - Beta: 0.519
2025-03-07 18:32:28,558 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_20000.pt
2025-03-07 18:32:28,559 - INFO - Episode 20000/25000 - Avg Reward: 1558.36 - Avg Max Tile: 127.68 - Epsilon: 0.050 - Beta: 0.520
2025-03-07 18:32:28,559 - INFO - Episode 20000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 18:35:13,880 - INFO - Episode 20100/25000 - Avg Reward: 1222.09 - Avg Max Tile: 103.04 - Epsilon: 0.122 - Beta: 0.521
2025-03-07 18:38:59,112 - INFO - Episode 20199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 18:39:02,574 - INFO - Episode 20200/25000 - Avg Reward: 1507.83 - Avg Max Tile: 130.24 - Epsilon: 0.050 - Beta: 0.521
2025-03-07 18:42:57,312 - INFO - Episode 20300/25000 - Avg Reward: 1587.45 - Avg Max Tile: 133.92 - Epsilon: 0.050 - Beta: 0.522
2025-03-07 18:46:44,785 - INFO - Episode 20400/25000 - Avg Reward: 1556.72 - Avg Max Tile: 126.72 - Epsilon: 0.050 - Beta: 0.522
2025-03-07 18:50:23,319 - INFO - Episode 20500/25000 - Avg Reward: 1485.32 - Avg Max Tile: 127.52 - Epsilon: 0.050 - Beta: 0.523
2025-03-07 18:54:13,712 - INFO - Episode 20600/25000 - Avg Reward: 1536.41 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.524
2025-03-07 18:58:18,911 - INFO - Episode 20700/25000 - Avg Reward: 1699.29 - Avg Max Tile: 148.48 - Epsilon: 0.050 - Beta: 0.524
2025-03-07 19:02:34,872 - INFO - Episode 20800/25000 - Avg Reward: 1747.52 - Avg Max Tile: 149.76 - Epsilon: 0.050 - Beta: 0.525
2025-03-07 19:06:25,082 - INFO - Episode 20900/25000 - Avg Reward: 1527.68 - Avg Max Tile: 128.00 - Epsilon: 0.050 - Beta: 0.525
2025-03-07 19:10:34,871 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_21000.pt
2025-03-07 19:10:34,871 - INFO - Episode 21000/25000 - Avg Reward: 1590.82 - Avg Max Tile: 136.64 - Epsilon: 0.050 - Beta: 0.526
2025-03-07 19:14:27,430 - INFO - Episode 21100/25000 - Avg Reward: 1615.30 - Avg Max Tile: 139.20 - Epsilon: 0.050 - Beta: 0.527
2025-03-07 19:18:36,899 - INFO - Episode 21200/25000 - Avg Reward: 1682.85 - Avg Max Tile: 143.68 - Epsilon: 0.050 - Beta: 0.527
2025-03-07 19:22:30,213 - INFO - Episode 21300/25000 - Avg Reward: 1547.68 - Avg Max Tile: 128.00 - Epsilon: 0.050 - Beta: 0.528
2025-03-07 19:26:19,090 - INFO - Episode 21400/25000 - Avg Reward: 1497.01 - Avg Max Tile: 127.04 - Epsilon: 0.050 - Beta: 0.528
2025-03-07 19:30:11,057 - INFO - Episode 21500/25000 - Avg Reward: 1531.28 - Avg Max Tile: 128.16 - Epsilon: 0.050 - Beta: 0.529
2025-03-07 19:33:50,146 - INFO - Episode 21600/25000 - Avg Reward: 1545.92 - Avg Max Tile: 125.60 - Epsilon: 0.050 - Beta: 0.530
2025-03-07 19:37:46,921 - INFO - Episode 21700/25000 - Avg Reward: 1536.76 - Avg Max Tile: 128.32 - Epsilon: 0.050 - Beta: 0.530
2025-03-07 19:41:49,359 - INFO - Episode 21800/25000 - Avg Reward: 1657.26 - Avg Max Tile: 136.72 - Epsilon: 0.050 - Beta: 0.531
2025-03-07 19:45:44,757 - INFO - Episode 21900/25000 - Avg Reward: 1603.90 - Avg Max Tile: 138.88 - Epsilon: 0.050 - Beta: 0.531
2025-03-07 19:49:52,735 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_22000.pt
2025-03-07 19:49:52,736 - INFO - Episode 22000/25000 - Avg Reward: 1686.73 - Avg Max Tile: 144.32 - Epsilon: 0.050 - Beta: 0.532
2025-03-07 19:49:52,736 - INFO - Episode 22000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 19:52:41,413 - INFO - Episode 22100/25000 - Avg Reward: 1260.84 - Avg Max Tile: 105.76 - Epsilon: 0.115 - Beta: 0.533
2025-03-07 19:56:17,400 - INFO - Episode 22199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 19:56:19,121 - INFO - Episode 22200/25000 - Avg Reward: 1541.64 - Avg Max Tile: 125.44 - Epsilon: 0.050 - Beta: 0.533
2025-03-07 19:59:53,537 - INFO - Episode 22300/25000 - Avg Reward: 1423.29 - Avg Max Tile: 115.36 - Epsilon: 0.050 - Beta: 0.534
2025-03-07 20:03:38,254 - INFO - Episode 22400/25000 - Avg Reward: 1533.22 - Avg Max Tile: 130.24 - Epsilon: 0.050 - Beta: 0.534
2025-03-07 20:07:48,178 - INFO - Episode 22500/25000 - Avg Reward: 1719.61 - Avg Max Tile: 149.44 - Epsilon: 0.050 - Beta: 0.535
2025-03-07 20:11:51,540 - INFO - Episode 22600/25000 - Avg Reward: 1668.71 - Avg Max Tile: 144.64 - Epsilon: 0.050 - Beta: 0.536
2025-03-07 20:15:32,218 - INFO - Episode 22700/25000 - Avg Reward: 1538.34 - Avg Max Tile: 129.44 - Epsilon: 0.050 - Beta: 0.536
2025-03-07 20:19:29,400 - INFO - Episode 22800/25000 - Avg Reward: 1613.81 - Avg Max Tile: 132.48 - Epsilon: 0.050 - Beta: 0.537
2025-03-07 20:23:05,733 - INFO - Episode 22900/25000 - Avg Reward: 1554.37 - Avg Max Tile: 128.16 - Epsilon: 0.050 - Beta: 0.537
2025-03-07 20:27:09,203 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_23000.pt
2025-03-07 20:27:09,203 - INFO - Episode 23000/25000 - Avg Reward: 1619.63 - Avg Max Tile: 137.44 - Epsilon: 0.050 - Beta: 0.538
2025-03-07 20:30:47,696 - INFO - Episode 23100/25000 - Avg Reward: 1581.03 - Avg Max Tile: 141.28 - Epsilon: 0.050 - Beta: 0.539
2025-03-07 20:34:40,007 - INFO - Episode 23200/25000 - Avg Reward: 1570.56 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.539
2025-03-07 20:38:24,663 - INFO - Episode 23300/25000 - Avg Reward: 1566.26 - Avg Max Tile: 134.24 - Epsilon: 0.050 - Beta: 0.540
2025-03-07 20:42:05,418 - INFO - Episode 23400/25000 - Avg Reward: 1553.88 - Avg Max Tile: 131.36 - Epsilon: 0.050 - Beta: 0.540
2025-03-07 20:46:01,405 - INFO - Episode 23500/25000 - Avg Reward: 1560.63 - Avg Max Tile: 134.08 - Epsilon: 0.050 - Beta: 0.541
2025-03-07 20:49:48,436 - INFO - Episode 23600/25000 - Avg Reward: 1595.67 - Avg Max Tile: 134.72 - Epsilon: 0.050 - Beta: 0.542
2025-03-07 20:53:20,833 - INFO - Episode 23700/25000 - Avg Reward: 1465.83 - Avg Max Tile: 122.24 - Epsilon: 0.050 - Beta: 0.542
2025-03-07 20:56:59,518 - INFO - Episode 23800/25000 - Avg Reward: 1539.66 - Avg Max Tile: 129.60 - Epsilon: 0.050 - Beta: 0.543
2025-03-07 21:00:30,327 - INFO - Episode 23900/25000 - Avg Reward: 1509.32 - Avg Max Tile: 121.60 - Epsilon: 0.050 - Beta: 0.543
2025-03-07 21:04:32,215 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_24000.pt
2025-03-07 21:04:32,216 - INFO - Episode 24000/25000 - Avg Reward: 1659.66 - Avg Max Tile: 141.76 - Epsilon: 0.050 - Beta: 0.544
2025-03-07 21:04:32,216 - INFO - Episode 24000: Reset epsilon to 0.5, learning rate to 2.5e-05, and batch size to 512
2025-03-07 21:07:16,627 - INFO - Episode 24100/25000 - Avg Reward: 1230.65 - Avg Max Tile: 103.84 - Epsilon: 0.119 - Beta: 0.545
2025-03-07 21:10:46,096 - INFO - Episode 24199: Returning to normal epsilon decay rate with learning rate 5e-05 and batch size 1024
2025-03-07 21:10:47,136 - INFO - Episode 24200/25000 - Avg Reward: 1501.32 - Avg Max Tile: 123.84 - Epsilon: 0.050 - Beta: 0.545
2025-03-07 21:14:28,293 - INFO - Episode 24300/25000 - Avg Reward: 1561.44 - Avg Max Tile: 132.80 - Epsilon: 0.050 - Beta: 0.546
2025-03-07 21:18:15,730 - INFO - Episode 24400/25000 - Avg Reward: 1623.55 - Avg Max Tile: 136.64 - Epsilon: 0.050 - Beta: 0.546
2025-03-07 21:21:55,814 - INFO - Episode 24500/25000 - Avg Reward: 1579.06 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.547
2025-03-07 21:25:53,142 - INFO - Episode 24600/25000 - Avg Reward: 1680.78 - Avg Max Tile: 141.12 - Epsilon: 0.050 - Beta: 0.548
2025-03-07 21:29:26,149 - INFO - Episode 24700/25000 - Avg Reward: 1518.04 - Avg Max Tile: 126.24 - Epsilon: 0.050 - Beta: 0.548
2025-03-07 21:33:16,309 - INFO - Episode 24800/25000 - Avg Reward: 1596.30 - Avg Max Tile: 136.96 - Epsilon: 0.050 - Beta: 0.549
2025-03-07 21:37:02,724 - INFO - Episode 24900/25000 - Avg Reward: 1551.93 - Avg Max Tile: 126.40 - Epsilon: 0.050 - Beta: 0.549
2025-03-07 21:40:51,356 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_25000.pt
2025-03-07 21:40:51,357 - INFO - Episode 25000/25000 - Avg Reward: 1559.42 - Avg Max Tile: 128.48 - Epsilon: 0.050 - Beta: 0.550
2025-03-07 21:40:58,007 - INFO - Training completed - Final model saved to models\dueling_dqn\dueling_dqn_per_final.pt
2025-03-07 21:40:58,008 - INFO - Highest tile achieved during training: 512
2025-03-07 21:46:36,776 - INFO - Starting training with device: cuda
2025-03-07 21:46:36,777 - INFO - Model parameters: 3394954
2025-03-07 21:46:37,022 - INFO - New best score: 983.5999915599823 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:46:37,022 - INFO - Final board state for new best score 983.5999915599823:
[[ 4, 32,  4,  2],
 [ 8, 64,  8,  4],
 [ 4, 32,  2,  8],
 [ 2, 16,  8,  2]]
2025-03-07 21:46:37,281 - INFO - New highest tile achieved: 128 (Episode 2)
2025-03-07 21:46:37,282 - INFO - Final board state for new max tile 128:
[[  2,   4,   2,   8],
 [  8,   2,   8,  16],
 [  2, 128,  64,   4],
 [  8,   2,   8,   2]]
2025-03-07 21:46:37,330 - INFO - New best score: 1206.3999811410904 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:46:37,330 - INFO - Final board state for new best score 1206.3999811410904:
[[  2,   4,   2,   8],
 [  8,   2,   8,  16],
 [  2, 128,  64,   4],
 [  8,   2,   8,   2]]
2025-03-07 21:46:38,411 - INFO - New best score: 1638.9999731779099 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:46:38,412 - INFO - Final board state for new best score 1638.9999731779099:
[[  2,  16, 128,   8],
 [  4, 128,  64,   2],
 [ 16,   2,   8,   4],
 [  2,   8,   4,   2]]
2025-03-07 21:46:39,073 - INFO - New highest tile achieved: 256 (Episode 7)
2025-03-07 21:46:39,074 - INFO - Final board state for new max tile 256:
[[  2,   8,  16,   4],
 [  4, 256,  32,   2],
 [  8, 128,   4,  16],
 [  2,   4,  16,   4]]
2025-03-07 21:46:39,137 - INFO - New best score: 2164.3999650478363 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:46:39,138 - INFO - Final board state for new best score 2164.3999650478363:
[[  2,   8,  16,   4],
 [  4, 256,  32,   2],
 [  8, 128,   4,  16],
 [  2,   4,  16,   4]]
2025-03-07 21:46:40,355 - INFO - New best score: 2258.3999655246735 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:46:40,356 - INFO - Final board state for new best score 2258.3999655246735:
[[  2,   4,  16,   4],
 [  8, 128, 256,  16],
 [  4,   8,  64,   8],
 [  2,   4,   8,   4]]
2025-03-07 21:48:19,309 - INFO - New best score: 2293.799989938736 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:48:19,310 - INFO - Final board state for new best score 2293.799989938736:
[[ 32,   8,   4,   2],
 [  2,  16,   2,   8],
 [ 64, 256,  32,   4],
 [  8,   2,   8,   2]]
2025-03-07 21:48:30,618 - INFO - Episode 100/10000 - Avg Reward: 1243.44 - Avg Max Tile: 110.40 - Epsilon: 0.274 - Beta: 0.401
2025-03-07 21:48:36,356 - INFO - New best score: 2533.1999727487564 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:48:36,357 - INFO - Final board state for new best score 2533.1999727487564:
[[  2,  16,   4,   2],
 [128,  64,   8,   4],
 [ 32,   4, 256,   8],
 [  8,   2,   8,   2]]
2025-03-07 21:49:48,866 - INFO - New best score: 2780.7999683618546 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:49:48,867 - INFO - Final board state for new best score 2780.7999683618546:
[[  2, 256,  32,  16],
 [128,   8,   2,   8],
 [  8,  64,  32,   4],
 [  2,   8,   4,   2]]
2025-03-07 21:50:18,675 - INFO - New best score: 3097.3999705314636 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:50:18,675 - INFO - Final board state for new best score 3097.3999705314636:
[[256,  64,  32,   8],
 [128,  32,  16,   4],
 [ 64,   8,   4,   2],
 [  8,   4,   2,   4]]
2025-03-07 21:51:15,495 - INFO - Episode 200/10000 - Avg Reward: 1360.38 - Avg Max Tile: 112.96 - Epsilon: 0.053 - Beta: 0.401
2025-03-07 21:53:13,890 - INFO - New highest tile achieved: 512 (Episode 262)
2025-03-07 21:53:13,891 - INFO - Final board state for new max tile 512:
[[  2, 128,   2,  16],
 [512,  64,  32,   8],
 [ 16,  32,  16,   4],
 [  2,  16,   4,   2]]
2025-03-07 21:53:14,913 - INFO - New best score: 4311.999950766563 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:53:14,914 - INFO - Final board state for new best score 4311.999950766563:
[[  2, 128,   2,  16],
 [512,  64,  32,   8],
 [ 16,  32,  16,   4],
 [  2,  16,   4,   2]]
2025-03-07 21:54:31,129 - INFO - Episode 300/10000 - Avg Reward: 1635.23 - Avg Max Tile: 142.72 - Epsilon: 0.050 - Beta: 0.402
2025-03-07 21:57:13,338 - INFO - New best score: 4848.199961185455 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-07 21:57:13,338 - INFO - Final board state for new best score 4848.199961185455:
[[ 64,   2,  32,  16],
 [512, 128,  16,   8],
 [ 16,  64,   8,   4],
 [  4,   2,  16,   2]]
2025-03-07 21:57:58,390 - INFO - Episode 400/10000 - Avg Reward: 1691.74 - Avg Max Tile: 144.64 - Epsilon: 0.050 - Beta: 0.402
2025-03-07 22:01:15,125 - INFO - Episode 500/10000 - Avg Reward: 1577.04 - Avg Max Tile: 132.00 - Epsilon: 0.050 - Beta: 0.403
2025-03-07 22:04:26,024 - INFO - Episode 600/10000 - Avg Reward: 1514.90 - Avg Max Tile: 130.08 - Epsilon: 0.050 - Beta: 0.404
2025-03-07 22:07:42,615 - INFO - Episode 700/10000 - Avg Reward: 1569.14 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.404
2025-03-07 22:11:08,409 - INFO - Episode 800/10000 - Avg Reward: 1649.69 - Avg Max Tile: 137.92 - Epsilon: 0.050 - Beta: 0.405
2025-03-07 22:14:38,117 - INFO - Episode 900/10000 - Avg Reward: 1596.82 - Avg Max Tile: 136.08 - Epsilon: 0.050 - Beta: 0.405
2025-03-07 22:18:00,668 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_1000.pt
2025-03-07 22:18:00,668 - INFO - Episode 1000/10000 - Avg Reward: 1581.22 - Avg Max Tile: 138.56 - Epsilon: 0.050 - Beta: 0.406
2025-03-07 22:21:21,910 - INFO - Episode 1100/10000 - Avg Reward: 1662.45 - Avg Max Tile: 144.64 - Epsilon: 0.050 - Beta: 0.407
2025-03-07 22:25:00,028 - INFO - Episode 1200/10000 - Avg Reward: 1634.83 - Avg Max Tile: 144.96 - Epsilon: 0.050 - Beta: 0.407
2025-03-07 22:28:30,905 - INFO - Episode 1300/10000 - Avg Reward: 1571.38 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.408
2025-03-07 22:32:25,053 - INFO - Episode 1400/10000 - Avg Reward: 1744.71 - Avg Max Tile: 157.44 - Epsilon: 0.050 - Beta: 0.408
2025-03-07 22:35:50,997 - INFO - Episode 1500/10000 - Avg Reward: 1489.64 - Avg Max Tile: 121.44 - Epsilon: 0.050 - Beta: 0.409
2025-03-07 22:39:20,971 - INFO - Episode 1600/10000 - Avg Reward: 1577.14 - Avg Max Tile: 136.96 - Epsilon: 0.050 - Beta: 0.410
2025-03-07 22:42:38,219 - INFO - Episode 1700/10000 - Avg Reward: 1499.97 - Avg Max Tile: 124.80 - Epsilon: 0.050 - Beta: 0.410
2025-03-07 22:46:05,170 - INFO - Episode 1800/10000 - Avg Reward: 1503.49 - Avg Max Tile: 126.24 - Epsilon: 0.050 - Beta: 0.411
2025-03-07 22:49:30,386 - INFO - Episode 1900/10000 - Avg Reward: 1530.64 - Avg Max Tile: 124.16 - Epsilon: 0.050 - Beta: 0.411
2025-03-07 22:53:02,842 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_2000.pt
2025-03-07 22:53:02,843 - INFO - Episode 2000/10000 - Avg Reward: 1530.31 - Avg Max Tile: 127.04 - Epsilon: 0.050 - Beta: 0.412
2025-03-07 22:53:02,843 - INFO - Episode 2000: Reset epsilon to 0.5, learning rate to 1e-05, and batch size to 1024
2025-03-07 22:55:50,595 - INFO - Episode 2100/10000 - Avg Reward: 1345.94 - Avg Max Tile: 117.12 - Epsilon: 0.105 - Beta: 0.413
2025-03-07 22:59:12,231 - INFO - Episode 2199: Returning to normal epsilon decay rate with learning rate 2e-05 and batch size 2048
2025-03-07 22:59:14,153 - INFO - Episode 2200/10000 - Avg Reward: 1530.79 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.413
2025-03-07 23:03:09,048 - INFO - Episode 2300/10000 - Avg Reward: 1607.68 - Avg Max Tile: 144.96 - Epsilon: 0.050 - Beta: 0.414
2025-03-07 23:06:49,095 - INFO - Episode 2400/10000 - Avg Reward: 1522.23 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.414
2025-03-07 23:10:38,788 - INFO - Episode 2500/10000 - Avg Reward: 1577.22 - Avg Max Tile: 133.60 - Epsilon: 0.050 - Beta: 0.415
2025-03-07 23:14:34,642 - INFO - Episode 2600/10000 - Avg Reward: 1574.26 - Avg Max Tile: 135.36 - Epsilon: 0.050 - Beta: 0.416
2025-03-07 23:18:29,061 - INFO - Episode 2700/10000 - Avg Reward: 1552.42 - Avg Max Tile: 130.56 - Epsilon: 0.050 - Beta: 0.416
2025-03-07 23:22:19,310 - INFO - Episode 2800/10000 - Avg Reward: 1557.40 - Avg Max Tile: 130.88 - Epsilon: 0.050 - Beta: 0.417
2025-03-07 23:26:25,472 - INFO - Episode 2900/10000 - Avg Reward: 1623.89 - Avg Max Tile: 143.04 - Epsilon: 0.050 - Beta: 0.417
2025-03-07 23:30:32,350 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_3000.pt
2025-03-07 23:30:32,350 - INFO - Episode 3000/10000 - Avg Reward: 1650.80 - Avg Max Tile: 137.76 - Epsilon: 0.050 - Beta: 0.418
2025-03-07 23:34:36,181 - INFO - Episode 3100/10000 - Avg Reward: 1641.44 - Avg Max Tile: 141.76 - Epsilon: 0.050 - Beta: 0.419
2025-03-07 23:38:40,238 - INFO - Episode 3200/10000 - Avg Reward: 1637.86 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.419
2025-03-07 23:42:27,091 - INFO - Episode 3300/10000 - Avg Reward: 1487.59 - Avg Max Tile: 125.28 - Epsilon: 0.050 - Beta: 0.420
2025-03-07 23:46:18,842 - INFO - Episode 3400/10000 - Avg Reward: 1545.33 - Avg Max Tile: 134.08 - Epsilon: 0.050 - Beta: 0.420
2025-03-07 23:50:10,394 - INFO - Episode 3500/10000 - Avg Reward: 1559.16 - Avg Max Tile: 131.52 - Epsilon: 0.050 - Beta: 0.421
2025-03-07 23:54:01,093 - INFO - Episode 3600/10000 - Avg Reward: 1568.25 - Avg Max Tile: 127.68 - Epsilon: 0.050 - Beta: 0.422
2025-03-07 23:58:03,121 - INFO - Episode 3700/10000 - Avg Reward: 1685.08 - Avg Max Tile: 143.04 - Epsilon: 0.050 - Beta: 0.422
2025-03-08 00:01:59,082 - INFO - Episode 3800/10000 - Avg Reward: 1507.45 - Avg Max Tile: 125.92 - Epsilon: 0.050 - Beta: 0.423
2025-03-08 00:02:18,095 - INFO - New best score: 4939.399951100349 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-08 00:02:18,096 - INFO - Final board state for new best score 4939.399951100349:
[[512, 128,  32,   4],
 [128,  32,  16,   2],
 [ 32,  16,   2,   8],
 [  4,   2,  16,   2]]
2025-03-08 00:05:57,350 - INFO - Episode 3900/10000 - Avg Reward: 1504.53 - Avg Max Tile: 129.12 - Epsilon: 0.050 - Beta: 0.423
2025-03-08 00:10:01,642 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_4000.pt
2025-03-08 00:10:01,642 - INFO - Episode 4000/10000 - Avg Reward: 1544.65 - Avg Max Tile: 130.88 - Epsilon: 0.050 - Beta: 0.424
2025-03-08 00:10:01,643 - INFO - Episode 4000: Reset epsilon to 0.5, learning rate to 1e-05, and batch size to 1024
2025-03-08 00:12:40,919 - INFO - Episode 4100/10000 - Avg Reward: 1270.56 - Avg Max Tile: 106.56 - Epsilon: 0.113 - Beta: 0.425
2025-03-08 00:15:57,367 - INFO - Episode 4199: Returning to normal epsilon decay rate with learning rate 2e-05 and batch size 2048
2025-03-08 00:15:59,679 - INFO - Episode 4200/10000 - Avg Reward: 1464.42 - Avg Max Tile: 118.24 - Epsilon: 0.050 - Beta: 0.425
2025-03-08 00:20:03,701 - INFO - Episode 4300/10000 - Avg Reward: 1646.71 - Avg Max Tile: 140.16 - Epsilon: 0.050 - Beta: 0.426
2025-03-08 00:23:48,416 - INFO - Episode 4400/10000 - Avg Reward: 1537.91 - Avg Max Tile: 129.12 - Epsilon: 0.050 - Beta: 0.426
2025-03-08 00:27:46,425 - INFO - Episode 4500/10000 - Avg Reward: 1595.71 - Avg Max Tile: 134.88 - Epsilon: 0.050 - Beta: 0.427
2025-03-08 00:31:36,437 - INFO - Episode 4600/10000 - Avg Reward: 1530.36 - Avg Max Tile: 129.12 - Epsilon: 0.050 - Beta: 0.428
2025-03-08 00:35:38,158 - INFO - New best score: 5150.599961280823 - Model saved to models\dueling_dqn\dueling_dqn_per_best.pt
2025-03-08 00:35:38,159 - INFO - Final board state for new best score 5150.599961280823:
[[512, 256,   4,   2],
 [  2,  32,   2,   8],
 [ 32,  16,   8,   4],
 [  2,   8,   4,   2]]
2025-03-08 00:35:46,015 - INFO - Episode 4700/10000 - Avg Reward: 1578.08 - Avg Max Tile: 133.44 - Epsilon: 0.050 - Beta: 0.428
2025-03-08 00:39:29,851 - INFO - Episode 4800/10000 - Avg Reward: 1491.69 - Avg Max Tile: 123.52 - Epsilon: 0.050 - Beta: 0.429
2025-03-08 00:43:08,219 - INFO - Episode 4900/10000 - Avg Reward: 1472.78 - Avg Max Tile: 118.88 - Epsilon: 0.050 - Beta: 0.429
2025-03-08 00:47:16,307 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_5000.pt
2025-03-08 00:47:16,308 - INFO - Episode 5000/10000 - Avg Reward: 1573.78 - Avg Max Tile: 135.04 - Epsilon: 0.050 - Beta: 0.430
2025-03-08 00:51:19,686 - INFO - Episode 5100/10000 - Avg Reward: 1656.32 - Avg Max Tile: 139.04 - Epsilon: 0.050 - Beta: 0.431
2025-03-08 16:01:52,667 - INFO - Episode 5200/10000 - Avg Reward: 1550.14 - Avg Max Tile: 128.00 - Epsilon: 0.050 - Beta: 0.431
2025-03-08 16:05:46,995 - INFO - Episode 5300/10000 - Avg Reward: 1480.45 - Avg Max Tile: 122.88 - Epsilon: 0.050 - Beta: 0.432
2025-03-08 16:10:03,057 - INFO - Episode 5400/10000 - Avg Reward: 1678.66 - Avg Max Tile: 151.04 - Epsilon: 0.050 - Beta: 0.432
2025-03-08 16:13:40,710 - INFO - Episode 5500/10000 - Avg Reward: 1416.70 - Avg Max Tile: 114.56 - Epsilon: 0.050 - Beta: 0.433
2025-03-08 16:17:33,532 - INFO - Episode 5600/10000 - Avg Reward: 1532.53 - Avg Max Tile: 129.76 - Epsilon: 0.050 - Beta: 0.434
2025-03-08 16:21:33,891 - INFO - Episode 5700/10000 - Avg Reward: 1609.61 - Avg Max Tile: 132.96 - Epsilon: 0.050 - Beta: 0.434
2025-03-08 16:25:36,276 - INFO - Episode 5800/10000 - Avg Reward: 1529.32 - Avg Max Tile: 127.04 - Epsilon: 0.050 - Beta: 0.435
2025-03-08 16:29:53,897 - INFO - Episode 5900/10000 - Avg Reward: 1518.40 - Avg Max Tile: 125.28 - Epsilon: 0.050 - Beta: 0.435
2025-03-08 16:34:20,894 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_6000.pt
2025-03-08 16:34:20,895 - INFO - Episode 6000/10000 - Avg Reward: 1552.06 - Avg Max Tile: 129.44 - Epsilon: 0.050 - Beta: 0.436
2025-03-08 16:34:20,895 - INFO - Episode 6000: Reset epsilon to 0.5, learning rate to 1e-05, and batch size to 1024
2025-03-08 16:37:34,262 - INFO - Episode 6100/10000 - Avg Reward: 1318.13 - Avg Max Tile: 114.56 - Epsilon: 0.105 - Beta: 0.437
2025-03-08 16:41:07,551 - INFO - Episode 6199: Returning to normal epsilon decay rate with learning rate 2e-05 and batch size 2048
2025-03-08 16:41:10,393 - INFO - Episode 6200/10000 - Avg Reward: 1459.14 - Avg Max Tile: 119.36 - Epsilon: 0.050 - Beta: 0.437
2025-03-08 16:45:48,618 - INFO - Episode 6300/10000 - Avg Reward: 1643.69 - Avg Max Tile: 139.84 - Epsilon: 0.050 - Beta: 0.438
2025-03-08 16:50:10,207 - INFO - Episode 6400/10000 - Avg Reward: 1573.76 - Avg Max Tile: 132.48 - Epsilon: 0.050 - Beta: 0.438
2025-03-08 16:54:24,108 - INFO - Episode 6500/10000 - Avg Reward: 1497.42 - Avg Max Tile: 119.04 - Epsilon: 0.050 - Beta: 0.439
2025-03-08 16:58:25,422 - INFO - Episode 6600/10000 - Avg Reward: 1434.37 - Avg Max Tile: 116.48 - Epsilon: 0.050 - Beta: 0.440
2025-03-08 17:02:52,694 - INFO - Episode 6700/10000 - Avg Reward: 1620.72 - Avg Max Tile: 138.88 - Epsilon: 0.050 - Beta: 0.440
2025-03-08 17:07:09,635 - INFO - Episode 6800/10000 - Avg Reward: 1506.69 - Avg Max Tile: 124.16 - Epsilon: 0.050 - Beta: 0.441
2025-03-08 17:11:29,487 - INFO - Episode 6900/10000 - Avg Reward: 1508.73 - Avg Max Tile: 125.76 - Epsilon: 0.050 - Beta: 0.441
2025-03-08 17:15:55,664 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_7000.pt
2025-03-08 17:15:55,665 - INFO - Episode 7000/10000 - Avg Reward: 1521.99 - Avg Max Tile: 126.08 - Epsilon: 0.050 - Beta: 0.442
2025-03-08 17:20:13,338 - INFO - Episode 7100/10000 - Avg Reward: 1542.47 - Avg Max Tile: 127.36 - Epsilon: 0.050 - Beta: 0.443
2025-03-08 17:24:42,531 - INFO - Episode 7200/10000 - Avg Reward: 1610.61 - Avg Max Tile: 140.32 - Epsilon: 0.050 - Beta: 0.443
2025-03-08 17:29:30,585 - INFO - Episode 7300/10000 - Avg Reward: 1701.06 - Avg Max Tile: 148.80 - Epsilon: 0.050 - Beta: 0.444
2025-03-08 17:34:01,323 - INFO - Episode 7400/10000 - Avg Reward: 1652.87 - Avg Max Tile: 141.76 - Epsilon: 0.050 - Beta: 0.444
2025-03-08 17:38:34,863 - INFO - Episode 7500/10000 - Avg Reward: 1587.71 - Avg Max Tile: 132.48 - Epsilon: 0.050 - Beta: 0.445
2025-03-08 17:43:07,727 - INFO - Episode 7600/10000 - Avg Reward: 1594.88 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.446
2025-03-08 17:47:53,692 - INFO - Episode 7700/10000 - Avg Reward: 1685.23 - Avg Max Tile: 147.52 - Epsilon: 0.050 - Beta: 0.446
2025-03-08 17:52:21,685 - INFO - Episode 7800/10000 - Avg Reward: 1587.56 - Avg Max Tile: 132.64 - Epsilon: 0.050 - Beta: 0.447
2025-03-08 17:56:33,190 - INFO - Episode 7900/10000 - Avg Reward: 1432.85 - Avg Max Tile: 121.12 - Epsilon: 0.050 - Beta: 0.447
2025-03-08 18:01:11,295 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_8000.pt
2025-03-08 18:01:11,296 - INFO - Episode 8000/10000 - Avg Reward: 1612.69 - Avg Max Tile: 137.92 - Epsilon: 0.050 - Beta: 0.448
2025-03-08 18:01:11,296 - INFO - Episode 8000: Reset epsilon to 0.5, learning rate to 1e-05, and batch size to 1024
2025-03-08 18:04:01,167 - INFO - Episode 8100/10000 - Avg Reward: 1185.87 - Avg Max Tile: 97.92 - Epsilon: 0.122 - Beta: 0.449
2025-03-08 18:07:51,910 - INFO - Episode 8199: Returning to normal epsilon decay rate with learning rate 2e-05 and batch size 2048
2025-03-08 18:07:53,607 - INFO - Episode 8200/10000 - Avg Reward: 1570.10 - Avg Max Tile: 134.40 - Epsilon: 0.050 - Beta: 0.449
2025-03-08 18:12:23,786 - INFO - Episode 8300/10000 - Avg Reward: 1580.25 - Avg Max Tile: 134.40 - Epsilon: 0.050 - Beta: 0.450
2025-03-08 18:16:58,410 - INFO - Episode 8400/10000 - Avg Reward: 1568.87 - Avg Max Tile: 131.84 - Epsilon: 0.050 - Beta: 0.450
2025-03-08 18:21:20,937 - INFO - Episode 8500/10000 - Avg Reward: 1535.91 - Avg Max Tile: 128.96 - Epsilon: 0.050 - Beta: 0.451
2025-03-08 18:25:58,531 - INFO - Episode 8600/10000 - Avg Reward: 1592.49 - Avg Max Tile: 133.76 - Epsilon: 0.050 - Beta: 0.452
2025-03-08 18:30:29,757 - INFO - Episode 8700/10000 - Avg Reward: 1636.22 - Avg Max Tile: 140.80 - Epsilon: 0.050 - Beta: 0.452
2025-03-08 18:35:06,391 - INFO - Episode 8800/10000 - Avg Reward: 1630.39 - Avg Max Tile: 139.20 - Epsilon: 0.050 - Beta: 0.453
2025-03-08 18:39:21,577 - INFO - Episode 8900/10000 - Avg Reward: 1620.01 - Avg Max Tile: 139.52 - Epsilon: 0.050 - Beta: 0.453
2025-03-08 18:43:27,178 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_9000.pt
2025-03-08 18:43:27,178 - INFO - Episode 9000/10000 - Avg Reward: 1540.79 - Avg Max Tile: 133.92 - Epsilon: 0.050 - Beta: 0.454
2025-03-08 18:47:34,045 - INFO - Episode 9100/10000 - Avg Reward: 1591.07 - Avg Max Tile: 136.48 - Epsilon: 0.050 - Beta: 0.455
2025-03-08 18:51:39,491 - INFO - Episode 9200/10000 - Avg Reward: 1572.31 - Avg Max Tile: 134.72 - Epsilon: 0.050 - Beta: 0.455
2025-03-08 18:55:42,636 - INFO - Episode 9300/10000 - Avg Reward: 1555.99 - Avg Max Tile: 127.52 - Epsilon: 0.050 - Beta: 0.456
2025-03-08 18:59:52,006 - INFO - Episode 9400/10000 - Avg Reward: 1593.80 - Avg Max Tile: 138.40 - Epsilon: 0.050 - Beta: 0.456
2025-03-08 19:03:56,688 - INFO - Episode 9500/10000 - Avg Reward: 1514.90 - Avg Max Tile: 131.52 - Epsilon: 0.050 - Beta: 0.457
2025-03-08 19:08:10,554 - INFO - Episode 9600/10000 - Avg Reward: 1602.67 - Avg Max Tile: 138.24 - Epsilon: 0.050 - Beta: 0.458
2025-03-08 19:12:19,904 - INFO - Episode 9700/10000 - Avg Reward: 1584.29 - Avg Max Tile: 139.84 - Epsilon: 0.050 - Beta: 0.458
2025-03-08 19:16:24,935 - INFO - Episode 9800/10000 - Avg Reward: 1596.01 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.459
2025-03-08 19:20:37,007 - INFO - Episode 9900/10000 - Avg Reward: 1640.46 - Avg Max Tile: 145.12 - Epsilon: 0.050 - Beta: 0.459
2025-03-08 19:24:44,800 - INFO - Checkpoint saved to models\dueling_dqn\dueling_dqn_per_10000.pt
2025-03-08 19:24:44,801 - INFO - Episode 10000/10000 - Avg Reward: 1522.90 - Avg Max Tile: 126.72 - Epsilon: 0.050 - Beta: 0.460
2025-03-08 19:24:50,630 - INFO - Training completed - Final model saved to models\dueling_dqn\dueling_dqn_per_final.pt
2025-03-08 19:24:50,630 - INFO - Highest tile achieved during training: 512
2025-03-08 22:18:19,837 - INFO - Starting training with device: cuda
2025-03-08 22:18:19,837 - INFO - Model parameters: 8914186
2025-03-08 22:18:20,096 - INFO - New best score: 4938.200000000001 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:20,096 - INFO - Final board state for new best score 4938.200000000001:
[[ 4,  2, 16,  4],
 [ 8,  4,  8,  2],
 [16, 64, 32,  4],
 [ 4,  2,  4, 16]]
2025-03-08 22:18:20,370 - INFO - New best score: 5430.899999999999 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:20,370 - INFO - Final board state for new best score 5430.899999999999:
[[ 4, 16,  4,  2],
 [ 8,  4,  8, 16],
 [ 2, 64, 32,  8],
 [ 4,  2, 16,  2]]
2025-03-08 22:18:20,906 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-08 22:18:20,906 - INFO - Final board state for new max tile 128:
[[  2,   8,  32,   4],
 [ 16,   4,  16,  32],
 [  4, 128,  64,   8],
 [  2,   4,   8,   4]]
2025-03-08 22:18:20,990 - INFO - New best score: 6664.399999999994 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:20,991 - INFO - Final board state for new best score 6664.399999999994:
[[  2,   8,  32,   4],
 [ 16,   4,  16,  32],
 [  4, 128,  64,   8],
 [  2,   4,   8,   4]]
2025-03-08 22:18:21,551 - INFO - New best score: 7106.100000000002 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:21,552 - INFO - Final board state for new best score 7106.100000000002:
[[  8,   2,   8,   4],
 [ 32, 128,   2,   8],
 [  2,   4,  16,   4],
 [  4,  16,   4,   2]]
2025-03-08 22:18:22,336 - INFO - New best score: 7227.000000000002 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:22,337 - INFO - Final board state for new best score 7227.000000000002:
[[  2,   4,  16,   8],
 [  4,  16,  32,  16],
 [  8, 128,   2,   4],
 [  4,  64,  32,   2]]
2025-03-08 22:18:23,194 - INFO - New best score: 7409.399999999999 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:23,195 - INFO - Final board state for new best score 7409.399999999999:
[[  4,  64,   4,   2],
 [128,   8,  16,   8],
 [  2,   4,  64,   4],
 [  4,   8,   4,   2]]
2025-03-08 22:18:23,695 - INFO - New highest tile achieved: 256 (Episode 12)
2025-03-08 22:18:23,696 - INFO - Final board state for new max tile 256:
[[  4,   2,   4,  32],
 [ 32,   8, 128,   4],
 [  4, 256,   8,  16],
 [  2,   8,  16,   8]]
2025-03-08 22:18:23,799 - INFO - New best score: 9438.000000000004 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:23,800 - INFO - Final board state for new best score 9438.000000000004:
[[  4,   2,   4,  32],
 [ 32,   8, 128,   4],
 [  4, 256,   8,  16],
 [  2,   8,  16,   8]]
2025-03-08 22:18:44,337 - INFO - New best score: 9614.9 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:18:44,338 - INFO - Final board state for new best score 9614.9:
[[  4,   2,   4,   2],
 [ 16,   8, 256,  16],
 [  8,  32,  64,   4],
 [  4,  16,   4,   2]]
2025-03-08 22:19:31,935 - INFO - New best score: 10268.199999999999 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:19:31,936 - INFO - Final board state for new best score 10268.199999999999:
[[  2,   4,   2,  16],
 [  8, 256,   8,   4],
 [ 16,   8,   4,   2],
 [  2,   4,   2,   8]]
2025-03-08 22:21:10,788 - INFO - Episode 100/15000 - Avg Reward: 6224.01 - Avg Max Tile: 101.76 - Epsilon: 0.328 - Beta: 0.401
2025-03-08 22:24:32,925 - INFO - New best score: 10952.199999999992 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:24:32,925 - INFO - Final board state for new best score 10952.199999999992:
[[256,   2,   8,   2],
 [  2,   4,  16,   8],
 [ 16,  64,   8,   4],
 [  2,   8,   4,   2]]
2025-03-08 22:25:24,685 - INFO - Episode 200/15000 - Avg Reward: 6379.74 - Avg Max Tile: 102.08 - Epsilon: 0.074 - Beta: 0.401
2025-03-08 22:25:34,393 - INFO - New best score: 11156.60000000001 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:25:34,394 - INFO - Final board state for new best score 11156.60000000001:
[[256,  32,   8,   4],
 [  2,  64,  16,   8],
 [ 64,  16,   4,   2],
 [  2,   8,   2,   4]]
2025-03-08 22:29:05,798 - INFO - New highest tile achieved: 512 (Episode 263)
2025-03-08 22:29:05,798 - INFO - Final board state for new max tile 512:
[[512,   2,   4,   2],
 [  2,  32,  64,   8],
 [ 32,   4,  16,   2],
 [  2,   8,   2,   4]]
2025-03-08 22:29:06,968 - INFO - New best score: 14377.000000000002 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:29:06,969 - INFO - Final board state for new best score 14377.000000000002:
[[512,   2,   4,   2],
 [  2,  32,  64,   8],
 [ 32,   4,  16,   2],
 [  2,   8,   2,   4]]
2025-03-08 22:31:06,416 - INFO - New best score: 14511.600000000017 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:31:06,416 - INFO - Final board state for new best score 14511.600000000017:
[[  8, 256,  32,  16],
 [512,  64,  16,   8],
 [  8,   2,   8,   2],
 [  2,  32,   2,   4]]
2025-03-08 22:31:13,735 - INFO - Episode 300/15000 - Avg Reward: 7774.94 - Avg Max Tile: 151.68 - Epsilon: 0.050 - Beta: 0.402
2025-03-08 22:36:12,572 - INFO - New best score: 15681.099999999991 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 22:36:12,573 - INFO - Final board state for new best score 15681.099999999991:
[[512,   2,  32,  16],
 [  2, 128,  16,   8],
 [128,  16,   8,   4],
 [  2,   8,   4,   2]]
2025-03-08 22:36:39,286 - INFO - Episode 400/15000 - Avg Reward: 7327.42 - Avg Max Tile: 135.68 - Epsilon: 0.050 - Beta: 0.402
2025-03-08 22:42:26,445 - INFO - Episode 500/15000 - Avg Reward: 7626.35 - Avg Max Tile: 144.96 - Epsilon: 0.050 - Beta: 0.403
2025-03-08 22:47:46,852 - INFO - Episode 600/15000 - Avg Reward: 7197.99 - Avg Max Tile: 130.40 - Epsilon: 0.050 - Beta: 0.404
2025-03-08 22:53:05,488 - INFO - Episode 700/15000 - Avg Reward: 7115.73 - Avg Max Tile: 129.76 - Epsilon: 0.050 - Beta: 0.404
2025-03-08 22:58:37,437 - INFO - Episode 800/15000 - Avg Reward: 7368.02 - Avg Max Tile: 134.40 - Epsilon: 0.050 - Beta: 0.405
2025-03-08 23:03:54,266 - INFO - Episode 900/15000 - Avg Reward: 6939.36 - Avg Max Tile: 121.60 - Epsilon: 0.050 - Beta: 0.405
2025-03-08 23:09:18,480 - INFO - Checkpoint saved to models\enhanced_dqn\enhanced_dqn_per_1000.pt
2025-03-08 23:09:18,482 - INFO - Episode 1000/15000 - Avg Reward: 7268.39 - Avg Max Tile: 128.96 - Epsilon: 0.050 - Beta: 0.406
2025-03-08 23:11:11,370 - INFO - New best score: 15796.200000000008 - Model saved to models\enhanced_dqn\enhanced_dqn_per_best.pt
2025-03-08 23:11:11,370 - INFO - Final board state for new best score 15796.200000000008:
[[512, 128,  64,  16],
 [128,  64,   4,   2],
 [  8,   4,   2,   4],
 [  4,  16,   8,   2]]
2025-03-08 23:14:52,769 - INFO - Episode 1100/15000 - Avg Reward: 7202.19 - Avg Max Tile: 129.92 - Epsilon: 0.050 - Beta: 0.407
2025-03-08 23:20:20,081 - INFO - Episode 1200/15000 - Avg Reward: 7370.19 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.407
2025-03-09 10:37:44,914 - INFO - Episode 1300/15000 - Avg Reward: 7430.40 - Avg Max Tile: 132.80 - Epsilon: 0.050 - Beta: 0.408
2025-03-09 10:43:15,706 - INFO - Episode 1400/15000 - Avg Reward: 7275.75 - Avg Max Tile: 132.16 - Epsilon: 0.050 - Beta: 0.408
2025-03-09 10:48:53,903 - INFO - Episode 1500/15000 - Avg Reward: 7301.39 - Avg Max Tile: 137.76 - Epsilon: 0.050 - Beta: 0.409
2025-03-09 10:54:45,932 - INFO - Episode 1600/15000 - Avg Reward: 7323.46 - Avg Max Tile: 135.84 - Epsilon: 0.050 - Beta: 0.410
2025-03-09 11:00:11,274 - INFO - Episode 1700/15000 - Avg Reward: 7201.98 - Avg Max Tile: 125.92 - Epsilon: 0.050 - Beta: 0.410
2025-03-09 11:05:49,224 - INFO - Episode 1800/15000 - Avg Reward: 7279.15 - Avg Max Tile: 131.20 - Epsilon: 0.050 - Beta: 0.411
2025-03-09 11:11:47,222 - INFO - Episode 1900/15000 - Avg Reward: 7414.63 - Avg Max Tile: 136.80 - Epsilon: 0.050 - Beta: 0.411
2025-03-09 11:18:31,323 - INFO - Checkpoint saved to models\enhanced_dqn\enhanced_dqn_per_2000.pt
2025-03-09 11:18:31,324 - INFO - Episode 2000/15000 - Avg Reward: 7953.63 - Avg Max Tile: 155.52 - Epsilon: 0.050 - Beta: 0.412
2025-03-09 11:18:31,324 - INFO - Episode 2000: Reset epsilon to 0.5, learning rate to 5e-06, and batch size to 2048
2025-03-09 11:23:22,896 - INFO - Episode 2100/15000 - Avg Reward: 6625.45 - Avg Max Tile: 115.04 - Epsilon: 0.108 - Beta: 0.413
2025-03-09 11:29:05,565 - INFO - Episode 2199: Returning to normal epsilon decay rate with learning rate 1e-05 and batch size 4096
2025-03-09 11:29:10,962 - INFO - Episode 2200/15000 - Avg Reward: 7340.68 - Avg Max Tile: 134.72 - Epsilon: 0.050 - Beta: 0.413
2025-03-09 11:39:25,728 - INFO - Episode 2300/15000 - Avg Reward: 7630.17 - Avg Max Tile: 141.44 - Epsilon: 0.050 - Beta: 0.414
2025-03-09 11:48:59,269 - INFO - Episode 2400/15000 - Avg Reward: 7181.76 - Avg Max Tile: 127.68 - Epsilon: 0.050 - Beta: 0.414
2025-03-09 11:58:11,875 - INFO - Episode 2500/15000 - Avg Reward: 7093.41 - Avg Max Tile: 128.64 - Epsilon: 0.050 - Beta: 0.415
2025-03-09 12:07:40,984 - INFO - Episode 2600/15000 - Avg Reward: 7310.05 - Avg Max Tile: 132.80 - Epsilon: 0.050 - Beta: 0.416
2025-03-09 12:16:55,258 - INFO - Episode 2700/15000 - Avg Reward: 6935.88 - Avg Max Tile: 123.20 - Epsilon: 0.050 - Beta: 0.416
2025-03-09 12:26:20,879 - INFO - Episode 2800/15000 - Avg Reward: 7128.75 - Avg Max Tile: 127.04 - Epsilon: 0.050 - Beta: 0.417
2025-03-09 12:35:47,141 - INFO - Episode 2900/15000 - Avg Reward: 7332.00 - Avg Max Tile: 131.36 - Epsilon: 0.050 - Beta: 0.417
2025-03-09 12:45:45,920 - INFO - Checkpoint saved to models\enhanced_dqn\enhanced_dqn_per_3000.pt
2025-03-09 12:45:45,921 - INFO - Episode 3000/15000 - Avg Reward: 7187.45 - Avg Max Tile: 137.76 - Epsilon: 0.050 - Beta: 0.418
2025-03-09 12:51:28,474 - INFO - Loading checkpoint from models\enhanced_dqn\enhanced_dqn_per_3000.pt
2025-03-09 12:51:32,668 - ERROR - Error loading checkpoint: Error(s) in loading state_dict for DQNAgent:
	Missing key(s) in state_dict: "res_blocks.6.conv1.weight", "res_blocks.6.conv1.bias", "res_blocks.6.bn1.weight", "res_blocks.6.bn1.bias", "res_blocks.6.bn1.running_mean", "res_blocks.6.bn1.running_var", "res_blocks.6.conv2.weight", "res_blocks.6.conv2.bias", "res_blocks.6.bn2.weight", "res_blocks.6.bn2.bias", "res_blocks.6.bn2.running_mean", "res_blocks.6.bn2.running_var", "res_blocks.7.conv1.weight", "res_blocks.7.conv1.bias", "res_blocks.7.bn1.weight", "res_blocks.7.bn1.bias", "res_blocks.7.bn1.running_mean", "res_blocks.7.bn1.running_var", "res_blocks.7.conv2.weight", "res_blocks.7.conv2.bias", "res_blocks.7.bn2.weight", "res_blocks.7.bn2.bias", "res_blocks.7.bn2.running_mean", "res_blocks.7.bn2.running_var", "fc_adv.5.weight", "fc_adv.5.bias", "fc_adv.5.running_mean", "fc_adv.5.running_var", "fc_adv.8.weight", "fc_adv.8.bias", "fc_val.5.weight", "fc_val.5.bias", "fc_val.5.running_mean", "fc_val.5.running_var", "fc_val.8.weight", "fc_val.8.bias", "target_network.res_blocks.6.conv1.weight", "target_network.res_blocks.6.conv1.bias", "target_network.res_blocks.6.bn1.weight", "target_network.res_blocks.6.bn1.bias", "target_network.res_blocks.6.bn1.running_mean", "target_network.res_blocks.6.bn1.running_var", "target_network.res_blocks.6.conv2.weight", "target_network.res_blocks.6.conv2.bias", "target_network.res_blocks.6.bn2.weight", "target_network.res_blocks.6.bn2.bias", "target_network.res_blocks.6.bn2.running_mean", "target_network.res_blocks.6.bn2.running_var", "target_network.res_blocks.7.conv1.weight", "target_network.res_blocks.7.conv1.bias", "target_network.res_blocks.7.bn1.weight", "target_network.res_blocks.7.bn1.bias", "target_network.res_blocks.7.bn1.running_mean", "target_network.res_blocks.7.bn1.running_var", "target_network.res_blocks.7.conv2.weight", "target_network.res_blocks.7.conv2.bias", "target_network.res_blocks.7.bn2.weight", "target_network.res_blocks.7.bn2.bias", "target_network.res_blocks.7.bn2.running_mean", "target_network.res_blocks.7.bn2.running_var", "target_network.fc_adv.5.weight", "target_network.fc_adv.5.bias", "target_network.fc_adv.5.running_mean", "target_network.fc_adv.5.running_var", "target_network.fc_adv.8.weight", "target_network.fc_adv.8.bias", "target_network.fc_val.5.weight", "target_network.fc_val.5.bias", "target_network.fc_val.5.running_mean", "target_network.fc_val.5.running_var", "target_network.fc_val.8.weight", "target_network.fc_val.8.bias". 
	size mismatch for conv1.weight: copying a param with shape torch.Size([128, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 16, 3, 3]).
	size mismatch for conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.0.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.0.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.1.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.1.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.2.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.2.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.3.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.3.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.4.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.4.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.5.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for res_blocks.5.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for res_blocks.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for conv2.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).
	size mismatch for conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for skip_conv.weight: copying a param with shape torch.Size([256, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 16, 1, 1]).
	size mismatch for skip_conv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for skip_bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for skip_bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for skip_bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for skip_bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc1.weight: copying a param with shape torch.Size([512, 4096]) from checkpoint, the shape in current model is torch.Size([1024, 8192]).
	size mismatch for fc1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for bn_fc1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for bn_fc1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for bn_fc1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for bn_fc1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for fc_adv.0.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([512, 1024]).
	size mismatch for fc_adv.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_adv.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_adv.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_adv.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_adv.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_adv.4.weight: copying a param with shape torch.Size([4, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for fc_adv.4.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for fc_val.0.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([512, 1024]).
	size mismatch for fc_val.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_val.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_val.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_val.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_val.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for fc_val.4.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for fc_val.4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.conv1.weight: copying a param with shape torch.Size([128, 16, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 16, 3, 3]).
	size mismatch for target_network.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.0.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.0.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.0.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.1.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.1.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.1.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.2.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.2.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.2.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.3.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.3.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.3.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.4.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.4.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.4.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.conv1.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.5.conv1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn1.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn1.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn1.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn1.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.conv2.weight: copying a param with shape torch.Size([128, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 256, 3, 3]).
	size mismatch for target_network.res_blocks.5.conv2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn2.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn2.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.res_blocks.5.bn2.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.conv2.weight: copying a param with shape torch.Size([256, 128, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 256, 3, 3]).
	size mismatch for target_network.conv2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.bn2.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.bn2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.bn2.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.bn2.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.skip_conv.weight: copying a param with shape torch.Size([256, 16, 1, 1]) from checkpoint, the shape in current model is torch.Size([512, 16, 1, 1]).
	size mismatch for target_network.skip_conv.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.skip_bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.skip_bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.skip_bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.skip_bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc1.weight: copying a param with shape torch.Size([512, 4096]) from checkpoint, the shape in current model is torch.Size([1024, 8192]).
	size mismatch for target_network.fc1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for target_network.bn_fc1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for target_network.bn_fc1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for target_network.bn_fc1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for target_network.bn_fc1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).
	size mismatch for target_network.fc_adv.0.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([512, 1024]).
	size mismatch for target_network.fc_adv.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_adv.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_adv.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_adv.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_adv.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_adv.4.weight: copying a param with shape torch.Size([4, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for target_network.fc_adv.4.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([256]).
	size mismatch for target_network.fc_val.0.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([512, 1024]).
	size mismatch for target_network.fc_val.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_val.1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_val.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_val.1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_val.1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for target_network.fc_val.4.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([256, 512]).
	size mismatch for target_network.fc_val.4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([256]).
2025-03-09 12:52:54,614 - INFO - Starting training with device: cuda
2025-03-09 12:52:54,614 - INFO - Model parameters: 40772618
2025-03-09 12:52:55,102 - INFO - New best score: 5422.700000000002 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 12:52:55,102 - INFO - Final board state for new best score 5422.700000000002:
[[ 4,  8,  4,  2],
 [ 2, 64, 16,  8],
 [ 8,  2,  8,  2],
 [ 2, 16,  2, 64]]
2025-03-09 12:52:55,601 - INFO - New best score: 5497.7999999999965 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 12:52:55,601 - INFO - Final board state for new best score 5497.7999999999965:
[[ 2, 32,  4,  2],
 [ 4,  8,  2,  8],
 [64, 16, 32,  4],
 [ 4,  8,  4,  2]]
2025-03-09 12:52:57,341 - INFO - New highest tile achieved: 128 (Episode 3)
2025-03-09 12:52:57,341 - INFO - Final board state for new max tile 128:
[[  2,   4,   2, 128],
 [ 16,   8,   4,  32],
 [  8,  64,  32,   2],
 [  2,   4,   2,   4]]
2025-03-09 12:52:57,647 - INFO - New best score: 7285.900000000001 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 12:52:57,648 - INFO - Final board state for new best score 7285.900000000001:
[[  2,   4,   2, 128],
 [ 16,   8,   4,  32],
 [  8,  64,  32,   2],
 [  2,   4,   2,   4]]
2025-03-09 12:52:58,721 - INFO - New best score: 7635.999999999998 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 12:52:58,721 - INFO - Final board state for new best score 7635.999999999998:
[[  2,   4,   2,   8],
 [  4,   2,   8,   4],
 [  8,  16, 128,  16],
 [  2,   4,  64,   8]]
2025-03-09 12:53:01,136 - INFO - New highest tile achieved: 256 (Episode 14)
2025-03-09 12:53:01,136 - INFO - Final board state for new max tile 256:
[[  2,  32,  16,   4],
 [ 16,   4, 256,  16],
 [  2,   8,   4,   2],
 [  4,   2,  32,   4]]
2025-03-09 12:53:01,523 - INFO - New best score: 10040.700000000008 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 12:53:01,523 - INFO - Final board state for new best score 10040.700000000008:
[[  2,  32,  16,   4],
 [ 16,   4, 256,  16],
 [  2,   8,   4,   2],
 [  4,   2,  32,   4]]
2025-03-09 12:53:09,121 - INFO - New best score: 10044.900000000005 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 12:53:09,121 - INFO - Final board state for new best score 10044.900000000005:
[[  4,   2,   8,   4],
 [ 16,   8, 256,   2],
 [  8,  64,   2,  16],
 [  2,   8,  16,   2]]
2025-03-09 12:59:09,081 - INFO - Episode 100/15000 - Avg Reward: 6194.27 - Avg Max Tile: 99.68 - Epsilon: 0.743 - Beta: 0.401
2025-03-09 13:19:13,694 - INFO - New best score: 10242.599999999997 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 13:19:13,694 - INFO - Final board state for new best score 10242.599999999997:
[[  4,   2,   4,   2],
 [256,   8,   2,   8],
 [  4,  32,  64,   2],
 [  8,   4,   2,   4]]
2025-03-09 13:31:10,230 - INFO - Episode 200/15000 - Avg Reward: 6290.71 - Avg Max Tile: 100.80 - Epsilon: 0.183 - Beta: 0.401
2025-03-09 13:44:24,557 - INFO - New best score: 10390.900000000014 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 13:44:24,557 - INFO - Final board state for new best score 10390.900000000014:
[[  4, 128,   2,   8],
 [256,  64,   8,   4],
 [  4,  32,  16,   2],
 [  2,   8,   4,   8]]
2025-03-09 13:45:20,250 - INFO - New best score: 10549.4 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 13:45:20,250 - INFO - Final board state for new best score 10549.4:
[[256,  64,   8,   2],
 [  4,   2,  32,  16],
 [  2,  64,   8,   4],
 [  4,  16,   4,   2]]
2025-03-09 13:46:03,189 - INFO - New best score: 10737.399999999992 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 13:46:03,190 - INFO - Final board state for new best score 10737.399999999992:
[[  4,   2,  32,   4],
 [256,  16,   8,   2],
 [ 16,   4,   2,   4],
 [  4,   2,   8,   2]]
2025-03-09 13:49:03,122 - INFO - New highest tile achieved: 512 (Episode 247)
2025-03-09 13:49:03,122 - INFO - Final board state for new max tile 512:
[[ 16,  64,   4,   2],
 [512, 128,  16,   8],
 [ 64,  32,   4,   2],
 [  2,   4,  16,   4]]
2025-03-09 13:49:04,555 - INFO - New best score: 13456.20000000001 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 13:49:04,555 - INFO - Final board state for new best score 13456.20000000001:
[[ 16,  64,   4,   2],
 [512, 128,  16,   8],
 [ 64,  32,   4,   2],
 [  2,   4,  16,   4]]
2025-03-09 14:11:20,817 - INFO - Episode 300/15000 - Avg Reward: 7020.89 - Avg Max Tile: 125.60 - Epsilon: 0.050 - Beta: 0.402
2025-03-09 14:53:11,475 - INFO - Episode 400/15000 - Avg Reward: 7285.31 - Avg Max Tile: 126.08 - Epsilon: 0.050 - Beta: 0.402
2025-03-09 15:30:54,175 - INFO - Checkpoint saved to models\enhanced_dqn_v2\enhanced_dqn_per_500.pt
2025-03-09 15:30:54,176 - INFO - Episode 500/15000 - Avg Reward: 6673.37 - Avg Max Tile: 108.16 - Epsilon: 0.050 - Beta: 0.403
2025-03-09 15:49:36,321 - INFO - New best score: 15007.500000000013 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 15:49:36,321 - INFO - Final board state for new best score 15007.500000000013:
[[512, 128,  64,  32],
 [128,   8,   2,  16],
 [  8,   2,  16,   4],
 [  4,  16,   8,   2]]
2025-03-09 16:03:13,354 - INFO - New best score: 15293.800000000005 - Model saved to models\enhanced_dqn_v2\enhanced_dqn_per_best.pt
2025-03-09 16:03:13,354 - INFO - Final board state for new best score 15293.800000000005:
[[  8,  32,   8,   2],
 [512,  64,  16,   8],
 [ 16,  32,   8,   4],
 [  4,   8,   4,   2]]
2025-03-09 16:12:17,368 - INFO - Episode 600/15000 - Avg Reward: 7207.24 - Avg Max Tile: 129.92 - Epsilon: 0.050 - Beta: 0.404
2025-03-09 16:55:13,211 - INFO - Episode 700/15000 - Avg Reward: 7208.64 - Avg Max Tile: 131.52 - Epsilon: 0.050 - Beta: 0.404
2025-03-09 17:38:20,124 - INFO - Episode 800/15000 - Avg Reward: 7383.70 - Avg Max Tile: 133.92 - Epsilon: 0.050 - Beta: 0.405
2025-03-09 18:23:46,486 - INFO - Episode 900/15000 - Avg Reward: 7408.41 - Avg Max Tile: 140.16 - Epsilon: 0.050 - Beta: 0.405
2025-03-09 19:05:18,086 - INFO - Checkpoint saved to models\enhanced_dqn_v2\enhanced_dqn_per_1000.pt
2025-03-09 19:05:18,087 - INFO - Episode 1000/15000 - Avg Reward: 7341.27 - Avg Max Tile: 133.28 - Epsilon: 0.050 - Beta: 0.406
2025-03-17 15:25:28,008 - INFO - Using device: cuda
2025-03-17 15:25:28,009 - INFO - Arguments: Namespace(episodes=20000, max_steps=2000, buffer_size=50000, batch_size=64, gamma=0.99, epsilon_start=0.9, epsilon_end=0.01, epsilon_decay=0.9999, learning_rate=5e-05, log_interval=100, eval_interval=500, eval_episodes=5, output_dir='custom_dqn_results', checkpoint=None, seed=42)
2025-03-17 15:25:30,992 - INFO - Starting training for 20000 episodes
2025-03-17 18:22:55,317 - INFO - Using device: cuda
2025-03-17 18:22:55,317 - INFO - Arguments: Namespace(episodes=20000, max_steps=2000, buffer_size=50000, batch_size=64, gamma=0.99, epsilon_start=0.9, epsilon_end=0.01, epsilon_decay=0.9999, learning_rate=5e-05, log_interval=100, eval_interval=500, eval_episodes=5, output_dir='custom_dqn_results', checkpoint=None, seed=42)
2025-03-17 18:22:58,539 - INFO - Starting training for 20000 episodes
2025-03-17 18:36:23,962 - INFO - Using device: cuda
2025-03-17 18:36:23,962 - INFO - Arguments: Namespace(episodes=20000, max_steps=2000, buffer_size=50000, batch_size=64, gamma=0.99, epsilon_start=0.9, epsilon_end=0.01, epsilon_decay=0.9999, learning_rate=5e-05, log_interval=100, eval_interval=500, eval_episodes=5, output_dir='custom_dqn_results', checkpoint=None, seed=42)
2025-03-17 18:36:27,138 - INFO - Starting training for 20000 episodes
2025-03-20 18:57:33,710 - INFO - Using device: cuda
2025-03-20 18:57:33,710 - INFO - Arguments: Namespace(total_timesteps=1000000, timesteps_per_update=2048, max_episode_length=2000, embed_dim=256, num_heads=4, num_layers=4, learning_rate=0.0003, gamma=0.995, clip_ratio=0.2, vf_coef=0.5, ent_coef=0.01, max_grad_norm=0.5, gae_lambda=0.95, update_epochs=4, target_kl=0.01, batch_size=256, mixed_precision=True, use_data_parallel=False, eval_interval=50, eval_episodes=5, output_dir='transformer_ppo_results', checkpoint=None, seed=42)
2025-03-20 18:57:33,717 - INFO - GPU: NVIDIA GeForce RTX 2080 SUPER
2025-03-20 18:57:33,717 - INFO - CUDA Version: 11.8
2025-03-20 18:59:29,618 - WARNING - Could not start GPU monitoring
2025-03-25 17:50:58,439 - INFO - Evaluation completed in 83.55 seconds
2025-03-25 17:50:58,440 - INFO - Average score: 6258.23 ± 1562.68
2025-03-25 17:50:58,440 - INFO - Average max tile: 100.48 ± 52.19
2025-03-25 17:50:58,440 - INFO - Average game length: 102.16 ± 32.15
2025-03-25 17:50:58,440 - INFO - Maximum tile reached: 256
2025-03-25 17:50:59,279 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-25 17:50:59,280 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-25 17:58:37,302 - INFO - Evaluation completed in 419.70 seconds
2025-03-25 17:58:37,303 - INFO - Average score: 6216.02 ± 1492.49
2025-03-25 17:58:37,303 - INFO - Average max tile: 100.35 ± 49.46
2025-03-25 17:58:37,304 - INFO - Average game length: 106.36 ± 32.20
2025-03-25 17:58:37,304 - INFO - Maximum tile reached: 256
2025-03-25 17:58:37,625 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-25 17:58:37,626 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-25 18:13:35,265 - INFO - Evaluation completed in 747.08 seconds
2025-03-25 18:13:35,266 - INFO - Average score: 6298.31 ± 1613.73
2025-03-25 18:13:35,266 - INFO - Average max tile: 104.80 ± 57.24
2025-03-25 18:13:35,266 - INFO - Average game length: 108.01 ± 36.22
2025-03-25 18:13:35,266 - INFO - Maximum tile reached: 256
2025-03-25 18:13:35,569 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
2025-03-25 18:13:35,570 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.
